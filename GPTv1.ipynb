{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12e463ad-ec4b-443a-8857-370f57660408",
   "metadata": {},
   "source": [
    "# <a href=\"https://paul-hyun.github.io/gpt-01/\">Reference blog</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d8e4a2c-dae7-4e85-8eea-598d8c901698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'web-crawler'에 복제합니다...\n",
      "remote: Enumerating objects: 75, done.\u001b[K\n",
      "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
      "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
      "remote: Total 75 (delta 36), reused 56 (delta 20), pack-reused 0\u001b[K\n",
      "오브젝트 묶음 푸는 중: 100% (75/75), 52.54 KiB | 768.00 KiB/s, 완료.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/paul-hyun/web-crawler.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd253300-6357-465b-bc14-c22372ef84a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (4.65.0)\n",
      "Requirement already satisfied: pandas in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (2.0.0)\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pymongo\n",
      "  Downloading pymongo-4.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (602 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.6/602.6 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from pandas) (1.24.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from bs4) (4.12.2)\n",
      "Collecting dnspython<3.0.0,>=1.16.0\n",
      "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from beautifulsoup4->bs4) (2.3.2.post1)\n",
      "Building wheels for collected packages: bs4, wget\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1256 sha256=c93fdf4777c43411515aa1e70f50556092b7671456f888cf7eb51d754edb3f4e\n",
      "  Stored in directory: /home/qkrwnstj/.cache/pip/wheels/73/2b/cb/099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=8bdea3e17c0478554e807cf98005ece52e01c2173759d4bd7eb523dc53f6a73a\n",
      "  Stored in directory: /home/qkrwnstj/.cache/pip/wheels/04/5f/3e/46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
      "Successfully built bs4 wget\n",
      "Installing collected packages: wget, dnspython, pymongo, bs4\n",
      "Successfully installed bs4-0.0.1 dnspython-2.4.2 pymongo-4.4.1 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm pandas bs4 wget pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2238db8a-5556-4b99-a885-cfbd3dc391d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/backup/GPTv1/web-crawler\n"
     ]
    }
   ],
   "source": [
    "%cd web-crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e427a5b-2e17-4ca9-b276-f50bb3344991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 93% [.............................................   ] 1075535872 / 1145584828"
     ]
    }
   ],
   "source": [
    "!python kowiki.py #kowiki 폴더아래 kowiki_yyyymmdd.csv 형태의 파일이 생성 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b56de25e-1db9-4d04-a547-2ac9bbbaaabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "csv.field_size_limit(sys.maxsize) #csv의 컬럼이 131072개 이상이여서 limit을 늘려줘야 함.\n",
    "\n",
    "in_file = \"./kowiki/kowiki_20230815.csv\"\n",
    "out_file = \"./kowiki/kowiki.txt\"\n",
    "SEPARATOR = u\"\\u241D\"\n",
    "\n",
    "df = pd.read_csv(in_file, sep=SEPARATOR, engine = \"python\")\n",
    "\n",
    "with open(out_file, \"w\") as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write(row[\"text\"]) #text에 title에 대한 정보가 존재하기 때문에, text만 저장\n",
    "        f.write(\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "271a5433-be6d-4740-aeda-ac762827b33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>https://ko.wikipedia.org/wiki?curid=5</td>\n",
       "      <td>지미 카터</td>\n",
       "      <td>지미 카터\\n제임스 얼 카터 주니어(, 1924년 10월 1일~)는 민주당 출신 미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>https://ko.wikipedia.org/wiki?curid=9</td>\n",
       "      <td>수학</td>\n",
       "      <td>수학\\n수학(數學, , 줄여서 math)은 수, 양, 구조, 공간, 변화 등의 개념...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>https://ko.wikipedia.org/wiki?curid=10</td>\n",
       "      <td>수학 상수</td>\n",
       "      <td>수학 상수\\n수학에서 상수란 그 값이 변하지 않는 불변량으로, 변수의 반대말이다. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>https://ko.wikipedia.org/wiki?curid=19</td>\n",
       "      <td>문학</td>\n",
       "      <td>문학\\n문학(文學, )은 언어를 예술적 표현의 제재로 삼아 새로운 의미를 창출하여,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>https://ko.wikipedia.org/wiki?curid=20</td>\n",
       "      <td>나라 목록</td>\n",
       "      <td>나라 목록\\n이 목록에 실린 국가 기준은 1933년 몬테비데오 협약 1장을 참고로 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                     url  title   \n",
       "0   5   https://ko.wikipedia.org/wiki?curid=5  지미 카터  \\\n",
       "1   9   https://ko.wikipedia.org/wiki?curid=9     수학   \n",
       "2  10  https://ko.wikipedia.org/wiki?curid=10  수학 상수   \n",
       "3  19  https://ko.wikipedia.org/wiki?curid=19     문학   \n",
       "4  20  https://ko.wikipedia.org/wiki?curid=20  나라 목록   \n",
       "\n",
       "                                                text  \n",
       "0  지미 카터\\n제임스 얼 카터 주니어(, 1924년 10월 1일~)는 민주당 출신 미...  \n",
       "1  수학\\n수학(數學, , 줄여서 math)은 수, 양, 구조, 공간, 변화 등의 개념...  \n",
       "2  수학 상수\\n수학에서 상수란 그 값이 변하지 않는 불변량으로, 변수의 반대말이다. ...  \n",
       "3  문학\\n문학(文學, )은 언어를 예술적 표현의 제재로 삼아 새로운 의미를 창출하여,...  \n",
       "4  나라 목록\\n이 목록에 실린 국가 기준은 1933년 몬테비데오 협약 1장을 참고로 ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4317be75-b099-45c6-8f34-4bf2389b80c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "지미 카터\n",
      "\n",
      "제임스 얼 카터 주니어(, 1924년 10월 1일~)는 민주당 출신 미국의 제39대 대통령(1977년~1981년)이다.\n",
      "\n",
      "지미 카터는 조지아주 섬터 카운티 플레인스 마을에서 태어났다.\n",
      "\n",
      "조지아 공과대학교를 졸업하였다. 그 후 해군에 들어가 전함·원자력·잠수함의 승무원으로 일하였다. 1953년 미국 해군 대위로 예편하였고 이후 땅콩·면화 등을 가꿔 많은 돈을 벌었다. 그의 별명이 \"땅콩 농부\" (Peanut Farmer)로 알려졌다.\n",
      "\n",
      "1962년 조지아주 상원 의원 선거에서 낙선하였으나, 그 선거가 부정선거 였음을 입증하게 되어 당선되고, 1966년 조지아 주지사 선거에 낙선하지만, 1970년 조지아 주지사 선거에서 당선됐다. 대통령이 되기 전 조지아주 상원의원을 두번 연임했으며, 1971년부터 1975년까지 조지아 지사로 근무했다. 조지아 주지사로 지내면서, 미국에 사는 흑인 등용법을 내세웠다.\n",
      "\n",
      "1976년 미합중국 제39대 대통령 선거에 민주당 후보로 출마하여 도덕주의 정책으로 내세워서, 많은 지지를 받고 제럴드 포드 대통령을 누르고 당선되었다.\n",
      "\n",
      "카터 대통령은 에너지 개발을 촉구했으나 공화당의 반대로 무산되었다.\n",
      "\n",
      "카터는 이집트와 이스라엘을 조정하여 캠프 데이비드에서 안와르 사다트 대통령과 메나헴 베긴 수상과 함께 중동 평화를 위한 캠프데이비드 협정을 체결했다. 이것은 공화당과 미국의 유대인 단체의 반발을 일으켰다. 그러나 1979년, 양국 간의 평화조약이 백악관에서 이루어졌다.\n",
      "\n",
      "소련과 제2차 전략 무기 제한 협상(SALT II)에 조인했다.\n",
      "\n",
      "카터는 1970년대 후반 당시 대한민국 등 인권 후진국의 국민들의 인권을 지키기 위해 노력했으며, 취임 이후 계속해서 도덕정치를 내세웠다.\n",
      "\n",
      "임기 말, 소련의 아프가니스탄 침공 사건으로 인해 1980년 하계 올림픽에 반공국가들의 보이콧을 하였다.\n",
      "\n",
      "그는 주이란 미국 대사관 인질 사건의 인질 구출 실패로 인한 원인으로, 1980년 제40대 대통령 선거에서 공화당의 로널드 레이건에게 패하며 재선에 실패하였다.\n",
      "\n",
      "대한민국과의 관계\n",
      "\n",
      "지미 카터는 대한민국과의 관계에서도 중요한 영향을 미쳤던 대통령 중 하나다. 인권 문제와 주한미군 철수 문제로 한때 한미 관계가 불편하기도 했다. 1978년 대한민국에 대한 북한의 위협에 대비해 한미연합사를 창설하면서, 1982년까지 3단계에 걸쳐 주한미군을 철수하기로 했다. 그러나 주한미군사령부와 정보기관·의회의 반대에 부딪혀 주한미군은 완전철수 대신 6,000명을 감축하는 데 그쳤다. 또한 박정희 정권의 인권 문제 등과의 논란으로 불협화음을 냈으나, 1979년 6월 하순, 대한민국을 방문하여 관계가 다소 회복되었다.\n",
      "\n",
      "1979년~1980년 대한민국의 정치적 격변기 당시의 대통령이었던 그는 이에 대해 애매한 태도를 보였고, 이는 후에 대한민국 내에서 고조되는 반미 운동의 한 원인이 됐다. 10월 26일, 박정희 대통령이 김재규 중앙정보부장에 의해 살해된 것에 대해 그는 이 사건으로 큰 충격을 받았으며, 사이러스 밴스 국무장관을 조문사절로 파견했다. 12·12 군사 반란과 5.17 쿠데타에 대해 초기에는 강하게 비난했으나, 미국 정부가 신군부를 설득하는데, 한계가 있었고 결국 묵인하는 듯한 태도를 보이게 됐다.\n",
      "\n",
      "퇴임 이후 민간 자원을 적극 활용한 비영리 기구인 카터 재단을 설립한 뒤 민주주의 실현을 위해 제 3세계의 선거 감시 활동 및 기니 벌레에 의한 드라쿤쿠르스 질병 방재를 위해 힘썼다. 미국의 빈곤층 지원 활동, 사랑의 집짓기 운동, 국제 분쟁 중재 등의 활동도 했다.\n",
      "\n",
      "카터는 카터 행정부 이후 미국이 북핵 위기, 코소보 전쟁, 이라크 전쟁과 같이 미국이 군사적 행동을 최후로 선택하는 전통적 사고를 버리고 군사적 행동을 선행하는 행위에 대해 깊은 유감을 표시 하며 미국의 군사적 활동에 강한 반대 입장을 보이고 있다.\n",
      "\n",
      "특히 국제 분쟁 조정을 위해 북한의 김일성, 아이티의 세드라스 장군, 팔레인스타인의 하마스, 보스니아의 세르비아계 정권 같이 미국 정부에 대해 협상을 거부하면서 사태의 위기를 초래한 인물 및 단체를 직접 만나 분쟁의 원인을 근본적으로 해결하기 위해 힘썼다. 이 과정에서 미국 행정부와 갈등을 보이기도 했지만, 전직 대통령의 권한과 재야 유명 인사들의 활약으로 해결해 나갔다.\n",
      "\n",
      "1978년에 채결된 캠프데이비드 협정의 이행이 지지부진 하자 중동 분쟁 분제를 해결하기 위해 1993년 퇴임 후 직접 이스라엘과 팔레인스타인의 오슬로 협정을 이끌어 내는 데도 성공했다.\n",
      "\n",
      "1993년 1차 북핵 위기 당시 북한에 대한 미국의 군사적 행동이 임박했으나, 미국 전직 대통령으로는 처음으로 북한을 방문하고 미국과 북 양국의 중재에 큰 기여를 해 위기를 해결했다는 평가를 받았다. 또한 이 때 김영삼 대통령과 김일성 주석의 만남을 주선했다. 하지만 그로부터 수주일 후 김일성이 갑자기 사망하여 김일성과 김영삼의 정상회담은 이루어지지 못했다.\n",
      "\n",
      "미국의 관타나모 수용소 문제, 세계의 인권문제에서도 관심이 깊어 유엔에 유엔인권고등판무관의 제도를 시행하도록 노력하여 독재자들의 인권 유린에 대해 제약을 하고, 국제형사재판소를 만드는 데 기여하여 독재자들 같은 인권유린범죄자를 재판소로 회부하여 국제적인 처벌을 받게 하는 등 인권 신장에 크나 큰 기여를 했다.\n",
      "\n",
      "2011년 4월 26일부터 29일까지 북한을 3일간 방문했다.\n",
      "\n",
      "경제문제를 해결하지 못하고 주 이란 미국 대사관 인질 사건에 발목이 잡혀 실패한 대통령으로 평가를 받지만 이란 사태는 미국 내 이란 재산을 풀어주겠다는 조건을 내세워서 사실상 카터가 해결한 것이었고, 사랑의 집짓기 운동 등으로 퇴임 후에 훨씬 더 존경받는 미국 대통령 중에 특이한 인물로 남았다.\n",
      "\n",
      "그는 2002년 말 인권과 중재 역할에 대한 공로를 인정받아 노벨 평화상을 받게 되었다.\n",
      "\n",
      "이외에도, 그는 대통령 재임 시절은 물론 퇴임 후에도 지속적으로 여러 장기 집권중인 독재자들을 만나왔는데, 그와 만난 독재자들 중 절대 다수가 얼마 되지 않아 최후를 맞이하게 되며 '독재자의 사신'이라는 별명이 붙기도 했다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "수학\n",
      "\n",
      "수학(數學, , 줄여서 math)은 수, 양, 구조, 공간, 변화 등의 개념을 다루는 학문이다. 널리 받아들여지는 명확한 정의는 없으나 현대 수학은 일반적으로 엄밀한 논리에 근거하여 추상적 대상을 탐구하며, 이는 규칙의 발견과 문제의 제시 및 해결의 과정으로 이루어진다. 수학은 그 발전 과정에 있어서 철학, 과학과 깊은 연관을 맺고 있으며, 다만 엄밀한 논리와 특유의 추상성, 보편성에 의해 다른 학문들과 구별된다. 특히 수학은 과학의 여느 분야들과는 달리 자연계에서 관측되지 않는 개념들에 대해서까지 이론을 추상화시키는 특징을 보이는데, 수학자들은 그러한 개념들에 대한 추측을 제시하고 적절하게 선택된 정의와 공리로부터 엄밀한 연역을 거쳐 그 진위를 파악한다.\n",
      "\n",
      "수학의 개념들은 기원전 600년 경에 활동하며 최초의 수학자로도 여겨지는 탈레스의 기록은 물론, 다른 고대 문명들에서도 찾아볼 수 있으며 인류의 문명과 함께 발전해 왔다. 오늘날 수학은 자연과학, 사회과학, 공학, 의학 등 거의 모든 학문에서도 핵심적인 역할을 하며 다양한 방식으로 응용된다.\n",
      "\n",
      "수학을 의미하는 매스매틱스(mathematics)라는 단어는 '아는 모든 것', '배우는 모든 것'이라는 뜻의 고대 그리스어 'máthēma'(μάθημα) 및 그 활용형 mathēmatikós(μαθηματικός)에서 유래되었다.\n",
      "\n",
      "역사적으로 고대부터 현대에 이르기까지 문명에 필수적인 건축, 천문학, 정치, 상업 등에 수학적 개념들이 응용되어 왔다. 교역·분배·과세 등 인류의 사회 생활에 필요한 모든 계산에 수학이 관여해 왔고, 농경 생활에 필수적인 천문 관측과 달력의 제정, 토지의 측량 또한 수학이 직접적으로 사용된 분야이다. 고대 수학을 크게 발전시킨 문명으로는 이집트, 인도, 중국, 그리스 등이 있다.\n",
      "\n",
      "특히 고대 그리스 문명에서는 처음으로 방정식에서 변수를 문자로 쓰는 등 추상화가 발전하였고 유클리드의 원론에서는 최초로 엄밀한 논증에 근거한 수학이 나타난다. 수학의 발전은 이후로도 계속되어 16세기의 르네상스에 이르러서는 과학적 방법과의 상호 작용을 통해 수학과 자연과학에 있어서 혁명적인 연구들이 진척되었고, 이는 인류 문명 발달에 큰 영향을 미치게 되었다.\n",
      "\n",
      "수학의 각 분야들은 상업에 필요한 계산을 하기 위해, 숫자들의 관계를 이해하기 위해, 토지를 측량하기 위해, 그리고 천문학적 사건들을 예견하기 위해 발전되어왔다. 이 네 가지 목적은 대략적으로 수학이 다루는 대상인 양, 구조, 공간 및 변화에 대응되며, 이들을 다루는 수학의 분야를 각각 산술, 대수학, 기하학, 해석학이라 한다. 또한 이 밖에도 근대 이후에 나타난 수학기초론과 이산수학 및 응용수학 등이 있다.\n",
      "\n",
      "산술은 자연수와 정수 및 이에 대한 사칙연산에 대한 연구로서 시작했다. 수론은 이런 주제들을 보다 깊게 다루는 학문으로, 그 결과로는 페르마의 마지막 정리 등이 유명하다. 또한 쌍둥이 소수 추측과 골드바흐 추측 등을 비롯해 오랜 세월 동안 해결되지 않고 남아있는 문제들도 여럿 있다.\n",
      "\n",
      "수의 체계가 보다 발전하면서, 정수의 집합을 유리수의 집합의 부분집합으로 여기게 되었다. 또한 유리수의 집합은 실수의 집합의 부분집합이며, 이는 또다시 복소수 집합의 일부분으로 볼 수 있다. 여기에서 더 나아가면 사원수와 팔원수 등의 개념을 생각할 수도 있다. 이와는 약간 다른 방향으로, 자연수를 무한대까지 세어나간다는 개념을 형식화하여 순서수의 개념을 얻으며, 집합의 크기 비교를 이용하여 무한대를 다루기 위한 또다른 방법으로는 기수의 개념도 있다.\n",
      "\n",
      "수 대신 문자를 써서 문제해결을 쉽게 하는 것과, 마찬가지로 수학적 법칙을 일반적이고 간명하게 나타내는 것을 포함한다. 고전대수학은 대수방정식 및 연립방정식의 해법에서 시작하여 군, 환, 체 등의 추상대수학을 거쳐 현대에 와서는 대수계의 구조를 보는 것을 중심으로 하는 선형대수학으로 전개되었다. 수의 집합이나 함수와 같은 많은 수학적 대상들은 내재적인 구조를 보인다. 이러한 대상들의 구조적 특성들이 군론, 환론, 체론 그리고 그 외의 수많은 대수적 구조들을 연구하면서 다루어지며, 그것들 하나하나가 내재적 구조를 지닌 수학적 대상이다. 이 분야에서 중요한 개념은 벡터, 벡터 공간으로의 일반화, 그리고 선형대수학에서의 지식들이다. 벡터의 연구에는 산술, 대수, 기하라는 수학의 중요한 세개의 분야가 조합되어 있다. 벡터 미적분학은 여기에 해석학의 영역이 추가된다. 텐서 미적분학은 대칭성과 회전축의 영향 아래에서 벡터의 움직임을 연구한다. 눈금없는 자와 컴퍼스와 관련된 많은 고대의 미해결 문제들이 갈루아 이론을 사용하여 비로소 해결되었다.\n",
      "\n",
      "공간에 대한 연구는 기하학에서 시작되었고, 특히 유클리드 기하학에서 비롯되었다. 삼각법은 공간과 수들을 결합하였고, 잘 알려진 피타고라스의 정리를 포함한다. 현대에 와서 공간에 대한 연구는, 이러한 개념들은 더 높은 차원의 기하학을 다루기 위해 비유클리드 기하학(상대성이론에서 핵심적인 역할을 함)과 위상수학으로 일반화되었다. 수론과 공간에 대한 이해는 모두 해석 기하학, 미분기하학, 대수기하학에 중요한 역할을 한다. 리 군도 공간과 구조, 변화를 다루는데 사용된다. 위상수학은 20세기 수학의 다양한 지류속에서 괄목할만한 성장을 한 분야이며, 푸앵카레 추측과 인간에 의해서 증명되지 못하고 오직 컴퓨터로만 증명된 4색정리를 포함한다.\n",
      "\n",
      "변화에 대한 이해와 묘사는 자연과학에 있어서 일반적인 주제이며, 미적분학은 변화를 탐구하는 강력한 도구로서 발전되었다. 함수는 변화하는 양을 묘사함에 있어서 중추적인 개념으로써 떠오르게 된다. 실수와 실변수로 구성된 함수의 엄밀한 탐구가 실해석학이라는 분야로 알려지게 되었고, 복소수에 대한 이와 같은 탐구 분야는 복소해석학이라고 한다. 함수해석학은 함수의 공간(특히 무한차원)의 탐구에 주목한다. 함수해석학의 많은 응용분야 중 하나가 양자역학이다. 많은 문제들이 자연스럽게 양과 그 양의 변화율의 관계로 귀착되고, 이러한 문제들이 미분방정식으로 다루어진다. 자연의 많은 현상들이 동역학계로 기술될 수 있다. 혼돈 이론은 이러한 예측 불가능한 현상을 탐구하는 데 상당한 기여를 한다.\n",
      "\n",
      "수학의 기초를 확실히 세우기 위해, 수리논리학과 집합론이 발전하였고, 이와 더불어 범주론이 최근에도 발전되고 있다. “근본 위기”라는 말은 대략 1900년에서 1930년 사이에 일어난, 수학의 엄밀한 기초에 대한 탐구를 상징적으로 보여주는 말이다. 수학의 엄밀한 기초에 대한 몇 가지 의견 불일치는 오늘날에도 계속되고 있다. 수학의 기초에 대한 위기는 그 당시 수많은 논쟁에 의해 촉발되었으며, 그 논쟁에는 칸토어의 집합론과 브라우어-힐베르트 논쟁이 포함되었다.\n",
      "\n",
      "오늘날 수학은 자연과학, 공학뿐만 아니라, 경제학 등의 사회과학에서도 중요한 도구로 사용된다. 예를 들어, 정도의 차이는 있으나, 미적분학과 선형대수학은 자연과학과 공학, 경제학을 하는데에 필수적 과목으로 여겨지며, 확률론은 계량경제학에 응용된다. 통계학은 사회과학 이론에 근거를 마련하는데 필수적이다. 16세기에 갈릴레오 갈릴레이가 \"자연이라는 책은 수학이라는 언어로 기록되어 있다.\"는 주장과 함께 물리학에 수학적 방법을 도입하였고, 17세기에 아이작 뉴턴이 고전 역학의 기본 물리학 법칙들을 수학적으로 기술하고 정립하여 물리학 이론에서 수학적 모델링은 필수적 요소가 되었다. 또한 이 시기는 과학적 방법이 정립되는 시기이기도 한데, 많은 과학적 현상들이 수학적 관계가 있음이 드러나면서 과학적 방법에도 수학은 중요한 역할을 하고 있다. 노벨 물리학상 수상자 유진 위그너는 그의 에세이 \"The unreasonable effectiveness of mathematics in natural sciences\"에서 인간 세상과 동떨어져있고 현실과 아무 관련이 없다고 여겨지던 수학 중 극히 일부는 뜻밖에도 자연과학과 연관성이 드러나고 과학이론에 효과적인 토대를 마련해 주는데에 대한 놀라움을 표현하였다. 예를 들어, 비유클리드 기하학과 3차원 이상의 임의의 차원에서 기하학을 탐구했던 미분 기하학은 당시에는 현실과 연관성을 가지지 않았으나 먼 훗날 일반상대성이론이 4차원 기하학을 필요로 함에 따라, 물리적 세상과 연관이 있음이 밝혀졌다. 또한 게이지이론, 양자장론 등에도 미분 기하학은 필수적이다.\n",
      "\n",
      "또한 수학은 음악이나 미술 등 예술과도 관련이 있다. 피타고라스는 두 정수의 비율이 듣기 좋은 소리가 난다는 점을 가지고 피타고라스 음계를 만들었다. 중세시대에도 음악과 수학을 밀접하게 연관시켰으며 성 빅토르의 후고는 “음악은 조화다”라고 했고, 성 트론드의 루돌프는 “음악은 조화의 토대(ratio)다”라고 쓴 바 있다. 조화가 반드시 소리로 표현될 필요는 없고 소리의 음악은 음악의 형식 중 하나에 불과했다. 소리에 대해 다루었던 중세의 저술가들이 있는가 하면, 조화와 비례의 추상적 이론만을 다루고 소리에는 거의 관심을 보이지 않았던 저술가들도 있었다. 청각적인 면과 추상적인 면이라는 음악의 이런 이중적 측면은 고대의 음악이론보다는 중세의 음악이론에서 큰 특징이 되었다. 또한 현대 음악을 군(群,group)같은 수학적 대상을 이용해 분석하기도 한다. 원근법은 사영 기하학에 해당한다. 미술 사조 중 하나인 입체파도 기하학의 영향을 받았다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "수학 상수\n",
      "\n",
      "수학에서 상수란 그 값이 변하지 않는 불변량으로, 변수의 반대말이다. 물리 상수와는 달리, 수학 상수는 물리적 측정과는 상관없이 정의된다.\n",
      "\n",
      "수학 상수는 대개 실수체나 복소수체의 원소이다. 우리가 이야기할 수 있는 상수는 (거의 대부분 계산 가능한) 정의가능한 수이다.\n",
      "\n",
      "특정 수학 상수, 예를 들면 골롬-딕맨 상수, 프랑세즈-로빈슨 상수, formula_1, 레비 상수와 같은 상수는 다른 수학상수 또는 함수와 약한 상관관계 또는 강한 상관관계를 갖는다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "문학\n",
      "\n",
      "문학(文學, )은 언어를 예술적 표현의 제재로 삼아 새로운 의미를 창출하여, 인간과 사회를 진실되게 묘사하는 예술의 하위분야이다. 간단하게 설명하면, 언어를 통해 인간의 삶을 미적(美的)으로 형상화한 것이라고 볼 수 있다. 문학은 원래 문예(文藝)라고 부르는 것이 옳으며, 문학을 학문의 대상으로서 탐구하는 학문의 명칭 역시 문예학이다. 문예학은 음악사학, 미술사학 등과 함께 예술학의 핵심분야로서 인문학의 하위범주에 포함된다.\n",
      "\n",
      "일반적으로 문학의 정의는 텍스트들의 집합이다. 각각의 국가들은 고유한 문학을 가질 수 있으며, 이는 기업이나 철학 조류, 어떤 특정한 역사적 시대도 마찬가지이다. 흔히 한 국가의 문학을 묶어서 분류한다. 예를 들어 고대 그리스어, 성서, 베오울프, 일리아드, 그리고 미국 헌법 등이 그러한 분류의 범주에 들어간다. 좀 더 일반적으로는 문학은 특정한 주제를 가진 이야기, 시, 희곡의 모음이라 할 수 있다. 이 경우, 이야기, 시, 그리고 희곡은 민족주의적인 색채를 띨 수도 아닐 수도 있다. 문학의 한 부분으로서 특정한 아이템을 구분 짓는 일은 매우 어려운 일이다. 어떤 사람들에게 \"문학\"은 어떠한 상징적인 기록의 형태로도 나타날 수 있는 것이다. (이를테면 이미지나 조각, 또는 문자로도 나타날 수 있다.) 그러나 또다른 사람들에게 있어 문학은 오직 문자로 이루어진 텍스트로 구성된 것만을 포함한다. 좀 더 보수적인 사람들은 그 개념이 꼭 물리적인 형태를 가진 텍스트여야 하고, 대개 그러한 형태는 종이 등의 눈에 보이는 매체에서 디지털 미디어까지 다양할 수 있다.\n",
      "\n",
      "더 나아가 보면, \"문학\"과 몇몇 인기있는 기록형태의 작업들, 소위 \"대중문학\" 사이에는 인식가능한 차이점이 존재한다. 이때 \"문학적인 허구성\"과 \"문학적인 재능\"이 종종 개별적인 작품들을 구별하는 데에 사용된다. 예를 들어, 찰스 디킨즈의 작품들은 대부분의 사람들에게 \"문학적인 것\"으로 받아들여지지만, 제프리 아처의 작품들은 영문학이라는 일반적인 범주 아래 두기에는 다소 가치가 떨어지는 것으로 생각된다. 또한 예를 들어 문법과 어법에 서투르거나, 이야기가 혼란스러워 신뢰성을 주지 않거나, 인물들의 성격에 일관성이 없을 경우에도 문학에서 제외될 수 있다. 로맨스, 범죄소설, 과학소설 등의 장르 소설도 때로 \"문학\"이 아닌 것으로 간주되는 경우도 있다. 이들은 대부분 \"대중문학\"의 범주에 포함된다.\n",
      "\n",
      "문학은 분류하는 방법에 따라 다음과 같이 구분한다.\n",
      "\n",
      "이 외에도 편의에 따라 발생적으로 대별하기도 한다.\n",
      "\n",
      "문학은 처음은 유일한 종류, 즉 노래하고, 말하고, 춤춘다는 것이 분화되지 않은 것이었다. 이 춤추는 것을 중심으로 발달한 것이 연극(演劇)이며, 노래하는 것이 발달하여 시(詩), 말하는 것이 발달하여 산문(散文)의 이야기가 되었다. 시는 정형시·자유시·산문시로, 또한 서사시와 서정시로 나뉜다. 산문은 사건을 중심으로 그려진 이야기, 근대 리얼리즘의 수법 이후 인물의 성격을 묘사하는 것을 중심으로 한 소설이 있다. 이야기나 소설과 같이 특별한 구상에 의하지 않고, 작자의 흥미에 의해서 씌어지는 것이 잡문(雜文) 또는 수필이며, 이것이 날짜에 따라 씌어지는 것이 일기, 여행의 과정에 따라 씌어지는 것이 기행문이다. 일기와 마찬가지로 발표의 의도가 작은 것에 서간(書簡)이 있다. 이 밖에 사건의 경험에 따른 회고록, 사건 등의 특정시(特定時)에 한정되지 않는 자서전, 제삼자에 의해서 씌어지는 전기(傳記)가 있다. 또한 이것들을 포함하는 예술작품의 가치평가를 시도하는 것이 평론(評論)이다.\n",
      "\n",
      "대중문학이란 상업성을 띠며 대중을 겨냥하여 그들의 통속적인 흥미와 욕구를 채워주는 문학을 말한다. 대중문학의 하위장르에는 여러가지가 있다.\n",
      "\n",
      "문학을 창작하는 예술가를 문예가라고 부른다. 문예학을 연구하는 사람을 문예학자라고 부른다. 문학을 창작하는 사람을 따로 저술가라고 한다. 문예학자와 언어학자를 합쳐 어문학자로 칭하기도 한다. 그러나 언어와 언어를 사용한 예술인 문학은 차이가 있다.\n",
      "\n",
      "반영론적 관점에 의한 감상은 작품을 창작된 당시 시대 정황과 연결시켜 감상하는 입장이고, 내재적 관점의 감상은 작품의 형식, 내용에 국한하여 감상하는 것이다. 표현론적 관점의 감상은 작가의 전기적 사실과 작품을 연결시켜 감상하는 것이고, 수용론적 관점의 감상은 독자와 작품을 연결시켜 감상하는 것을 말한다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "나라 목록\n",
      "\n",
      "이 목록에 실린 국가 기준은 1933년 몬테비데오 협약 1장을 참고로 하였다. 협정에 따르면, 국가는 다음의 조건을 만족해야 한다.\n",
      "\n",
      "특히, 마지막 조건은 국제 공동체의 참여 용인을 내포하고 있기 때문에, 다른 나라의 승인이 매우 중요한 역할을 할 수 있다. 이 목록에 포함된 모든 국가는 보통 이 기준을 만족하는 것으로 보이는 자주적이고 독립적인 국가이다. 하지만 몬테비데오 협약 기준을 만족하는지의 여부는 많은 국가가 논쟁이 되고 있는 실정이다. 또한, 몬테비데오 협약 기준만이 국가 지위의 충분한 자격이든 아니든, 국제법의 견해 차이는 존재할 수 있다. 이 물음에 대한 다른 이론에 대한 고리는 아래에서 볼 수 있다.\n",
      "\n",
      "위 기준에 논거하여 이 목록은 다음 206개 국가를 포함하고 있다.\n",
      "\n",
      "다음 국가는 몬테비데오 협약의 모든 조건을 만족하지 못하거나, 자주적이고 독립적임을 주장하지 않는 국가이다.\n",
      "\n",
      "이 목록은 주권을 주장하고 점유한 영토를 실제로 관리하고 있으나, 많은 국가와 외교관계를 맺지 못한 나라를 설명하고 있다. 극소형 국가는 이 목록에 포함하지 않는다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "화학\n",
      "\n",
      "화학(化學)은 물질의 성질, 조성, 구조, 변화 및 그에 수반하는 에너지의 변화를 연구하는 자연과학(自然科學)의 한 분야이다. 물리학(物理學)도 역시 물질을 다루는 학문이지만, 물리학이 원소(元素)와 화합물(化合物)을 모두 포함한 물체의 운동과 에너지, 열적·전기적·광학적·기계적 속성을 다루고 이러한 현상으로부터 통일된 이론을 구축하려는 것과는 달리 화학에서는 물질 자체를 연구 대상으로 한다. 화학은 이미 존재하는 물질을 이용하여 특정한 목적에 맞는 새로운 물질을 합성하는 길을 제공하며, 이는 농작물(農作物)의 증산, 질병의 치료 및 예방, 에너지 효율 증대, 환경오염(環境汚染) 감소 등 여러 가지 이점을 제공한다.\n",
      "\n",
      "화학은 연금술사들이 물질을 섞으며 발전시켰기 때문에 화학을 뜻하는 영어 ‘케미스트리(chemistry)’는 연금술을 뜻하는 단어 ‘알케미(alchemy)’에서 비롯하였다. 이는 다시 아랍어 ‘알 키미야(, al-kīmiyāʾ)’에서 왔는데, 이 단어의 어원에 대해서는 여러 가지 설이 있다.\n",
      "\n",
      "‘화학(化學)’이란 단어는 물질의 변화를 다루는 학문이라는 점에 착안한 번역어이다. 이 번역어는 의 《항해술기(航海述奇)》(1866), 의 자연과학 교과서 《격물입문(格物入門)》(1866) 등에서 처음 쓰였다.\n",
      "\n",
      "고대 화학(古代化學)\n",
      "\n",
      "<nowiki>*</nowiki>\"초기 야금 (冶金, 야금: 금속을 광석으로부터 추출하고 정련하는 기술)\"\n",
      "\n",
      "인간에 의해 발견된 최초의 기록된 금속은 금(金)인 것으로 보이며 구석기(舊石器) 후기(BC 40,000)에 스페인 동굴에서 소량의 천연 금이 발견되었다고 한다.\n",
      "\n",
      "은(銀), 구리(銅), 주석(朱錫) 및 유성 철(鐵) 또한 고대 문화에서 일부 제한된 양의 금속 가공을 허용하면서 고대문화로 발견 될 수 있었다. 기원전 3000년경 유성 철제로 만든 이집트 무기는 \"천국의 단검(天國短劍)\"으로 높이 평가 받았다.\n",
      "\n",
      "아마도 통제 된 방식으로 사용된 최초의 화학 반응은 불이였다. 그러나 천년 동안 불은 단순히 열과 빛을 생성하면서 한 물질을 다른 물질 (타는 나무 또는 끓는 물)로 변형시킬 수있는 신비한 힘으로만 알려졌다. 불은 초기 사회의 여러 측면에 영향을 미쳤다. 이들은 요리 및 서식지(棲息地) 조명과 같은 일상 생활의 가장 단순한면에서 도기, 벽돌 및 금속을 녹여 도구를 만드는 것과 같은 고급 기술(高級技術)에 이르기까지 다양했다.\n",
      "\n",
      "유리(琉璃)의 발견과 금속(金屬)의 정화로 이어지는 불로 인해 야금이 부상했다. 야금의 초기 단계에서 금속의 정화 방법이 요구되었고, 금은 BC 2900년 초기의 고대 이집트의 귀중한 금속이되었다.\n",
      "\n",
      "17 세기와 18 세기 : 초기 화학(初期化學)\n",
      "\n",
      "\"<nowiki>*</nowiki>로버트 보일\"\n",
      "\n",
      "영국계 미국인 화학자(化學者) 로버트 보일 (Robert Boyle, 1627-1691)은 연금술(鍊金術)에 대한 현대의 과학적 방법을 정제하고 화학을 연금술과 분리한 것으로 생각된다. 그의 연구가 연금술 전통에 뿌리를 두고 있음에도 불구하고, 보일은 오늘날 현대의 화학자이자 현대화학(現代化學)의 창시자이자 현대 실험 과학 방법의 선구자(先驅者) 중 한 사람으로 불리고 있다. 보일이 원래 발견자가 아님에도 보일은 1662년에 제시한 보일의 법칙으로 가장 잘 알려져있다. 보일의 (法則)은 온도(溫度)만 폐쇄(閉鎖)된 시스템 내에서 일정하게 유지된다면 가스의 절대 압력과 부피가 반비례함을 의미한다. 보일은 또한 화학 분야의 초석으로 간주되는 1661년의 《의심 많은 화학자》 에 대한 획기적인 저서로 인정받고 있다. 작품에서 보일은 모든 현상이 움직이는 입자의 충돌의 결과라는 가설을 제시한다. 보일 (Boyle)은 화학자들에게 실험을 호소했으며 실험은 지구, 화염, 공기 및 물과 같은 고전적인 4 가지 원소만으로 화학 원소를 제한한다는 것을 부인했다. 그는 또한 화학이 의학이나 연금술에 종속되어 과학의 지위로 부상하는 것을 중단해야 한다고 촉구했다. 중요한 것은 과학 실험에 대한 엄격한 접근 방식이라고 주장했다. 그는 모든 이론이 사실로 간주되기 전에 실험적으로 입증되어야 한다고 믿었다. 이 작품은 원자, 분자 및 화학 반응의 가장 초기의 현대적인 아이디어를 포함하고 있으며 현대 화학의 역사의 시작을 나타낸다. 보일은 또한 화학 물질을 정제하여 재현 가능한 반응을 얻으려고 시도했다. 그는 재료 물질의 물리적 특성(物理的特性)과 상호 작용(相互作用)을 설명하고 정량화(定量化)하기 위해 르네 데카르트가 제안한 기계 철학(機械哲學)의 공개적인 지지자였다. 보일은 원자핵론자(原子核論者)였지만 원자보다 더 많은 입자를 선호했다. 그는 속성이 유지되는 물질의 가장 정밀한 부분은 미립자(微粒子)의 수준에 있다고 논평했다. 그는 또한 공기 펌프로 수 많은 조사를 수행했으며, 공기가 펌프로 퍼져 나감에 따라 수은이 떨어지는 것으로 나타났다. 그는 또한 컨테이너에서 공기를 펌핑하면 화염을 없애고 내부에 있는 작은 동물을 죽일 수 있음을 관찰했다.\n",
      "\n",
      "과거 화학에서 더 이상 나뉘지 않는 기초적인 요소가 존재한다고 했는데, 이 기초적인 요소를 원자(原子)라 한다. 원자란 물질을 구성하는 기본적인 입자(粒子)로 고대 그리스의 데모크리토스에서부터 그 존재가 주장되었는데, 1803년 존 돌턴에 의해서 원자론(原子論)으로 정리되었다. 20세기 초, 화학자들은 원자를 구성하는 더 작은 입자들, 즉 전자(電子), 양성자(陽性子), 중성자(中性子)가 존재한다는 사실을 발견하였다. 전자는 음전하를 띠고 있고, 양성자는 양전하를 띠고 있으며, 중성자는 전하를 띠지 않고 있다. 원자는 양성자와 중성자로 구성되어 있는 원자핵(原子核)을 가지고 있으며 전자는 이 주변에 원자 궤도(原子軌道)을 이루며 분포되어 있다.\n",
      "\n",
      "원소(元素)는 일반적인 화학적, 물리학적 방법으로는 분해되지 않는 물질을 의미한다. 원소는 원자핵에 존재하는 양성자 수로 정의되는 원자 번호(原子番號)로 구별된다. 산소(酸素), 황(黃), 주석(朱錫), 철(鐵) 등은 원소이다. 19세기 중엽까지 약 80가지의 원소가 발견되었는데, 이들은 주기율(週期律)에 따라 배열(配列)될 수 있다.\n",
      "\n",
      "동위원소(同位元素)는 아이소토프 또는 동위체(同位體)라고도 한다. 서로 화학적으로는 거의 구별하지 못하지만 그것을 구성하고 있는 원자(原子)의 질량(質量)이 서로 다른 원소를 동위원소라고 한다. 영어의 isotope는 그리스어인 isos(같은)와 topos(장소)의 합성어(合成語)인데, 질량은 서로 달라도 원소의 주기율표(週期律表)에서 같은 장소에 배열되는 데서 1901년 영국의 화학자 F. 소디가 isotope라는 명칭을 붙였다. 대부분의 원소는 동위 원소를 가진다. 동위 원소는 원자 번호는 같으나, 중성자수가 다른 원소를 뜻한다. 동위 원소는 화학적인 성질(化學的性質)은 동일하나, 원자량의 차이를 이용하여 분리할 수 있다. 자연에서도 발견되는 92개의 원소 중 88개는 동위 원소가 지표면 상에 존재한다. 자연에서 발견되지 않더라도 동위 원소는 핵반응(核反應)을 이용하여 만들어낼 수 있다. 어떤 동위 원소는 방사능을 가지기도 하는데, 이 경우 동위 원소의 원자핵은 불안정하고 방사선(放射線)을 방출하며 자연적으로 붕괴된다.\n",
      "\n",
      "동중 원소(同重元素)는 원자 질량(原子質量)은 같으나, 양성자수(陽性子數)가 다른 원소를 뜻한다. 동중 원소는 화학적, 물리적 성질이 다르며 S, Cl, Ar, K, Ca등이 있다.\n",
      "\n",
      "분자(分子)란 원자의 결합체(結合體) 중 독립 입자(獨立粒子)로서 작용하는 단위체(單位體)이다. 일정한 개수의 원자가 특정하게 정렬되어 서로 결합해 분자가 형성된다. 원자가 원소(元素)의 최소단위(最小單位)이듯, 분자(分子)는 화합물(化合物)의 최소단위가 된다. 원자가 결합(結合)될 때 전자의 재배치(再配置)가 일어나는데, 이는 화학에서의 중요한 관심사중 하나이다.\n",
      "\n",
      "화학 반응은 원자 혹은 분자가 화학적인 변화를 겪는 일을 말한다. 화학 반응은 원자간의 결합이 끊어지는 일과 다시 이어지는 일을 포함한다. 결합이 끊어질 때는 에너지가 흡수되고, 결합이 이어질 때는 에너지가 방출된다. 화학 반응의 간단한 예로는 수소와 산소가 반응하여 물이 되는 것을 들 수 있다. 반응식(反應式)은 다음과 같다.\n",
      "\n",
      "반응식(反應式)에서 알 수 있듯이, 화학 반응에서는 원자가 새로 생성되거나 나타나는 일이 일어나지 않는다. ΔH는 에너지 또는 엔탈피 변화를 뜻한다. 반응은 발열반응(發熱反應)일 수도 있고, 흡열반응(吸熱反應)일 수도 있다. 발열반응은 주위로 열을 방출(放出)하는 반응으로 엔탈피 변화가 음수(陰數)로 나타난다. 반면에 흡열반응은 주위 열을 흡수하는 반응으로 엔탈피 변화가 양수(陽數)로 나타난다. 위 반응의 경우는 발열반응인데, 이는 계(界)로부터 주위(周圍)로 열이 이동(移動)하였다는 의미이다.\n",
      "\n",
      "화학 결합(化學結合)을 주된 세 가지 부류로 나누어보면 이온 결합(ion結合), 공유 결합(共有結合) 그리고 금속결합(金屬結合)으로 나눌 수 있다. 이온이란 전하(電荷)를 띤 원자 또는 분자를 뜻한다. 이온 결합은 양전하(陽電荷)와 음전하(陰電荷)의 전기적인 인력(電氣的引力)에 의해서 생성되는 화학 결합이다. 예를 들면 염화 나트륨은 양전하를 띤 나트륨 이온(Na)과 음전하를 띤 염화 이온(Cl) 사이의 전기적인 결합으로 이루어진 이온 화합물(化合物)이다. 이러한 물질을 물에 녹이면 이온은 물 분자에 의해 수화되고 이렇게 해서 만들어진 수용액(水溶液)은 전기전도도(電氣傳導度)를 가진다.\n",
      "\n",
      "공유 결합(共有結合)은 원자 궤도(原子軌道)이 겹쳐진 결과 두 원자가 전자쌍(電子雙)을 공유하게 되어 생성되는 결합을 의미한다. 공유 결합이 형성되는 결합은 발열반응(發熱反應)인데, 이때 방출되는 에너지의 양이 그 결합의 결합 에너지이다. 결합 에너지만큼의 에너지를 그 결합에 가해주면 결합은 끊어질 수 있다.\n",
      "\n",
      "금속 결합(金屬結合)은 금속 원자에서 전자(電子)들이 떨어져 나와 자유전자(自由電子)를 생성하게 되어 생성되는 결합을 의미한다. 금속의 특성인 연성(延性)과 전성(轉成)이 생성되는 이유이기도 하다.\n",
      "\n",
      "화합물(化合物)은 구성하고 있는 원자의 종류, 수, 배치에 의해서 그 특성이 결정된다. 자연에서 찾을 수 있거나 인공적으로 합성(合成)할 수 있는 화합물의 수는 엄청나고, 이들 중 대부분은 유기 화합물(有機化合物)이다. 유기 화합물을 이루는 주된 화학 원소(化學元素)인 탄소(炭素)는 다른 화학 원소와는 다르게 매우 긴 사슬 형태로 정렬될 수 있으며, 같은 수많은 이성질체(異性質體)를 형성할 수 있다. 예를 들어, 분자식(分子式) CHO는 약 천 개의 서로 다른 화합물을 뜻할 수 있다.\n",
      "\n",
      "화학은 취급 대상(取扱對象) 및 대상의 취급 방법에 따라서 몇 가지 분과(分科)로 구분될 수 있다. 물질을 분석하는 분석화학(分析化學)은 크게 물질의 존재를 취급하는 정성 분석과 물질의 양을 결정하는 정량 분석으로 나눌 수 있다. 탄소를 포함한 유기 화합물(有機化合物)을 다루는 유기화학(有機化學)과 유기 화합물을 제외한 무기 화합물(無機化合物)을 다루는 무기화학(無機化學)도 있다. 물리학(物理學)과 화학의 경계에는 물리화학(物理化學)이 있고 생물학(生物學)과의 경계에는 생화학(生化學)이 있다. 물리화학에서 특히 분자의 구조와 성질과의 관계를 다루는 부분을 구조화학(構造化學)이라고 부르기도 한다. 제2차 세계 대전(第2次世界大戰) 이후에는 방사성 물질을 다루는 방사화학(放射化學)이 발전하였고 화학 공업을 다루는 공업화학(工業化學)도 있다. 이 외에도 화학의 분과는 매우 다양하다.\n",
      "\n",
      "화학의 분과는 전통적으로 다음과 같은 5가지로 나눌 수 있으며, 각각의 분과는 더욱 세분화될 수 있다.\n",
      "\n",
      "무기화학(無機化學)은 유기화학에서 다루지 않는 물질을 다루며 주로 금속이나 준금속(準金屬)이 포함된 물질에 대해서 연구한다. 따라서 무기화학에서는 매우 넓은 범위의 화합물을 다루게 된다. 초기에는 광물(鑛物)의 구성이나 새 원소의 발견이 주요 관심사였고 여기서부터 지구화학(地球化學)이 분기되었다. 주로 전이 금속(轉移金屬) 등을 이용한 촉매(觸媒)나 생물에서 산소 수송(酸素輸送), 광합성(光合成), 질소 고정(窒素固定) 등의 과정에서 중요한 역할을 하는 금속 원자들에 대해 연구하며 이 외에도 세라믹, 복합재료(複合材料), 초전도체(超傳導體)등에 대한 연구를 한다.\n",
      "\n",
      "물리화학(物理化學)은 화학적 현상(化學的現象)에 대한 해석과 이를 설명하기 위한 물리적 원리들에 대해 다루는 분과이다. 화학반응(化學反應)에 관련된 열역학적 원리와 물질의 물리학적 성질에 대한 설명은 물리화학이 다루는 고전적인 주제이다. 물리화학은 양자화학(量子化學)의 발전에도 큰 기여를 하였다. 분광계(分光計)나 자기 공명(磁氣共鳴), 회절(回折) 기기 등 물리화학에서 사용하는 실험 장비나 실험 방법(實驗裝備)들은 다른 화학의 분과에서도 매우 많이 사용된다. 물리화학이 다루는 대상은 유기 화합물, 무기 화합물, 혼합물(混合物)을 모두 포함한다.\n",
      "\n",
      "분석화학(分析化學)은 물질의 조성이나 혼합물(混合物)의 구성요소(構成要素) 등을 결정하는 방법에 대해서 연구하는 화학의 분과이다. 혼합물을 이루고 있는 성분의 탐색(探索), 분리(分離), 정량(定量)과 분자를 이루고 있는 원자의 비율을 측정하여 분자식을 결정하는 일 등이 분석화학에서 행해진다. 1950년대의 분석화학의 발전은 많은 질량 분석기를 포함한 분석 기구의 등장을 불러일으켰다. 이 외에도 고해상도(高解像度) 크로마토그래피, 전기화학(電氣化學)에서의 많은 실험방법(實驗方法) 등은 분석화학에 있어서 중요한 분석법이다. 분석화학에 있어서 최종 목표는 더 정확한 측정법(測定法)이나 측정기기(測定機器) 등을 개발하는 것이다. 분석화학의 발전으로 인해 환경오염 물질(環境汚染物質) 등을 피코그램의 수준에서도 감지하는 것이 가능해졌다.\n",
      "\n",
      "생화학(生化學)에서는 이와 같이 생물체에서 기능하는 물질들을 다룬다.화학의 관점(觀點)에서 다루는 학문이다. 식물(植物)이나 동물(動物)의 세포(細胞)에서 발견되는 물질이나 일어나는 화학 반응들이 주 관심사이다. 생명체(生命體)에서 발견되는 탄수화물(炭水化物), 지방(脂肪), 단백질(蛋白質), 핵산(核酸), 호르몬 등은 유기 화합물이라서 유기화학에서도 다루어지기도 하나, 이들 화합물에 관련된 물질대사(物質代謝) 과정이나 조절 과정에 대한 연구는 생화학의 고유 분야이다. 효소(酵素)와 조효소(助酵素), 그리고 이들의 작용 과정에 대해서도 연구하며, 세포막(細胞膜)을 통과하는 이온과 분자, 신경전달물질(神經傳達物質)과 다른 조절 물질들의 작용에 대해서도 연구한다. 생화학은 내분비학(內分泌學), 유전학(遺傳學), 면역학(免疫學), 바이러스학의 발전에 큰 영향을 끼쳤다.\n",
      "\n",
      "유기화학(有機化學)은 탄소(炭素)로 이루어진 화합물(化合物)을 연구하는 분과이다. 원래 유기 화합물은 식물이나 동물로부터 추출해낸 화합물을 뜻하였으나 지금은 유기 화합물의 범위가 크게 넓어져 탄소 사슬 또는 탄소 고리를 가진 모든 화합물을 뜻한다. 유기화학의 오랜 관심사는 유기 화합물의 합성 메커니즘이다. 현대에 들어서 핵자기 공명법(核磁氣共鳴法)과 X선 결정학(X線結晶學) 등이 개발되어 유기 화합물 분석에 있어서 매우 중요한 방법으로 자리잡았다. 플라스틱, 합성섬유(合成纖維)등의 고분자물질(高分子物質) 등도 유기화학에서 다루어진다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "체첸 공화국\n",
      "\n",
      "체첸 공화국(, , ), 또는 줄여서 체첸(, , )은 연방국가인 러시아를 이루는 러시아의 공화국이다. 북캅카스 지역에 위치하여 있으며, 인구 다수는 체첸인으로 구성되어 있다.\n",
      "\n",
      "거의 대부분이 체첸인이다. 일부는 러시아인, 인구시인과 기타 북코카서스계 민족도 섞여있다. 체첸에서는 체첸인들의 토착 언어인 체첸어와 러시아어가 모두 사용된다. 체첸어는 캅카스 제어 중 북동 캅카스어족으로 불리는 그룹에 속하는데 인근의 인구시인들이 쓰는 인구시어와 밀접한 관계에 있다.\n",
      "\n",
      "1989년에 행해진 체첸-인구시 자치공화국의 통계에서는 체첸인이 956,879명, 인구시인이 237,438명으로, 269,000명의 러시아인은 인구의 약 23%로 상당한 수의 소수 민족이 있었다. 그 후 서부가 인구시 공화국으로 분리되었기 때문에 인구시인들의 수가 절반 가까이 감소하고, 내전과 사회불안, 민족 대립으로 거의 대부분의 러시아인은 체첸 공화국에서 떠나며 현재 체첸인이 인구 대다수를 차지하게 된 것이다. 1990년대 기준 체첸 공화국에 남아 있던 러시아인은 약 6만 명이었다.\n",
      "\n",
      "체첸 공화국은 일반적으로 러시아 연방 중에서도 젊은 층이 가장 많은 인구 구성을 가진다. 1990년대에는 몇몇 지방에서 인구증가가 있었다.\n",
      "\n",
      "16세기에서 19세기를 기점으로 다게스탄 지역을 통해 이슬람교가 전해져, 체첸인들은 절대다수가 수니파 이슬람교를 믿는데 러시아 정교회 신자도 소수 존재한다.\n",
      "\n",
      "크게 체첸인과 인구시인으로 구분되는 바이나흐족은 오래 전부터 캅카스 지역에 거주하던 토착 민족으로, 그 기원에 관해서는 다양한 학설이 있으나 다게스탄의 민족들과 언어가 가깝다는 것 외에 확실히 밝혀진 바가 없다.\n",
      "\n",
      "중세에 몽골 제국의 침략으로 이들이 속해있던 알라니야 연맹체는 크게 파괴되었으나 일부 부족들은 계속해서 저항하였는데 그 중에 체첸인들이 있었다. 이후 저지대의 일부 부족들은 몽골 제국에 복속하였으나 다른 체첸 부족들은 고지대에서 성과 벽을 쌓고 농성하며 끝까지 침략에 저항하였다. 티무르와 토흐타미시 등 몽골-타타르 세력과의 빈번한 충돌은 15세기까지도 이어졌다. 러시아와의 접촉은 16세기에 시작되었으며 17세기에는 카바르디인과 아바르인의 침략에 대항하였는데 이 시기에 이슬람교로의 대대적인 개종이 이루어졌다.\n",
      "\n",
      "1722년에서 1723년 표트르 1세가 카스피해와 캅카스 지역의 지배권을 확립하기 위해 페르시아와 전쟁을 일으켰고, 이때 캅카스와 다게스탄 지역을 점령하게 되면서 체첸인들과 본격적인 충돌이 시작되었다. 1830년에서 1859년에 이르는 동안, 러시아 제국은 오스만 제국과의 접경지역 안보를 이유로 체첸에 진주했고, 캅카스 전쟁이 일어나 체첸인은 주변 민족들과 함께 이에 맞서싸웠으나 1859년 러시아군에 항복하며 완전히 병합되었다.\n",
      "\n",
      "1917년 러시아의 혼란기에 인근 민족들과 함께 북캅카스 산악공화국을 선포하였으나 1921년 소련에 의해 병합되었고, 이후 체첸인과 인구시인의 자치 정부인 체첸-인구시 자치 소비에트 사회주의 공화국이 수립되었다. 제2차 세계 대전 말기인 1944년 스탈린은 체첸인들이 전쟁 중에 나치군과 협력하여 반란을 꾀했다는 구실을 들어 체첸과 인구셰티야 국민 전체에게 중앙아시아로의 강제이주를 명령했다. 그러나 전쟁과 강제이주를 거치며 바이나흐족 인구는 수십만 명이 사망하였다. 스탈린이 사망한지 4년이 지난 1956년에 이르러서야 흐루쇼프의 탈스탈린 정책 하에 이들의 귀환이 허용되었다. 그러나 체첸-인구시 공화국의 영토가 변화하였을 뿐 아니라 이들의 버려진 고향에 러시아인들이 들어와 살면서 민족구성도 상당히 달라졌다.\n",
      "\n",
      "소련 붕괴 이후 체첸인들의 분리주의 운동이 벌어져 조하르 두다예프를 지도자로 하여 이치케리야 체첸 공화국이 수립되었다. 제1차 체첸 전쟁에서 분리주의 반군이 승리하며 사실상 독립을 얻었으나 전쟁의 여파로 치안이 악화되고 심각한 경제난과 난민 문제가 발생하여 사회 혼란이 이어졌으며 여러 군벌 조직이 난립하였다. 대선을 거쳐 아슬란 마스하도프 대통령이 취임하였으나 이러한 내부적 혼란을 잠재우지 못하였다. 1999년 통제를 벗어난 샤밀 바사예프 치하 이슬람주의 군벌이 다게스탄을 침공하고 곧 모스크바 등지에서 일어난 러시아 아파트 폭탄 테러의 사건의 배후로 체첸 세력이 지목되면서 다시 러시아가 체첸을 침공, 제2차 체첸 전쟁이 벌어졌다. 이 때 블라디미르 푸틴 대통령의 강경 대응 명령 하에 러시아군의 엄청난 공세로 체첸 전역은 초토화되었으며, 2000년 그로즈니가 함락되고 반군은 산악 지대로 패퇴하였다.\n",
      "\n",
      "이치케리야 정부가 무너진 이후에도 반군의 러시아군에 대한 공격과 테러 공격이 계속되었다. 2002년 10월에는 수십 명의 체첸 반군이 모스크바 극장 인질극을 일으켰고, 진압 과정에서 러시아 특수부대가 살포한 독가스 등으로 117명의 민간인이 사망하는 결과를 내었다. 2003년 러시아는 친러 정권을 수립하고 체첸을 안정화시키기 위해 친러파 군벌을 이끌던 아흐마트 카디로프를 정부수반으로 하여 러시아 연방 소속의 체첸 공화국을 수립시켰다.\n",
      "\n",
      "2004년 9월 분리주의 반군이 북오세티야 베슬란의 한 학교를 점령하고 777명의 아동을 포함한 1100명을 인질로 삼은 채 체첸의 독립 승인과 러시아군 철수를 요구하며 농성을 벌인 베슬란 학교 인질사건이 발생하였다. 이는 3일 동안 이어져 최소 331명의 사망자를 내었으며 그 중 과반수가 어린이였다. 이후 푸틴은 반군에 대한 완전한 소탕을 명령하였고 2005년 아슬란 마스하도프, 2006년 샤밀 바사예프가 암살당하며 점차 반군은 세력이 와해되어 갔다.\n",
      "\n",
      "2007년부터 아흐마트 카디로프의 아들로서 마찬가지 친러 군벌 출신인 람잔 카디로프가 2대 대통령으로 취임하였다. 카디로프 정부 하의 체첸은 연방으로부터 연 수백억 루블에 달하는 원조금을 받으며 빠른 정치적 안정과 경제 발전을 이루었으나, 한편으로 인권 탄압과 독재정치가 강화되었다.\n",
      "\n",
      "2009년 러시아 정부는 반테러 작전의 종결을 선포하고 군대를 철수하였다. 이후로도 이슬람 지하드주의 무장단체들에 의한 북캅카스 반란이 발생하였으나 2013년 지도자 도카 우마로프가 사살당하고 2017년 사실상 진압되었다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "맥스웰 방정식\n",
      "\n",
      "맥스웰 방정식(-方程式, s)은 전기와 자기의 발생, 전기장과 자기장, 전하 밀도와 전류 밀도의 형성을 나타내는 4개의 편미분 방정식이다. 맥스웰 방정식은 빛 역시 전자기파의 하나임을 보여준다. 각각의 방정식은 가우스 법칙, 가우스 자기 법칙, 패러데이 전자기 유도 법칙, 앙페르 회로 법칙으로 불린다. 각각의 방정식을 제임스 클러크 맥스웰이 종합한 이후 맥스웰 방정식으로 불리게 되었다.\n",
      "\n",
      "전자기역학은 맥스웰 방정식과 로런츠 힘 법칙으로 요약된다. 로랜츠 힘은 맥스웰 방정식으로부터 유도될 수 있다.\n",
      "\n",
      "맥스웰의 방정식은 네 개의 법칙을 모아 종합하여 구성한 것이다. 맥스웰의 방정식은 빛과 같은 전자기파의 특성을 설명한다. 각 방정식의 수학적 표현은 공식 부분에서 다루기로 하고 우선은 방정식의 의미를 살펴보면 다음과 같다.\n",
      "\n",
      "맥스웰의 방정식에 나타난 각 식은 오랜 시간에 걸쳐 연구된 전기와 자기의 특성을 종합한 것이다. 인류는 고대 시대부터 이미 정전기에 의한 인력과 방전 현상을 알고 있었고 자석의 특징을 이용한 나침반을 만들어 사용해 왔다. 근대에 이르러 전기와 자기에 대한 많은 연구가 진행되었으며 그 결과 쿨롱 법칙, 패러데이 전자기 유도 법칙, 앙페르 회로 법칙과 같은 법칙들이 발견되었다. 맥스웰은 이러한 기존의 연구 성과를 종합하여 전기와 자기가 하나의 상호작용, 즉 전자기력에 의한 것임을 증명하면서 빛역시 전자기파라는 것을 밝혔고, 전자기 복사의 발견을 예언하였다.\n",
      "\n",
      "앞서 밝힌 바와 같이 두 전하 사이에 인력과 척력이 작용한다는 것은 고대 이후 잘 알려진 사실이었다. 그러나 이렇게 두 전하 사이에 작용하는 힘의 관계와 크기는 측정하기 매우 어려웠는데, 그 까닭은 작용하는 힘의 크기가 매우 작기 때문이었다. 1784년 샤를 드 쿨롱은 비틀림 저울을 이용한 실험장치를 고안하여 대전된 두 전하 사이에 작용하는 힘의 크기를 측정할 수 있었다.\n",
      "\n",
      "샤를 드 쿨롱은 금속공과 비틀림 저울을 이용하여 두 점전하 사이에 작용하는 힘을 측정하고, 두 전하 사이에서 작용하는 힘은 두전하 크기의 곱에 비례하고 거리의 제곱에 반비례한다는 쿨롱 법칙을 발견하였다.\n",
      "\n",
      "쿨롱 법칙을 식으로 나타내면 다음과 같다.\n",
      "\n",
      "한편, 쿨롱 힘은 전하 사이의 작용뿐만 아니라 자계에도 적용될 수 있다. 두 자극의 세기를 각각 m, m라 할 때, 이 두 자극 사이에 작용하는 힘은 다음과 같이 정리된다.\n",
      "\n",
      "자극의 세기 단위는 웨버(Wb)로 쿨롱은 세기가 같은 두 개의 자극을 1m 떨어뜨려 놓았을 때 작용하는 힘의 세기가 formula_5인 경우를 1Wb로 정의했다. 따라서 상수 k의 값은 다음과 같다.\n",
      "\n",
      "자극 사이에 작용하는 힘의 크기는 전하 사이에 작용하는 힘의 크기와 같은 방식으로 계산할 수 있으나 둘 사이에는 분명한 차이가 있다. 즉, 전하는 양전하이든 음전하이든 단독으로 존재할 수 있는 데 반해 자극은 홀극으로 존재할 수 없고, N극과 S극이 언제나 쌍으로 존재하여야 한다는 것이다.\n",
      "\n",
      "제임스 클러크 맥스웰은 각각 독립적으로 다루어져 오던 전기와 자기의 법칙들을 종합하여 맥스웰 방정식을 수립하였다. 맥스웰은 마이클 패러데이의 \"역선\"(力線) 개념과 앙드레마리 앙페르의 회로 이론을 근간으로 방정식을 정리하였다.\n",
      "\n",
      "1861년 맥스웰은 논문 《물리적인 역선에 대해》를 발표하여 모두 4개의 방정식으로 구성된 맥스웰 방정식을 소개하였다. 이 방정식은 1865년 발표된 논문 《전자기장의 역학 이론》과 1873년 출간된 《전기와 자기에 관한 논문집》제2권의 9장에서 다시 소개되었다.\n",
      "\n",
      "물리학자 리처드 파인먼은 \"이 방정식에 비하면 남북전쟁조차 큰 의미없는 지엽적인 사건이라고 할 수 있다\"라고 맥스웰 방정식의 중요성을 강조하였다.\n",
      "\n",
      "1865년 맥스웰 자신에 의해 발표된 맥스웰 방정식의 원래 형태는 8개의 방정식으로 이루어진 것이었다. 그러나, 오늘날에는 1884년 올리버 헤비사이드가 4개의 방정식으로 정리한 형태가 일반적으로 사용된다. 조사이어 윌러드 기브스와 하인리히 루돌프 헤르츠 역시 헤비사이드와 동일한 작업을 한 바 있다. 이 때문에 맥스웰 방정식은 헤르츠-헤비사이드 방정식으로 불리기도 한다. 그러나 \"맥스웰 방정식\"이란 이름이 더 폭넓게 쓰이고 있다.\n",
      "\n",
      "1861년 맥스웰은 《물리적인 역선에 대해》에서 앙페르 회로 법칙을 설명하기 위해 방정식들을 열거하였다. 맥스웰은 이 논문에서 앙페르 회로 법칙에 치환 전류를 덧붙였다. 1865년 발표한 《전자기장의 역학 이론》에서는 전자기파 방정식을 기술하면서 빛이 전자기파임을 제시하였다. 맥스웰의 이론은 1887년 하인리히 루돌프 헤르츠의 실험에 의해 증명되었다.\n",
      "\n",
      "\"장\"(場)이란 개념은 마이클 패러데이가 도입하였다. 알베르트 아인슈타인은 맥스웰이 장 개념을 도입한 것에 대해 다음과 같이 평가하였다.\n",
      "\n",
      "당시 이 방정식은 헤르츠-헤비사이드 방정식 또는 멕스웰-헤비사이드 방정식이라고 불렸다. 그러나 아인슈타인은 사이언스에의 기고문에서 이를 \"맥스웰 방정식\"이라 부르며, 이 방정식들이 이론물리학의 기초라고 설명하였다. 맥스웰은 방정식을 정리하면서 헤비사이드의 전위와 벡터 위치 등 위치 요소를 중요한 개념으로 도입하였다. 1884년 맥스웰은 전자기파의 전달을 중력과 같이 원격에서 상호작용하는 힘이 아닌 전자기장에서 빛의 속도로 전파되는 전위로 파악하였다. 라디오 안테나에 대한 현대의 분석에서도 맥스웰의 백터와 스칼라 위키에 대한 수식만으로 서로 떨어져 있는 안테나 사이에 작용하는 전파의 영향을 모두 설명할 수 있다.\n",
      "\n",
      "맥스웰 방정식과 관련한 헤비사이드의 업적은 맥스웰이 여러 논문과 책에서 서술한 맥스웰 방정식을 오늘날과 같은 4개의 방정식으로 정리하였다는 것이다.\n",
      "\n",
      "오늘날 4개의 방정식으로 정리된 맥스웰의 방정식은 1861년 발표된 논문인 《물리적 역선에 대해》에 기반한 것이다. 이 논문에는 전자기장에 대한 다수의 방정식이 실려있다.\n",
      "\n",
      "1855년 맥스웰은 케임브리지 철학 학회에서 《패러데이의 역선》을 발표하면서 formula_8와 formula_9 벡터의 차이점을 설명하였다. 이 논문은 오늘날에도 패러데이 전자기 유도 법칙에 대한 가장 간결한 모형으로 인정받고 있다. 여기서 맥스웰은 전류에 관한 모든 지식을 미분 방정식으로 나타내었다.\n",
      "\n",
      "1855년 맥스웰이 제안한 분자 와동의 바다란 개념은 1861년 《물리 역선에 대해》에서 보다 분명하게 소개되었다. 이 논문에서는 자기장이 형성되는 분자 규모의 와동에서 formula_8의 밀도에 따라 formula_9의 순 와동 운동이 결정된다고 보았다. 맥스웰은 와동의 밀도를 측정하기 위한 값으로 투자율 µ 을 정의하였다. 이 논문에서 밝힌 맥스웰의 개념은 다음과 같다.\n",
      "\n",
      "이 때 formula_14는 전하 밀도이다. formula_8는 축을 이루어 회전하는 자기 전류이고 formula_9는 그 주위를 돌게 되는 자기력선의 자기 선속이다. 투자율 µ는 결국 자기장 formula_8에 의해 유도되는 자기 선속 formula_9의 비가 된다.\n",
      "\n",
      "전류 방정식은 전하의 대류 전류가 선형적으로 움직이는 것을 보여준다. 한편, 자기 방정식은 유도 전류의 회전에 의해 발생하는 자기를 나타내는 것으로 formula_8 벡터의 방향성으로 인해 비선형 방정식이 된다. 따라서 자기 유도 전류는 역선으로 표현된다. 자기력선은 역제곱 법칙에 의해 전류에서 멀어질수록 약해지게 된다.\n",
      "\n",
      "1864년 맥스웰은 《전자기장의 역학이론》을 출간하였다. 맥스웰은 이 책에서 빛이 전자기파임을 제시하였다. 이 책에서 맥스웰은 8개의 방정식을 전자기장에 대한 일반적인 방정식으로 제시하였다. 이 때문에 훗날 \"맥스웰 방정식\"이라는 표현이 오늘날의 4개의 방정식을 가리키는 것인지 1864년 제시된 8개의 방정식을 가리키는 것인지를 혼동하기도 한다. 따라서 오늘날의 4개로 구성된 방정식을 분명히 하기 위해 헤비사이드가 정리한 맥스웰 방정식(맥스웰-헤비사이드 방정식)이라는 표현이 사용된다.\n",
      "\n",
      "현대 벡터 표기를 사용하여 정리한 멕스웰의 8개 방정식은 다음과 같다.\n",
      "\n",
      "이 책에서 표현된 방정식 D는 로런츠 힘의 효과를 나타낸 것으로 1861년 논문의 방정식 77번을 보다 간략하게 표현한 것이다. 또한, 맥스웰은 1865년 논문에서 전자기파 방정식을 정의하였는데 이 책의 방정식 D를 전자기 유도를 설명하기 위해 사용하였다. 오늘날에는 방정식 D 대신 패러데이 전자기 유도 법칙이 쓰인다. 맥스웰은 전자기파 방정식을 연구하는 과정에서 방정식 D의 formula_36를 버렸다.\n",
      "\n",
      "1873년 맥스웰이 출간한 《전기와 자기에 관한 논문집》에서 방정식은 두 개의 묶음으로 나뉘었다.\n",
      "\n",
      "다음은 국제단위계를 사용하여 수식으로 표현한 맥스웰 방정식이다.\n",
      "\n",
      "발산정리와 스토크스의 정리를 이용하면 미분형과 적분형 방정식이 같음을 알 수 있다.\n",
      "\n",
      "아래 표는 각 기호의 뜻과 단위를 나타낸다.\n",
      "\n",
      "formula_41는 발산 연산자(단위: 1 / 미터), formula_42는 회전 연산자(단위: 1 / 미터)이다. 두 번째 방정식은 자기 홀극이 없음을 뜻한다. 전기장과 자기장이 대전된 입자에 미치는 힘은 리엑턴스 힘에 따라 국제단위계에서 다음과 같다.\n",
      "\n",
      "여기서 formula_44는 입자의 전하량이고 formula_45는 입자의 속도다. (CGS 단위계에서는 자기장을 다르게 정의하므로, formula_45 대신 formula_47를 쓴다.)\n",
      "\n",
      "위의 수식은 국제단위계로 표현되었지만, 다른 단위계에서도 맥스웰 방정식은 변하지 않거나, 약간의 상수 변화만이 있을 뿐이다. 물리학과 공학에서 일반적으로 가장 널리 쓰이는 국제단위계 이외에도 특수한 경우 CGS 단위계가 쓰인다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "초월수\n",
      "\n",
      "초월수(超越數, )는 수학에서 대수학적이지 않은 수, 즉 유리수 계수를 가지는 0이 아닌 유한 차수 다항 방정식의 해가 될 수 없는 수를 의미한다. 가장 잘 알려진 초월수는 (원주율)과 (자연로그의 밑)이다.\n",
      "\n",
      "현재까지는 적은 양의 초월수들만 알려져 있다. 이는 어떤 주어진 수가 초월수인지 보여주는 것은 극히 어려울 수 있기 때문이다. 그러나 초월수들은 드물지 않다. 실제로 대수적 수들이 가산 집합을 구성하는 반면 실수의 집합, 복소수의 집합은 모두 비가산 집합이므로 거의 모든 실수들과 복소수들은 초월적이다. 또한 모든 유리수가 대수학적이기 때문에 모든 초월실수(\"실제 초월수\" 또는 \"초월무리수\"라고도 함)는 무리수이다. 그러나 모든 무리수가 초월적인 것은 아니다. 따라서 실수의 집합은 겹치지 않는 유리수, 대수적인 무리수, 초월적인 실수로 구성된다. 예를 들어 제곱근 2는 무리수이지만 다항식 의 근인 만큼 초월수는 아니다. 황금비(formula_1 또는 formula_2로 표시됨)은 다항식 의 근으로서 초월적이지 않은 또다른 무리수이다.\n",
      "\n",
      "\"초월적\"이라는 이름은 라틴어로 \"넘어오거나 넘어서거나\"를 뜻하는 '트란스켄데레'(transcendĕre)에서 유래되었다. 고트프리트 빌헬름 라이프니츠는 1682년에 발표한 자신의 논문에서 수학적 개념을 처음 사용했는데 가 의 대수함수가 아니라는 것을 증명했다. 레온하르트 오일러는 18세기에 \"초월수\"를 현대적 의미로 정의한 최초의 수학자로 여겨지고 있다.\n",
      "\n",
      "요한 람베르트는 1768년에 발표한 자신의 논문에서 (자연로그의 밑)와 (원주율) 둘 다 초월수라고 추측했고 무리수인 의 초월수 증명에 대한 대략적인 구성을 제안했다. 조제프 리우빌은 1844년에 초월수의 존재를 처음으로 증명했고 1851년에 리우빌 수와 같은 초월수의 사례를 제시했다.\n",
      "\n",
      "이 ( 계승)인 경우에는 소수점 뒤의 번째 자리가 이고 그렇지 않은 경우에는 이다. 즉 이 숫자 등일 경우에만 이 숫자의 번째 자릿수가 이다. 리우빌은 이 숫자가 특정한 무리수인 대수적 수보다 유리수에 의해 보다 가깝게 근사할 수 있는 초월수의 종류에 속한다는 것을 보여주었고 이 종류의 숫자는 그의 이름을 따서 리우빌 수라고 불린다. 리우빌은 모든 리우빌 수가 초월수라는 것을 증명했다. 1873년에는 샤를 에르미트가 초월수의 존재를 증명하기 위해 가 특별히 구성되지 않은 초월수임을 증명했다.\n",
      "\n",
      "1874년에는 게오르크 칸토어가 대수적 수들은 셀 수 있고 실수는 셀 수 없다는 사실을 증명했다. 그는 또한 초월수를 구성하는 새로운 방법을 제시했다. 비록 이것이 대수적 수의 계산 가능성에 대한 그의 증명에 의해 이미 암시되었지만 칸토어는 실수들만큼 초월적인 숫자들이 있다는 것을 증명하는 구성을 공개했다. 칸토어의 연구는 초월수의 보편성을 확립했다.\n",
      "\n",
      "1882년에는 페르디난트 폰 린데만이 의 초월성에 대한 최초의 증명을 담은 책을 출판했다. 그는 먼저 가 0이 아닌 대수적 수일 경우 가 초월수라는 것을 증명했다. 그렇다면 은 대수적이므로(오일러의 항등식 참조), 는 초월수이어야 한다. 그러나 가 대수적 수이기 때문에 는 초월수이어야 한다. 이러한 접근 방식은 카를 바이어슈트라스에 의해 일반화되었는데 오늘날에는 린데만-바이어슈트라스 정리로 알려져 있다. 의 초월은 원적문제와 같이 가장 유명한 것을 포함하여 컴퍼스와 자 작도를 포함한 여러 고대 기하학 구조들이 갖고 있던 불가능성의 증거를 가능하게 했다.\n",
      "\n",
      "1900년에는 다비트 힐베르트가 힐베르트의 7번째 문제인 초월수에 대해 영향력 있는 질문을 던졌다. \"가 0이나 1이 아닌 대수적 수이고 가 무리수인 대수적 수라면 반드시 은 초월수인가?\" 이에 대한 해답은 1934년에 겔폰트-슈나이더 정리를 통해 제공되었다. 이 연구는 1960년대에 앨런 베이커가 진행한 (대수 수) 로그에서 선형 형태의 하한에 대한 연구를 통해 확장되었다.\n",
      "\n",
      "초월수의 집합은 셀 수 없이 무한하다. 유리수인 계수를 갖는 다항식은 셀 수 있고 각각의 다항식은 유한한 근을 가지기 때문에 대수적 수도 셀 수 있어야 한다. 그러나 칸토어는 대각선 논법을 통해 실수가 (그리고 복소수또한) 셀 수 없다는 것을 증명했다. 그리고 실수 집합은 대수적 수 집합과 초월수 집합의 합집합이기 때문에, 초월수 집합은 셀 수 없다.\n",
      "\n",
      "어떠한 유리수도 초월적이지 않고 모든 초월실수는 무리수이다. 무리수는 2차 무리수 및 그 외의 형태를 가진 대수적 무리수를 포함하여 모든 실제 초월수와 대수적 수의 부분집합을 포함한다. 단일 변수의 일정하지 않은 대수함수는 초월 인수에 적용될 때 초월 값을 산출한다.\n",
      "\n",
      "단일 변수의 대수함수에서 초월수는 다른 초월수에 대응된다. 예를 들어 가 초월적이라는 것을 아는 것으로부터 과 같은 숫자들이 초월수임을 수 있다. 도 초월수이다.\n",
      "\n",
      "그러나 여러 변수의 대수함수는 초월수에 적용될 때 대수적 수를 산출할 수 있다. 예를 들어 와 는 둘 다 초월적이지만 은 그렇지 않다. 예를 들어 가 초월적인지는 알 수 없지만, 와 가운데 적어도 하나는 초월적인 것이어야 한다. 보다 일반적으로 어떤 2가지 초월수 와 의 경우 적어도 와 가운데 하나는 초월수여야 한다. 그 이유는 다항식 을 고려해보면 알 수 있다. 만약 와 가 둘 다 대수적이라면 이것은 대수적 계수를 갖는 다항식이 될 것이다. 대수적 수는 대수적으로 닫힌 체를 형성하기 때문에 다항식인 와 의 근은 대수적이어야 한다는 것을 의미한다. 하지만 이때 모순이 생긴다. 따라서 적어도 하나의 계수가 초월적이라는 것을 알 수 있다.\n",
      "\n",
      "계산 불가능한 수는 초월수의 진부분집합이다. 모든 리우빌 수는 초월적이지만 그 반대는 아니다. 모든 리우빌 수는 지속적인 연분수에서 제한 없는 부분적인 몫을 가져야 한다. 계산 인수를 사용하면 제한된 부분적인 몫을 가진 초월수가 존재하므로 리우빌 수가 아니라는 것을 증명할 수 있다.\n",
      "\n",
      "의 지속적인 연분수를 사용하여 가 리우빌 수가 아니라는 것을 보여줄 수 있다(비록 지속적인 분수의 부분적인 몫은 무한대이다). 쿠르트 말러는 1953년에 또한 리우빌 수가 아니라는 것을 증명했다. 결국 주기적이지 않은 경계 항을 갖는 모든 무한 연분수는 초월적(결국 주기적인 연분수는 2차 무리수에 해당함)이라고 추측된다.\n",
      "\n",
      "초월수로 입증된 수:\n",
      "\n",
      "초월수 또는 대수적 수로 아직 입증되지 않은 수:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "음계\n",
      "\n",
      "음계(音階)는 음악에서 음높이(pitch) 순서로 된 음의 집합을 말한다. 악곡을 주로 구성하는 음을 나타낸 것이며 음계의 종류에 따라 곡의 분위기가 달라진다.\n",
      "\n",
      "음계의 각각의 음에는 위치에 따라 도수가 붙는다.\n",
      "\n",
      "음계는, 음계가 포함하고 있는 음정(interval)에 따라서 이름을 붙일 수 있다.\n",
      "\n",
      "또는 음계가 포함하고 있는 서로 다른 피치 클래스의 수에 따라서 이름을 붙일 수 있다.\n",
      "\n",
      "\"음계의 음정(interval) 뿐만 아니라 음계를 만드는 음(note)의 수가, 한 문화권의 음악에 독특한 음악적 특징을 지니게 한다\" \"어떤 음계의 음의 수보다, 음의 거리(interval, pitch distance)가 음악의 소리에 대해서 더 많은 것을 알려준다.\"\n",
      "\n",
      "온음계와 반음계(半音階)는 서양 음악에서 쓰이는 용어이다. 자체로는 음계에 관한 말이지만, 온음계적·반음계적인 선율, 화음, 화성 진행 등의 표현으로도 쓰인다. 대부분의 경우 온음계는 7개 음으로 이루어진 장음계를 말한다. 20세기 음악론에서는 반음계가 아닌 모든 음계(이를테면 팔음음계)를 말할 때 쓰이기도 한다.\n",
      "\n",
      "반음계는 12개의 반음으로 이루어진 음계를 말한다.\n",
      "\n",
      "계이름은 음계를 기준으로 한 음의 이름이다. 장음계를 이루는 음의 계이름은 으뜸음부터 위로 올라가면서 각각 도, 레, 미, 파, 솔(), 라, 시(), 도가 된다.\n",
      "\n",
      "서양 음악에서는 도·레·미·파·솔·라·시로 된 7음계가 많이 쓰이지만 한국 전통 음악에는 황종(黃鍾)-미♭·태주(太蔟)-파·중려(仲呂)-라♭·임종(林鍾)-시♭·무역(無射)-레♭으로 된 5음계가 많이 쓰이고, 중국 전통 음악에는 궁-도·상-레·각-미·변치(變徵)-올림화(Fa )·치-솔·우-라·변궁(變宮)-시로 7음계를 많이 쓴다.\n",
      "\n",
      "한국 전통 음악에서는 5음계 외에도 3음계 또는 악계통에서는 7음계 등이 쓰인다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "대한민국 제16대 대통령 선거\n",
      "\n",
      "대한민국 제16대 대통령 선거는 2002년 12월 19일 목요일 치뤄진 대통령 선거로, 21세기에 처음으로 치뤄진 대한민국 대통령 선거이다. 15대 김대중 대통령의 차기 대통령을 뽑기 위한 선거이다.\n",
      "\n",
      "16대 대선은 지난 15대 대선에서 간발의 차로 낙선하고 재도전한 이회창 한나라당 후보와 사상 최초의 국민 참여 경선을 통해 여당의 대통령 후보가 된 해양수산부 장관 출신 노무현 새천년민주당 후보의 양강 구도로 진행되었다.\n",
      "\n",
      "대선 재수생인 이회창 후보는 경험이나 세력 면에서 노무현 후보보다 대권 고지에 좀 더 유리할 것으로 점쳐졌으나, 이전 대선부터 불거진 이회창 후보의 두 아들의 병역기피 논란, 노사모를 비롯한 네티즌들의 열성적인 노무현 지지, 정몽준 후보와의 단일화 성공 등에 힘입어 노무현 후보가 당선되었다.\n",
      "\n",
      "만 20세 이상의 대한민국 국민은 선거권이 있었다. 즉, 1982년 12월 19일 이전에 태어난 사람은 투표를 할 자격이 있었다.\n",
      "\n",
      "만 40세 이상의 대한민국 국민은 피선거권을 가졌다. 즉, 1962년 12월 19일 이전에 태어난 사람은 후보자가 될 자격이 있었다.\n",
      "\n",
      "새천년민주당은 3월 9일부터 4월 27일까지 한국 정당 역사상 최초로 국민 참여 경선을 실시하고 과반 득표자인 노무현 전 해양수산부 장관을 대통령 후보로 선출하였다.\n",
      "\n",
      "한나라당은 4월 13일부터 5월 9일까지 국민 참여 경선을 실시하고 최다 득표자인 이회창 전 당 총재를 대통령 후보로 선출하였다.\n",
      "\n",
      "민주노동당은 9월 8일 당원들에 의한 단일 후보 찬반 투표를 통해 권영길 당 대표를 대통령 후보로 선출하였다.\n",
      "\n",
      "통합21은 11월 5일 창당대회를 열고 정몽준 의원을 당 대표 및 대통령 후보로 추대하였다.\n",
      "\n",
      "사회당은 10월 27일 전당대회를 열고 김영규 전 인하대학교 교수를 당 대표 및 대통령 후보로 선출하였다. 김영규 후보는 대의원 찬반투표 결과 전체 투표수의 95%를 득표하였다. 이온규 이엽규 이천규 이상규 이인규 이일근\n",
      "\n",
      "하나로국민연합은 11월 15일 재적 대의원 8,500명 중 8,125명이 참석한 가운데 창당대회를 열고 이한동 전 자유민주연합 총재를 당 대표 및 대통령 후보로 추대하였다.\n",
      "\n",
      "개혁당 추진위는 독자 후보를 내는 대신 노무현 민주당 후보를 지지하기로 하고 이를 10월 12일부터 18일까지 창당 발기인 28,500여명을 대상으로 한 인터넷·모바일 찬반 투표에 부친 결과 총투표수 16,733표 중 15,723표가 찬성으로 나와 노무현 새천년민주당 대통령 후보와의 대선 연대가 결정되었다. 개혁당 추진위는 10월 20일 창당 발기인 대회에서 이를 발표하였으며, 대회에 참석한 노무현 후보는 수락을 선언하였다.\n",
      "\n",
      "박근혜 한나라당 부총재는 2001년 12월 11일 한나라당 대선 후보 경선 출마를 공식 선언하였다. 그러나 박근혜 부총재는 2월 28일 이회창 총재의 리더십을 비판하며 한나라당을 탈당하였으며, 이후 신당을 창당하여 독자적으로 대선에 출마할 뜻을 밝혔다. 결국 5월 17일 박근혜 대표가 이끄는 미래연합이 창당되기에 이르렀다. 그러나 한미련은 6·13 지방선거에서 대참패를 당한 뒤 동력을 잃었으며, 그 후 별다른 움직임을 보이지 못하다가 대선 한 달 전 한나라당에 흡수 합당되었다.\n",
      "\n",
      "장세동 전 국가안전기획부장은 10월 21일 무소속 대선 출마를 선언하였다. 그러나 장세동 후보는 12월 18일 당선 가능성이 없다며 사퇴를 선언하였다.\n",
      "\n",
      "호국당은 11월 25일 재적 대의원 645명 중 539명이 참석한 가운데 창당대회를 열고 김길수 법륜사 주지를 당 총재 및 대통령 후보로 추대하였다.\n",
      "\n",
      "제16대 대선은 민주당의 노무현 후보와 한나라당의 이회창 후보, 두 후보의 양자 대결 구도로 진행되어, 1971년 제7대 대선 이후 최초로 3자, 4자가 아닌 양자 구도로 치러진 대선이 되었다. 그러나 제15대 대선에서 패한 후 차근차근 대권 재도전을 준비해오던 이회창 후보가 한나라당을 완전히 장악하고 있었던 것과 달리, 진보 성향 인사이면서 보수 정당 민주당의 후보가 된 노무현 후보는 끊임없이 당 내부에서 공격을 받고 있었다.\n",
      "\n",
      "이같은 상황에서 이회창의 당선이 유력시되고 있었으나, 제15대 대선과 마찬가지로 아들 병역기피 의혹에 시달리며 난관에 봉착한데다 노무현후보가 이른바 '노풍'을 일으키며 선풍적 인기를 끌어 승패를 예측할 수 없게 되었다. 또한 노무현 후보는 정몽준 통합21 후보와 극적으로 단일화에 성공, 이를 발판 삼아 이회창 후보의 지지율을 맹추격했다.\n",
      "\n",
      "5월 들어 김대중 대통령의 두 아들인 김홍업과 김홍걸의 비리가 불거지며 민주당의 지지율이 하락함과 더불어, 노무현의 지지율도 본격적인 내림세로 돌아서기 시작했다. 이에 노무현은 6.13 지방선거에서 영남권 광역 단체장을 한 명도 당선시키지 못할 경우 재신임을 받겠다고 공약했다.\n",
      "\n",
      "선거 결과 새천년민주당은 호남과 제주의 광역단체장만 당선되는 등 참패를 기록했다. 노무현은 선거 전 약속한 대로 후보 재신임을 물었고, 민주당 당무회의는 만장일치로 재신임을 의결했다. 민주당 내 최대 계파 모임인 중도개혁 포럼은 이를 인정할 수 없다며 ‘후보·지도부 즉각 사퇴론’을 주장했다.\n",
      "\n",
      "지방 선거 참패를 계기로 이인제 등 민주당 내 반노무현 세력의 후보 흔들기는 더욱 노골화되는 모습을 보였다.\n",
      "\n",
      "대한축구협회장이던 정몽준 무소속 의원은 2002년 한일 월드컵을 유치해내고 성공적으로 개최함으로써 국민들 사이에 선풍적 인기를 얻어 유력 대권 주자가 되었다. 정몽준이 대선에 출마하자 노무현 후보의 지지율은 토막났고, 안 그래도 노무현 후보와 갈등이 있던 당내 상당수 의원들은 노무현 후보를 더 적극적으로 배척하기 시작했다. ‘노무현 흔들기’는 더욱 노골화되었고, ‘후보 단일화론’은 물론이거니와 ‘후보 교체론’까지 나왔다. 노무현은 경쟁력이 없는 만큼 정몽준을 수혈해 대선 새판 짜기에 나서야 하지 않느냐는 정치공학적 판단이었다.\n",
      "\n",
      "10월 들어서는 아예 노무현의 낙마를 바라는 의원들이 탈당하여 후보 단일화 추진 협의회(후단협)를 만들고 후보 단일화를 주장했는데, 이들은 노무현으로 후보 단일화가 되면 함께 할 수 없다고 발언하였고 정몽준 지지의 속내를 감추지 않았다. 11월 19일 후단협은 정몽준에 대한 공개 지지를 밝혔으며, 심지어 후단협 소속 의원이 정몽준 대표 측에 돈을 요구하기도 했다. 후단협 해체 후 일부 의원은 한나라당에 입당했고, 12명은 민주당에 복당했다.\n",
      "\n",
      "그러던 10월 17일 김민석 전 민주당 최고위원이 민주당 탈당 및 통합21 합류를 선언했는데, 노무현에게 큰 타격이 되리라는 관측과 달리 오히려 이는 노무현 후보에게 호재로 작용했다. 일반 국민들 사이에서 노무현 후보에 대한 동정론이 불었고, 결국 답보 상태였던 그의 지지율은 20%대를 회복하고 후원금도 크게 늘어난 것으로 드러났다.\n",
      "\n",
      "단일화 방안으로는 크게 3가지가 제시되었는데, 국민 경선과 여론 조사, 협상 담판이었다. 정몽준 캠프는 11월 1일 양 캠프가 협상·담판을 통해 단일 후보를 정할 것을 제안했고, 노무현 캠프는 11월 3일 국민 참여 50%, 당원 참여 50%로 국민 경선을 실시하는 방식을 제안했다. 또한 여론조사상 노무현 후보에 우위를 점하고 있던 정몽준 후보 측은 여론조사로 단일 후보를 정하는 방안도 긍정적으로 보고 있었다. 통합21은 노무현 캠프의 국민경선 실시 주장에 대해 “국민 경선을 할 시간적 여유가 없다”는 이유로 반대를 표했다. 그러나 노무현 후보의 지지율이 꾸준히 회복해 이미 판세는 이회창 후보가 독주하고 노·정 두 후보가 2위 싸움을 벌이는 1강 2중 구도로 재편되고 있었으므로, 정몽준 캠프로서도 하루 빨리 단일화를 성사시키지 않으면 안 되는 상황이었다.\n",
      "\n",
      "노무현 후보는 11월 11일, 자신에게 불리한 것으로 여겨지던 여론조사를 통한 단일화를 정식으로 제의하였다. 또한 여론조사 결과 이회창 후보의 지지율이 일정 수준에 미달할 시 그 여론조사는 무효 처리하자는 정몽준 캠프의 주장을 수용하였다. 이에 따라 11월 23일부터 25일까지 주요 언론사에서 실시한 여론조사 결과 중 이회창 후보의 지지율이 가장 낮게 나온 결과보다 단일화 여론조사에서 이회창 후보의 지지율이 더 낮게 나올 시 그 결과는 한나라당 지지자들이 역선택을 했을 가능성이 있는 것으로 보고 무효 처리하기로 하였다. 11월 23일부터 25일까지 실시된 여론조사 중 이회창 후보의 지지율이 가장 낮게 나온 것은 국민일보-월드리서치가 11월 25일 실시한 결과에서의 30.4%였다. 따라서 단일화 여론조사에서 이회창 후보의 지지율이 30.4%보다 낮을 시 그 조사 결과는 무효 처리하도록 했다.\n",
      "\n",
      "단일화 협의 과정에서 노무현 후보가 단일화 방식 등 쟁점 사항에 있어 통큰 양보를 하는 모습은 국민들에게 좋은 인상을 주었고, 이는 노무현 후보의 지지율이 상승하는 효과로 이어지기도 하였다.\n",
      "\n",
      "단일화의 방식은 합의되었으나, 여론조사의 설문 내용을 두고도 논란이 일었는데, '노무현 후보와 정몽준 후보 중 누가 더 마음에 드느냐'는 지지도 질문에는 노무현 후보의 지지율이 높게 나오는 반면, '어느 후보가 이회창 후보를 이길 수 있겠느냐'는 경쟁력 질문에는 정몽준 후보의 지지율이 높게 나오는 경우가 많았다. 결국 양 캠프는 조율을 거친 결과 지지도 질문과 경쟁력 질문을 조금씩 섞은 \"한나라당 이회창 후보와 견주어 경쟁력 있는 단일후보로 노무현·정몽준 후보 중 누구를 지지하십니까\"를 사용하기로 결정하였다.\n",
      "\n",
      "두 후보는 여론조사 실시에 앞서 텔레비전 토론을 가지기로 했는데, 이에 대해 한나라당은 사전 선거 운동이 될 수 있다며 텔레비전 토론을 허용해선 안 된다고 주장하였다. 결국 중앙선거관리위원회는 한 차례에 한해 텔레비전 토론을 허용하였고, 두 후보 간 토론은 11월 22일 실시되었다.\n",
      "\n",
      "후보 단일화를 위한 여론조사는 11월 24일 오후 1시부터 8시 30분까지 7시간 반에 걸쳐 실시되었다. 여론조사는 월드리서치와 리서치앤리서치, 2개 업체에 의해 실시되었으며, 한 업체가 각각 2,000명, 총 4,000명을 상대로 실시되었다.\n",
      "\n",
      "민주당과 통합21은 11월 24일 자정 공동으로 여론조사 결과를 발표하였다. 리서치앤리서치 조사는 응답자 중 이회창 후보 지지율이 32.1%가 나와, 무효 처리되지 않았다. 그러나 월드리서치 조사는 이회창 후보의 지지율이 28.7%로 무효화 기준인 30.4%에 미달하여 무효 처리되었다. 리서치앤리서치 조사 결과 노무현 후보가 46.8%, 정몽준 후보가 42.2%를 얻음으로써 노무현 후보의 승리가 확정되었다. 무효 처리된 월드 리서치 조사 결과 또한 노무현 후보가 38.8%, 정몽준 후보가 37.0%를 얻은 것으로 나타났다.\n",
      "\n",
      "정몽준 후보는 단일화 여론조사 결과에서 패배함에 따라 사퇴를 선언하고 노무현 후보 지지를 선언하였다. 노무현 후보는 정몽준 후보와의 단일화를 계기로 각종 여론조사에서 이회창 후보를 역전하였다.\n",
      "\n",
      "민주당 대선 후보 경선 당시 2위를 했던 이인제 전 민주당 최고위원은 12월 1일 민주당 탈당을 선언한 데 이어 이틀 뒤인 12월 3일 자유민주연합에 입당하였으며, 입당과 동시에 김종필 자민련 총재의 지명을 받아 총재 권한대행으로 취임하였다. 이인제는 이회창 후보 지지를 선언할 계획으로 자민련에 입당했으나, 김종필 총재의 강력한 의지로 자민련은 12월 12일 당 차원에서 특정 후보를 지지하지 않기로 선언하였다. 다만 당원 및 당직자들이 개별적인 지지를 하는 것은 막지 않기로 해, 이인제는 다수 자민련 의원들과 함께 이회창 지지를 선언하고 이회창 후보 지원 활동에 나섰다.\n",
      "\n",
      "정몽준 역시 대선 전날인 12월 18일 밤 10시 긴급 발표를 통해 민주당과의 선거 공조 파기, 노무현 후보 지지 철회를 선언하였다. 정몽준은 지지 철회 발표문에서 그 날 유세에서 노무현 후보가 ‘미국과 북한과 싸우면 우리가 말린다’는 표현을 한 것에 노무현 후보의 외교안보 의식에 문제를 느껴 지지를 철회했다고 밝혔다. 노무현 후보와 정대철 민주당 선대위원장 등은 정몽준을 만나기 위해 정몽준의 자택 앞까지 찾아갔으나, 정몽준 대표는 끝내 만나주지 않았다. 하지만 이 모습이 전파를 타며 당시 진보 진영이 민노당 권영길 후보 대신 민주당 노무현 후보로 결집하는 의외의 효과가 일어났다는 분석도 있었다.\n",
      "\n",
      "이 선거는 대한민국 정치를 이끈 3김 시대의 종식과 대한민국 정치계의 본격적인 세대 교체론의 대두와 함께 노사모의 등장 등 인터넷 정치 시대의 개막을 알렸다는 점에서 많은 의미를 담고 있다.\n",
      "\n",
      "한나라당 이회창 후보는 선거 이후 정계 은퇴를 선언하였으나, 2007년 전격적으로 정계에 복귀하게 된다.\n",
      "\n",
      "노무현 후보의 당선으로 새천년민주당은 정권 연장에 성공하였다. 하지만 노무현 대통령을 위시한 신주류 소장파와 구주류파가 중심인 민주당의 관계는 썩 좋지 않았고, 결국 임기 중이던 2003년 9월 30일 노무현 대통령이 새천년민주당을 탈당함으로써 민주당은 야당으로 전락하게 된다. 그리고 새천년민주당은 2004년 한나라당, 자유민주연합과 함께 노무현 대통령 탄핵안을 가결시키지만, 오히려 민심의 역풍을 맞고 총선에서 참패하며 몰락하고 만다.\n",
      "\n",
      "열린우리당은 탄핵 역풍의 수혜를 맞고 2004년 제17대 국회의원 총선거에서 압승, 192석을 차지하며 여대야소 구도를 이루게 된다. 노무현 대통령은 탄핵 기각 6일 뒤인 2004년 5월 20일 열린우리당에 공식적으로 입당하였다.\n",
      "\n",
      "반면 제1야당 한나라당는 선거에서 패배하며 정권 교체를 실패하며 계속 야당시절을 보내게 된다. 이회창 은퇴와 참여정부의 출범 이후 원내 의석수을 악용해 압박하여 참여정부에게 향한 견제를 하기 시작했지만 그러나 2003년 11월 한나라당이 대기업들부터 선거 자금을 받았다는 의혹로 인해 16대 대선 차떼기 사건으로 역풍을 맞게되고 한나라당는 창당 이래 최악의 위기를 맞게된다. 하지만 2004년 3월 17대 총선를 한달 앞두고 제2야당 새천년민주당, 소수야당 자민련와의 공조하여 노무현 대통령의 탄핵을 일으켜 민심의 역풍을 맞게되었지만 17대 총선에서 16년 만에 원내 1당 지위를 상실했지만 개헌 저지선 100석 이상 사수을 하며 선전하는데 만족했다. 이회창 은퇴와 한나라당의 실질적 뿌리 민정계 인사들의 퇴장 이후 박정희 대통령의 차녀 박근혜 대표와 이명박 서울시장의 등장으로 친박계과 친이계이란 거대한 파벌이 등장했다. 이후 두 사람는 17대 대선과 18대 대선에서 나란히 승리하여 대통령이 되었다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "함석헌\n",
      "\n",
      "함석헌(咸錫憲, 1901년 3월 13일 ~ 1989년 2월 4일)은 대한민국의 독립운동가, 종교인, 언론인, 출판인이며 기독교운동가, 시민사회운동가였다.\n",
      "\n",
      "광복 이후 비폭력 인권 운동을 전개한 인권운동가, 언론인, 재야운동가, 문필가로 활약한 그의 본관은 강릉(江陵)이며 호는 신천(信天), 씨알, 바보새이다.\n",
      "\n",
      "1919년 3.1 운동에 참여했다가 퇴학 당한 후, 사무원과 소학교 교사 등을 전전하다가 1928년부터 1938년까지 오산학교의 교사를 역임했다. 이후 교육, 언론 활동 등에 종사하다가 해방 후, 1947년 월남하였다. 이후에는 성서 강해 등을 하다가 1956년부터는 장준하의 사상계에 참여하여 정치, 시사 등에 대한 평론 활동, 신앙 활동, 반독재 민주화운동 등을 하였다.\n",
      "\n",
      "그의 종교는 초기에는 일본 유학 중에 우치무라 간조의 영향을 받아 무교회주의자였다가 중기에는 기독교였으나 후기에는 장로회로 바꾼것이다,\n",
      "\n",
      "함석헌은 1901년 평안북도 용천에서 출생했다. 어려서 당숙 함일형(咸一亨)이 세운 한학 서당인 삼천재(三遷齋)에서 한학을 수학하다가 덕일소학교(德一小學校)에 입학, 1914년에 덕일소학교를 수료하고 그 해에 양시공립소학교에 편입하였다가 1916년 양시공립소학교를 졸업했다.\n",
      "\n",
      "그해 평양고등보통학교에 진학하였으며 1917년에 황득순과 결혼하고, 1919년 평양 고등보통학교 3학년 재학 중에 숭실학교 교사로 있었던 6촌 형 함석은 등의 영향으로 학업을 중단하고 3·1 운동에 참가한 후, 3.1운동에 대한 반성문을 쓰면 복학시켜 준다는 일본인 교장의 제의를 거부하고 퇴학되어 2년간 학업을 중단한다. 이 시기에 함석헌은 수리조합 사무원과 소학교 선생 등을 하게 된다.\n",
      "\n",
      "1921년 함석규 목사의 권유로 평안북도 정주(定州)에 있는 오산학교(五山學校) 3학년에 편입하여 수학했으며, 그곳에서 류영모를 만나 평생 스승으로 삼았다. 또한 이때 안창호, 이승훈, 이광수, 조만식 등과도 알게되어 그들로부터 민족주의 사상과 실력 양성론의 영향을 받게 된다. 그러나 후일 그는 맹목적인 민족주의와 국가주의에 비판적인 성향으로 돌아서게 된다.\n",
      "\n",
      "1923년 오산학교를 졸업하고, 1924년 일본 동경고등사범학교 문과 1부에 입학하여, 우치무라 간조의 성서 집회에 참가하여 그의 무교회주의를 접했다.\n",
      "\n",
      "동경고등사범학교 재학 중에 일본인 무교회주의자 우치무라(內村鑑三)의 성서연구에 깊이 영향을 받고 김교신(金敎臣), 송두용(宋斗用), 정상훈(鄭相勳), 유석동(柳錫東), 양인성(楊仁性)등과 함께 교회에 다니지 않고도 신앙을 유지하는 무교회주의 신앙클럽을 결성하였다. 1927년 동인지 《성서조선 聖書朝鮮》 창간에 참여하고 논객으로 글을 발표하기 시작하였다.\n",
      "\n",
      "1928년 동경고등사범학교 졸업(역사과 수석)과 동시에 귀국하여 오산학교에서 역사와 수신을 가르쳤다. 1934년~1935년에 동인지 《성서조선》에서 그의 주저인 〈성서적 입장에서 본 조선역사(뜻으로 본 한국역사)〉를 연재한다. 1940년 계우회 사건으로 일본 당국에 의해 투옥되어 평양 대동경찰서에서 1년간 구치되었다.\n",
      "\n",
      "이후 1938년 3월까지 오산학교의 교사로 있다가 사임하였다.\n",
      "\n",
      "1940년 평안남도 송산(松山)에서 김혁(金赫)이 운영하는 송산학원의 이사로 참여하여 활동하다가 계우회 사건(鷄友會事件)에 연루되어 평안남도 대동경찰서에 체포, 유치장에서 1년간 수감 생활을 하다가 1942년 초 풀려났다. 그러나 1942년 5월 《성서조선》(聖書朝鮮) 제 158호(폐간호)에 실린, 김교신의 〈조와〉(弔蛙)라는 우화로 관련자가 모두 투옥되는 성서조선 사건이 발생했다. 이로 인해 성서조선은 폐간되고, 함석헌은 서대문형무소에 미결수로 1943년 4월 1일까지 1년간 복역하였다(수형번호1588번).\n",
      "\n",
      "1945년 혈맹의 친구였던, 김교신이 흥남에서 장티푸스로 별세하고, 그 해 8월 15일 해방을 맞이한다. 해방이 되자 그는 해방이 ‘도둑같이(아무도 모르게) 왔다’고 평하였다.\n",
      "\n",
      "해방 후에는 반공 시위인 신의주 학생시위의 배후로 지목되어 조선민주주의인민공화국 당국에 의해 투옥되었다가 소련군에게서 풀려난 후 1947년 3월 17일 월남하였다. 조선민주주의인민공화국 탈출 전 그는 조만식을 만나고 오기도 했다.\n",
      "\n",
      "1947년 3월부터 YMCA에서 성서강해를 계속하고, 이후 성서 강해와 신학, 종교적 강연 활동을 하였다. 또한 조만식의 추모 활동에도 참여하였다.\n",
      "\n",
      "1950년 한국 전쟁 때는 대전을 거쳐 부산으로 피난갔다가 휴전 후 상경하였다. 이후 1956년부터 장준하 등의 천거로 《사상계》를 통해 논객으로 활약하였다. 1958년 '생각하는 백성이라야 산다'는 견해를 발표하면서 정부의 정책에 비평을 가하기 시작하였고, 1958년 5월 잡지 <사상계>에 발표한 칼럼 하나는 화제가 되었다.\n",
      "\n",
      "이 일로 그는 우익 인사들로부터 비판을 받았다. 그는 또 1959년 6.25 전쟁 관련자들에 대한 훈장 서훈 이야기가 나오자 \"형제를 죽이고도 무슨 훈장이냐\"라고 비판하였다. 이 사건을 계기로 국가보안법 위반으로 수감되었다가 풀려났다. \"한국전쟁에 대해 비판하고 전쟁하는 국가와 거리를 두어보려는 목사를 한 번도 만나지 못한 것이 놀라운 일\"이라고 일갈하기도 했다.\n",
      "\n",
      "1961년 장면이 국토건설단을 창설하고 강사를 초빙할 때, 국토건설요원 정신교육 담당 강사로 초빙되었다. 그러나 5·16 군사 정변으로 제2공화국이 붕괴되자 다시 야인으로 되돌아갔다. 1961년 5·16 군사 정변이 있자 모두가 침묵하고 있는 그해 7월 사상계에 발표한 정치평론인 '5·16을 어떻게 볼까'라는 글을 통해 신랄한 비판을 하여 군정 인사들과 갈등을 빚기도 했다.\n",
      "\n",
      "1962년 미국 국무성내 기독교 신자 정치인들의 특별 초청으로 미국을 방문하고 돌아왔다. 방미하였을 때 퀘이커교파(Quaker敎派) 인사들과 만나 친분관계를 형성하고 돌아왔다. 이후 1989년까지 매년 미국 정계의 기독교인사들의 초청을 받고 미국을 방문하기도 했다.\n",
      "\n",
      "제3공화국 출범 후에는 종교인으로서 한일회담에 반대하는 등 사회운동에 참여했다.\n",
      "\n",
      "1967년 장준하의 국회의원 총선거 옥중출마를 지원하기도 하였다. 그는 이승만 정권 즉, 자유당 정권 시절부터 좌익 운동에 참여하여 3선 개헌에 반대하였으며 이후 10월 유신 이후 민주화 운동에 앞장서서 수차례 투옥되었다. 1969년 4월 19일에는 4.19 10주년 기념 강연을 마친 뒤 침묵 시위에 들어가기도 했다.\n",
      "\n",
      "1970년에는 정치, 시사평론을 실은 월간잡지 《씨알의 소리》를 창간하였으나 정권의 탄압을 받기도 했다. 이후 씨알의 소리의 발행인, 편집인, 주간 등으로 있으면서, 장준하 등 재야 언론인들을 필진으로 영입하고 1980년 1월 폐간당할 때까지 신진 문인들을 발간하였으며, 글과 강연 등을 통해 민중 계몽운동을 폈다.\n",
      "\n",
      "1974년 7월 인혁당 사건 관련자에 대한 탄원서에 서명하였다.\n",
      "\n",
      "10·26 사건 이후 통일주체국민회의에서 대통령 간선제를 고수하자 윤보선 등과 함께 대통령 직선제를 요구하기도 했다.\n",
      "\n",
      "11월 24일 YWCA 위장 결혼식에 참석하였다가 사건에 연루되어 윤보선과 함께 재판정에 섰다. 1980년 1월 YWCA 위장결혼식 사건 선고 공판에 출석하였다. 1980년 1월 25일 수경사 보통군법회의의 최종상고심에서 윤보선은 징역 2년, 함석헌은 징역 1년을 선고받았으나 후에 복권되었다. 1980년 신군부 즉 전두환 정권의 탄압으로 《씨알의 소리》는 강제 폐간되었다가, 1988년 12월 복간되어 2011년 7월 현재 217호까지 출간되어오고 있다.\n",
      "\n",
      "제5공화국을 거치면서도 민주화운동을 계속하다가 1984년에는 민주통일 국민회의 고문을 지냈다. 1985년 민주쟁취 국민운동본부 고문이 되었다.\n",
      "\n",
      "그는 국가주의와 민족주의에 반대하였다. 한 인터뷰에서 그는 '민족통합을 참으로 하려면 우리의 대적이 누군가부터 분명히 알아야 합니다. 우리를 분열시킨 도둑이 누구입니까? 일본? 미국? 소련? 중공? 아닙니다. 어느 다른 민족이나 이데올로기 때문이 아닙니다. 국민을 종으로 만드는 국가지상주의 때문입니다. 이제 정치는 옛날처럼 다스림이 아닙니다. 통치가 아닙니다. 군국주의 시대에조차 군림은 하지만 통치는 아니한다는 말이 있었습니다. 참 좋은 군주는 그래야 한다 말입니다. 그런데 이 민주주의 시대에, 나라의 주인이 민중이라면서 민중을 다스리려해서 되겠습니까? 분명히 말합니다. 남북을 구별할 것 없이 지금 있는 정권들은 다스리려는 정권이지 주인인 민중의 심부름을 하려는 충실한 정부가 아닙니다. 그런 것들이 설혹 통일을 한다해도 그것은 정복이지 통일이 아닙니다. 민중의 불행이 더해질 뿐입니다. 나는 그래서 반대합니다.'라고 밝히기도 했다. 국가주의와 민족지상주의는 개인으로 하여금 권리와 자유를 스스로 반납하는 주요한 근거가 된다는 것이 그의 견해였다.\n",
      "\n",
      "1984년 민주쟁취국민운동본부 고문에 위촉됐다. 또한 동아일보로부터 제1회 인촌상을 수여받았다.\n",
      "\n",
      "성서뿐만 아니라 동서양의 각 고전을 섭렵하여 자신의 사상으로 소화하여, 씨알사상이라는 비폭력, 민주, 평화 이념을 제창하였다. 비폭력주의 신조로 말미암아 “한국의 간디”라는 별명을 가지고 있기도 하다. 사회 평론뿐만 아니라 《도덕경》 등의 각종 동양 고전 주해도 행하였고, 그리고 시를 창작하기도 했다. 1989년 서울대학교 병원에서 입원, 그해 서울대 병원에서 별세하였다(향년 87세).\n",
      "\n",
      "장지는 경기도 연천군 전곡읍 간파리의 가족산에 매장되었다가, 2002년 독립유공자로 선정되어 건국포장 수훈 이후 묘소가 대전 현충원(애국지사 제3-329 묘역)으로 이장되었다.\n",
      "\n",
      "일본 유학 시절 우치무라 간조의 제자였던 함석헌은 김교신, 송두용 등과 함께 초창기 한국 무교회주의 기독교 운동을 하였고, 퀘이커 모임(1961년과 1967년)을 계기로 퀘이커 신자가 되었다. 상훈으로 1987년 제1회 인촌상과 2002년 건국포장을 받았다.\n",
      "\n",
      "일대기로 《내가 본 함석헌》, 《함석헌 평전》이 있다.\n",
      "\n",
      "그는 김교신 등과 함께 무교회주의 운동을 하기도 했다. 이는 일본 유학 시절, 동경고등사범학교 재학 중에 일본인 무교회주의자 우치무라 간조(內村鑑三)의 성서연구에 깊이 영향을 받고 김교신(金敎臣), 송두용(宋斗用), 정상훈(鄭相勳) 등과 함께 교회에 다니지 않고도 신앙을 유지하는 무교회주의 신앙클럽을 결성하였다.\n",
      "\n",
      "귀국 후에도 무교회주의에 대한 신념을 버리지 않았다. 일본인 신학자 우치무라 간조의 성서집회의 영향을 받은 그는 이후 줄곧 무교회주의를 주장하게 되었다.\n",
      "\n",
      "2010년 함석헌이 사회진화론 추종자인가 아닌가 하는 내용을 두고 관련 학계에서 논란이 일고 있다. 2009년 3월 함석헌평화포럼 공동대표인 김영호 인하대 명예교수는 한길사에서 30권으로 발간한 ’함석헌 저작집’에 실은 글 '함석헌 저작집 발간에 부치는 말'에서 그가 사회진화론자라고 주장했다. 당시 함석헌씨알사상연구원장이던 김영호는 함석헌을 사회진화론자로 소개하며, 함석헌 사상에서 거듭 반복되는 일관된 주제 가운데 하나로 사회진화론을 들었다.\n",
      "\n",
      "이에 대해 함석헌이 창간한 잡지 ’씨알의 소리’ 편집위원인 김상봉 전남대 교수는 '씨알의 소리' 2010년 1~2월호에 반론인 '함석헌과 사회진화론의 문제'를 실어 “함석헌의 철학과 사회진화론은 물과 기름처럼 양립할 수 없는 사상”이라고 반박했다. 김상봉 교수는 “사회진화론은 전쟁으로 열등한 종족이 도태되고 상대적으로 우수한 종족들만이 살아남아 인류가 발전했다는 것”이라며 “사회진화론자들은 약자가 도태되는 것은 자연적인 필연이므로 이를 인위적으로 막는 것은 자연법칙을 거스르는 일이라고 본다”고 설명했다.\n",
      "\n",
      "이어 그는 “만물을 짓고, 만물을 유지하고, 뜻을 이뤄가는 것은 힘이 아니라 사랑”이라고 말한 함석헌의 글을 인용하며 함석헌 사상은 ’힘의 철학’이 아니라 '사랑의 철학'이기 때문에 사회진화론과 양립할 수 없다고 반박했다. 김상봉은 이어 함석헌이 ’생명은 나와 남을 구별하지 않는 하나’라고 지적하였다. 김상봉은 함석헌이 평소 민족이기주의와 국가지상주의를 비판했다는 점을 지적하며 “(함석헌에게) 사회진화론이라는 이름표를 붙이는 것이 가능하지 않다”고 강조했다.\n",
      "\n",
      "2010년 김영호는 3월 16일 열린 함석헌학회 창립총회 기념 학술발표에서 ’함석헌과 사회진화론’이라는 제목의 글을 통해 김상봉 교수의 주장을 재반박하고 나섰다. 김영호 교수는 ’함석헌은 사회/전체의 진화를 주장하지 않았는가’라는 부제가 달린 이 글을 통해 \"김상봉 교수의 주장은 자신이 쓴 '사회 진화론'을 '사회다윈주의(Social Darwinism)'로 오해한 것'이라고 반박하였다. 그에 따르면 ’사회진화론’에는 김상봉 교수가 받아들인 '사회다윈주의' 말고도 여러 가지 다른 일반론이 있다고 하였다. 그는 함석헌이 쓴 “지금까지 생각의 주체는 개인이었지만 앞으로는 커뮤니티이다. 그런 역사의 진화단계가 지금이다”라는 글을 인용하며 함석헌이 전체사회, 곧 인류공동체로서의 사회의 진화를 통찰했다고 강조하였다.\n",
      "\n",
      "함석헌은 '누가 나처럼 수줍은 놈을 미친놈을 만들어 놓았느냐'라고 하기도 했다.\n",
      "\n",
      "고려대학교 화학공학과 교수를 역임한 철학자 김용준은 함석헌이 철학자라고 하였다. 그는 \"나는 화학 빼고는 다 함선생님한테 배웠다고. 요즘 사람들은 함석헌하면 마치 주먹질만 하는 사람으로 아는데 그것은 넌센스야. 그건 함선생님의 일부분이고 80퍼센트는 도를 찾아 헤맸던 구도자\"라고 하였다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "백남준\n",
      "\n",
      "백남준(白南準, , 1932년 7월 20일 ~ 2006년 1월 29일, 서울 출생, )은 한국 태생의 세계적인 비디오 아트 예술가, 작곡가, 전위 예술가이다. 본관은 수원(水原).\n",
      "\n",
      "생전에 뉴욕, 쾰른, 도쿄, 마이애미와 서울에 주로 거주한 그는 여러 가지 매체로 예술 활동을 하였다. 특히 비디오 아트라는 새로운 예술의 범주를 발전시켰다는 평가를 받는 예술가로서 '비디오 아트의 창시자'로 알려져 있다.\n",
      "\n",
      "현 서울특별시 종로구 서린동 (구 일제 강점기 경기도 경성부 서린정) 출신이다. 친일파인 아버지 백낙승과 어머니 조종희 사이의 3남 2녀 중 막내로 태어났다. 그후 종로구 창신동 197번지 소위 \"큰대문집\"에서 18세까지 살았다. 수송국민학교와 경기제1고등보통학교를 다니면서 피아니스트 신재덕에게 피아노 연주를, 이건우에게 작곡을 각각 배웠다. 이때 한국이 낳은 작곡가 김순남을 사사했다. 1949년 그는 홍콩 로이덴 스쿨로 전학했으며, 한국 전쟁이 발발하기 이전 가족이 일본으로 이주했다. 그 후 일본으로 건너가 1952년 도쿄 대학교 문과부에 입학했다. 2년 후 미술사학 및 미학으로 전공을 정했지만, 실제로는 일본 당대의 작곡가 모로이 사부로, 미학자 노무라 요시오 등에게서 작곡과, 음악사학을 공부했다. 졸업 논문은 ‘아르놀트 쇤베르크 연구’이다.\n",
      "\n",
      "1956년 백남준은 졸업과 함께 독일로 유학을 떠나 뮌헨 대학교 및 쾰른 대학교 등에서 서양의 건축, 음악사, 철학 등을 공부하였다. 뮌헨 대학교 입학 1년 후에는 프라이부르크 국립 음악 대학교로 옮겨 볼프강 포르트너 교수에게 배우지만, 곧 쇤베르크 이후 현대음악의 실험이 활발히 진행되던 다름슈타트 하기 강좌에 참여했다. 1958년 그 곳에서 현대음악가 존 케이지를 만나 그의 음악에 대한 파괴적 접근과 자유정신으로부터 깊은 영감을 얻었다. 이 영감은 \"세계의 역사는 우리에게 알려준다. 주어진 게임에서 이길 수 없다면 규칙을 바꿔라\"라는 것으로 규정된다. 이후 1950년대부터 활발해지기 시작한 독일 라인 지역의 액션뮤직의 현장에서 백남준은 ‘아시아에서 온 문화테러리스트’(앨런 카프로)라고 불릴 정도의 탁월한 퍼포먼스 아티스트로 활약했다. 1959년 ‘존 케이지에게 보내는 경의’에서 음악적 콜라주와 함께 피아노를 부수는 퍼포먼스를 선보이는 것을 시작으로, 바이올린을 단숨에 파괴하거나(바이올린 솔로) 존 케이지가 착용한 넥타이를 잘라버리는 퍼포먼스(피아노 포르테를 위한 연습곡)가 특히 유명하다. 이 초기 퍼포먼스에 대해 백남준은 스스로 \"충격, 표현주의, 낭만주의, 클라이맥스, 놀라움, 기타 등등을 보여준 것\"이라고 표현한 바 있다. 1961년 카를하인츠 슈토크하우젠의 음악 퍼포먼스 ‘오리기날레’에서 머리와 넥타이로 잉크를 묻혀 두루마리에 흔적을 남기는 독특한 퍼포먼스 심플 머리를 위한 선율을 보여주기도 했다. 1960년대 초반 조지 마키우나스, 요셉 보이스 등과 의기투합하여 플럭서스 활동을 함께 전개했다. 다다이즘에 영향을 받은 플럭서스는 헤라클레이투스가 주장한 ‘변화 생성의 흐름’이라는 개념을 받아들여 \"목적이 없는 자유, 실험을 위한 실험\"이라는 명목 하에 이벤트와 퍼포먼스 그리고 전위음악에 주력했고, 곧 유럽과 아시아 및 미국 등 세계로 퍼져나갔다.\n",
      "\n",
      "1961년 백남준은 작곡가 슈토크하우젠이 중심이 된 쾰른의 WDR 전자음악 스튜디오에 출입했으며, 이때 1950년대부터 노버트 위너에 의해 제안된 '사이버네틱스' 개념 하에서 전자공학을 공부한 것으로 알려져 있다. 특히 레이다와 TV 작업에 몰두했던 독일 작가 칼 오토 괴츠의 실패를 거울 삼아서 2년여 동안 홀로 TV를 활용한 미디어 아트로서의 가능성을 탐문하고 실험했다. 그 성과를 바탕으로 1963년 독일 부퍼탈 파르나스 갤러리에서 자신의 첫 번째 전시 ‘음악의 전시-전자 텔레비전’을 열었으며, 13대의 실험적인 TV를 통해 훗날 비디오 아트라고 불리게 되는 초기 형태를 보여주었다. 이 전시는 백남준이 자신의 즉흥음악 또는 무음악의 발상에 기초한 실제 퍼포먼스, 그 흔적과 결과물처럼 유럽에서 자신이 진행해온 작업의 성과와 함께 TV를 비롯한 미디어로 새로운 예술의 형태를 시도하는 작업이 공존하고 있었다. ‘적분된 피아노’, ‘랜덤 액세스 뮤직’, ‘레코드 샤슐릭’같은 20세기 전위음악에 젖줄을 대고 있는 실험적 음악의 시도와 ‘잘린 소머리’, ‘파괴된 누드 마네킹’, ‘보이스의 피아노 파괴 퍼포먼스’'걸음을 위한 선' '바람을 위한 선' 같은 우상파괴적 설치 작업 및 참여예술 형태의 퍼포먼스가 함께 펼쳐졌다. 청년 백남준은 이러한 전시 내용을 ‘동시성’, ‘참여’, ‘임의접속’ 등등에 관한 16개의 테마로써 정리하는 종합적인 큐레이팅 전시로 보여주었기 때문에 최근 독일, 오스트리아 등지의 연구자들 사이에서 이 전시의 중요성을 재평가하면서 아카이빙 작업과 연구가 점차 활발해지는 추세에 있다.\n",
      "\n",
      "1964년 백남준은 일본으로 건너가 '로봇 K-456'을 제작했으며, 곧 세계 예술의 중심지 뉴욕으로 이주했다. 뉴욕 언더그라운드 필름 운동의 중심지 중 하나였던 시네마테크 필름메이커스에 관여했으며, 스스로 영상 작업을 진행하기도 했다. 1965년 소니의 포타팩(세계 최초의 휴대용 비디오카메라)으로 미국 뉴욕을 첫 방문 중이던 교황 요한 바오로 6세를 촬영하여 곧바로 그 영상을 ‘카페 오 고고’에서 방영했다. 이것이 미술사에서는 한동안 공식적인 비디오 아트의 시작으로 기록되어 있었다. 지금은 1963년 첫번째 전시를 비디오아트의 기점으로 보고 있다. 또한 첼로 연주자이자 뉴욕 아방가르드 페스티벌의 기획자였던 샬럿 무어먼과 함께 비디오 아트와 음악을 혼합한 퍼포먼스 작업을 활발히 펼쳤다. 특히 1967년 음악에 성적인 코드를 집어넣은 백남준의 ‘오페라 섹스트로니크’에서 샬럿 무어먼은 누드 상태의 첼로 연주를 시도하다가 뉴욕 경찰에 체포되어 큰 사회적 파장을 불러일으켰다. 그 결과로 인해 예술 현장에서 누드를 처벌할 수 없다는 뉴욕의 법 개정이 이루어지는 획기적인 진전이 일어난다. 이후에도 미디어 아트가 미국 뉴욕을 중심으로 서서히 득세해가는 시대적 조류 속에서 두 사람은 ‘살아있는 조각을 위한 TV 브라’, ‘TV 첼로’, ‘TV 침대’ 등등 미디어 테크놀로지와 퍼포먼스를 결합한 많은 예술활동을 전개했다.\n",
      "\n",
      "1974년부터 백남준은 영상으로서의 비디오 아트를 새로운 미술적 방법인 설치 미술로 변환하여 다양하게 진행했으며, 그에 따라 ‘TV 붓다’, ‘달은 가장 오래된 TV다’, ‘TV 정원’, ‘TV 물고기’ 등등 많은 대표작을 선보였다. 이 작품들은 비디오 아트와 생명의 상징을 전자적으로 결합하여 테크놀로지로 물든 현대 사회의 새로운 합성적 생명력을 추구했다는 평판을 얻었다. 특히 'TV 붓다'는 그의 초기 비디오 설치의 경향을 잘 보여주는 대표작으로서 가장 널리 알려졌다. 1960년대 후반부터 미국의 문화적 환경이 미디어 테크놀로지에 호의적으로 변화하면서 폭발적인 수준의 미디어 전시가 빈발했고, 백남준의 비디오 아트는 그룹전 형태로 수많은 전시에 활발하게 참여했다. 1974년 뉴욕 에버슨 미술관 개인전과 함께 이라는 예술과 기술을 교차시키는 하이브리드에 관한 저작을 내놓아 미디아 아트의 이해를 도왔으며, 1982년 뉴욕 휘트니 미술관에서 개최된 ‘백남준 회고전’을 통해 그의 예술 세계가 뉴욕을 중심으로 미국 사회에 많이 알려지는 계기가 되었다.\n",
      "\n",
      "1970년대 중반부터는 뉴욕 WNET 방송국, 보스턴 WGBH 방송국과 협력하여 자신의 비디오 아트를 공중파 TV에서 방송했고, 이는 네트워크 방송을 끌어들여 예술 세계의 영역 확장을 꾀한 놀라운 시도였다. 나아가 1984년 1월 1일 ‘굿모닝 미스터 오웰’은 세계적인 아티스트들의 퍼포먼스를 뉴욕 WNET 방송국과 파리 퐁피두 센터를 연결한 실시간 위성 생중계로 방송하여 전 세계적 반향을 불러일으켰다. 샌프란시스코와 서울까지 연결된 이 국제적인 규모의 위성 아트에는 로리 앤더슨, 피터 가브리엘, 오잉고 보잉고, 존 케이지, 요셉 보이스, 앨런 긴즈버그, 이브 몽탕 등의 예술가과 대중문화의 스타가 다수 참여했으며, 전 세계 2천 5백만명(재방송 포함)이 시청하였다. 이로써 전세계적인 차원의 대중적 각인이 이루어졌고, 마치 대중스타처럼 성가를 높였다. 이후에도 ‘위성 아트’ 3부작으로 명명된 ‘바이 바이 키플링’(1986), ‘손에 손잡고’(1988) 등이 이어져 위성 연결을 통한 전세계의 네트워크가 어떻게 새로운 부족사회를 낳는지 실감시켰다.\n",
      "\n",
      "1984년 일본 도쿄 소게쓰[草月]홀에서 백남준과 요셉 보이스가 공동으로 참여한 퍼포먼스 '코요테 콘서트 II'가 펼쳐졌으며, 이들이 각각 몽골의 늑대 울음소리와 초원의 달빛을 음악적으로 표현한 것을 통해 1961년 첫 만남부터 계속 이어온 공동의 관심사가 무엇인지 알려지기 시작했다. 그러나 이들의 이후 퍼포먼스 계획은 요셉 보이스의 죽음과 함께 미완으로 끝났다.\n",
      "\n",
      "1992년 '비디오 때, 비디오 땅' 전시는 독일 쿤스트 할레와 스위스 쮜리히에서 진행된 전시의 서울 투어전시로서 당시 과천 막계동에 자리잡은 지 몇 년 되지 않았던 국립현대미술관 과천관에 총 관람 인원 20만명이 찾은 첫번째 전시로 기록되었다. 이 전시의 주요한 작품은 '나의 파우스트' 시리즈이다. 1993년 백남준은 독일 작가 한스 하케와 함께 베니스 비엔날레 독일관 작가로 초대되어 국가전시관 부문에서 황금사자상을 수상했다. '문명의 동서남북'이라는 주제의 이 전시에서 그는 북방 유라시아의 유목 문화를 배경으로 전자적 소통을 시도하는 비디오 로봇 형태의‘칭기스칸의 복권’, ‘마르크폴로’, ‘훈족의 왕 아틸라’,‘스키타이의 왕 단군’, ‘로봇 전사’, ‘고대기마인물상’ 같은 작품들을 중심으로 다수의 작품을 내놓았다.\n",
      "\n",
      "1995년 백남준은 제1회 광주 비엔날레 태동의 산파 역할을 하며, 한국 미술이 국제적으로 진출할 수 있도록 조력자 역할을 수행했다. 제1회 광주 비엔날레는 국내외 총 관람객이 160만 명에 달하는 성공을 거두었고, 특히 백남준이 직접 관여한 ‘INFO Art’전이 주목받았다. 또한 백남준은 같은 해 베니스 비엔날레 국가전시관 부문에 한국관을 설치하는 일에 결정적인 역할을 했다. 이로써 한국 미술이 세계 미술계에 진출하는 교두보가 마련되었다고 하겠다. 같은 해 그의 예술적 정수가 담긴 일렉트로닉 수퍼하이웨이 전시를 진행했다. 1996년 4월 9일 뇌졸중으로 쓰러졌으며, 6개월만인 그해 10월에 재기했다. 2000년 뉴욕 구겐하임 미술관에서 ‘백남준의 세계’ 라는 대규모 회고전이 열렸으며, 이때 백남준은 레이저 아트 ‘야곱의 사다리’, ‘삼원소’ 등을 전시한 바 있다.\n",
      "\n",
      "2006년 1월 29일, 미국 마이애미의 자택에서 노환으로 75세로 별세, 유해가 서울, 뉴욕, 독일에 나눠서 안치되었다..\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "2002년\n",
      "\n",
      "2002년은 화요일로 시작하는 평년이며, 이 해는 21세기의 첫 대규모 행사의 해이다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "12월 19일\n",
      "\n",
      "12월 19일은 그레고리력으로 353번째(윤년일 경우 354번째) 날에 해당한다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "5월 31일\n",
      "\n",
      "5월 31일은 그레고리력으로 151번째(윤년일 경우 152번째) 날에 해당한다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "6월 30일\n",
      "\n",
      "6월 30일은 그레고리력으로 181번째(윤년일 경우 182번째) 날에 해당하며, 6월의 마지막 날이다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "우크라이나\n",
      "\n",
      "우크라이나()는 동유럽 국가다. 남쪽과 남동쪽으로는 흑해와 아조프해, 동쪽과 북동쪽으로는 러시아, 북쪽과 북서쪽으로는 벨라루스, 서쪽으로는 폴란드, 슬로바키아, 헝가리, 남서쪽으로는 루마니아, 몰도바와 접한다. 키이우가 수도이며 가장 큰 도시다. 동유럽 평원과 이어져 있으며 기후는 비교적 온화한 편이다. 법적 공용어는 우크라이나어이고, 인구 대부분은 우크라이나어를 사용하지만, 대부분 동부 인구(주로 동부 지역과 동남부 지역, 오데사 지역)는 러시아어 사용자이기도 하다. 주요 도시로는 키예프, 도네츠크, 드니프로, 하르키우, 르비우, 오데사, 자포리자가 있다. 2014년 3월 18일 러시아가 크림반도를 합병함에 따라 행정력이 크림반도에 미치지 못하지만, 국제사회는 대체로 크림반도를 우크라이나의 일부라는 태도를 견지하고 있다.\n",
      "\n",
      "중세 초 루스 카간국으로부터 키예프 루스로 이어진 우크라이나는 오랫동안 투르크족·몽골족 등 지배를 받았다. 19세기까지 대다수 우크라이나 영토가 러시아 제국에 통합되었고, 나머지 부분은 오스트리아-헝가리 통제 아래 있었다. 우크라이나는 러시아 혁명 후 혼란과 끊임 없는 전쟁 속에서 여러 차례 독립을 시도하여 1917년에 민족국가를 건설했으나, 1922년에 소비에트 연방에 강제 합병되었다. 1923년 소비에트 연방 헌법 적용을 받으며 우크라이나 소비에트 사회주의 공화국이란 이름의 구성국으로 존재했다, 1991년 소련 해체와 함께 독립하였다.\n",
      "\n",
      "지하 자원이 풍부하여 도네츠 탄전의 석탄, 크리보이로그의 철광석, 카르파티아 유전과 천연가스, 그 밖에 망간, 우라늄, 식염, 칼리염, 석회석 등을 산출한다. 산업으로는 석탄·철광·선철 생산에서 중요성 있다. 풍부한 수력 전기를 이용하여 기계 제조 공업·화학 공업이 크게 발달했으며 유수 공업 지대를 이루고 있다. 석탄업, 철강업, 기계 제조업, 화학 공업 중심은 돈바스·드니프로 주이며, 드니프로 강 하구에서 키이우 사이 6개 수력 발전소가 단계상(段階狀)으로 건설되어 있다. 우크라이나 경지율은 약 70%에 이르고 있어, 겨울밀·옥수수·보리·사탕무·해바라기·포도의 재배, 가축 사양 등에서는 구 소련 시절 매우 중요한 지위를 차지하고 있었다. 온난한 크림 반도 남단과 광천이 솟는 카르파트 지방은 중요한 관광·보양지다. 러시아 작가 니콜라이 고골의 작품 〈타라스 부리바〉 배경으로도 알려졌다. 공용어는 우크라이나어를 쓰고, 우크라이나인 대다수는 우크라이나 정교회를 믿는다.\n",
      "\n",
      "국토 면적 603,700km에 576,700km (크림 공화국과 세바스토폴 제외시) 해안선 길이는 2,782km로, 우크라이나는 세계에서 44번째로 큰 국가(중앙아프리카 공화국보다는 작고, 마다가스카르보다는 크다.)이다. 또한, 유럽에서는 두 번째로 큰 나라이다. 어떤 사람들은 유럽의 중심이 우크라이나 서쪽의 라키브 마을 인근이라고 한다. 하지만 여전히 유럽의 지리적 중심을 보는 관점에 대해 논쟁이 있다.\n",
      "\n",
      "우크라이나는 비옥한 평원, 스텝, 고원이 있으며, 그들을 지나가는 강이 흑해로 흘러들어간다. 거의 남쪽 만으로 강이 빠져나가고 남동부 지방에는 다뉴브 삼각지가 루마니아와 국경을 접하고 있다. 우크라이나의 대표적인 산은 카르파티아 산맥으로서 우크라이나 서부에 위치한다. 우크라이나에서 가장 높은 산은 호베를라 산으로 높이는 2,061m이다. 크림 반도를 따라서 넓은 해안선이 펼쳐진다.\n",
      "\n",
      "우크라이나에 분포하고 있는 초르노젬(흑토) 지대는 비옥한 토양으로 유명하다. 그 밖에 아스팔트, 무연탄, 철, 망가니즈, 크롬, 타이타늄, 납, 아연, 알루미늄, 수은, 니켈, 천연 가스, 석유 등 70여 가지의 종류에 달하는 천연 자원이 매장되어 있다.\n",
      "\n",
      "대개 온화한 대륙성 기후를 보이는데 남쪽의 크림반도 인근에서는 온난 습윤 기후가 나타나기도 한다. 비는 북서부 지방에 가장 많이 내리고 동부와 남동부 지역은 덜 오는 편이다. 겨울은 흑해 인근 지방이라면 따뜻하지만 내륙으로 들어갈수록 대체로 추워진다. 여름에는 전반적으로 따뜻하지만 남쪽 지방은 무덥다.\n",
      "\n",
      "우크라이나(Україна)라는 국호는 고대 동슬라브어 표현인 Оукраина/Oukraina에서 유래하였으며, 우(Оу)는 전치사에 해당되며,\n",
      "\n",
      "크라이(краи)는 땅 또는 변경, 경계를, 나(на)는 접미사에 해당되는 단어이며, 크라이나(країна)는 러시아어에서 파생된 크라이(край)와 비슷한 어원을 가지며, 우크라이나의 국명 뜻을 풀이하면, \"변방의 지대\", \"변방의 땅\"이라는 의미가 있으며, 동슬라브어로 국가, 땅, 영토, 변방, 끝자락 등의 의미를 뜻한다.\n",
      "\n",
      "우크라이나 역사는 중앙아시아에서부터 건너와 동유럽을 정복한 튀르크 민족들의 관계를 빼 놓을 수 없다. 3세기부터 시작한 중앙아시아 투르크 민족들의 유럽 침공과 동슬라브족 정복 그리고 이주는 5세기부터 10세기까지 사바르 카간국에 이어 아바르 카간국 그리고 하자르 카간국까지 이어진다. 동유럽 동슬라브 원주민들은 사바르 카간국에 정복당해 프랑크족들과 대립하기도 하였고 하자르 카간국의 우크라이나 초원 정복으로 인해 동슬라브 문화는 서유럽의 문화와는 조금 이질적인 특징을 가지게 되었다. 하자르 카간국의 영향에 따라 동슬라브족으로서의 정체성이 생기기 시작하였고 8세기에서 9세기에 루스 카간국이라는 고대 투르크어인 군주 칭호인 카간을 자칭하는 북게르만족 루스인의 첫 국가가 등장하였다. 그 전까지는 벨라루스와 우크라이나를 지배했던 중앙아시아 투르크 민족들이 카간을 자칭하였으나 그 지배 아래 동슬라브인들도 완전히 종속과 동화되어 동슬라브인의 정체성이 확립되었고 그 후 동슬라브인들이 카간을 자칭하였다.\n",
      "\n",
      "키예프 루스는 10세기까지 중앙아시아 투르크 민족의 영향을 받았고 이에 따라 류리크 왕조의 시조인 류리크 또한 위대한 카간이자 왕으로 불렸다는 기록이 존재한다. 862년경 전까지는 확실히 카간이라 칭한 루스인들이 페르시아 사서와 동, 서 로마 기록에 남아 있다. 여기에 원초연대기의 기록에서는 루스인들의 카간으로 알려진 류리크가 동슬라브족 지역에 정착하면서 류리크 왕조와 키예프 루스가 나타나며 카간이라는 호칭보다는 크냐지 또는 벨리키 크냐지라는 호칭이 자주 쓰이게 된다.<ref><дека името Украина доаѓа од старословенскиот поим \"украина\"<nowiki> што значи „гранична област“ или „крајина“\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "가위\n",
      "\n",
      "가위()는 손으로 잡아 종이 등을 쉽게 자를 수 있게 하는 도구이다. 두 장의 얇은 금속 날을 결리지 않도록 엇갈리게 나사로 엮어, 그 두 날이 지레의 원리로 움직이면서 서로 부딪치면 절단력이 발생한다. 플라스틱 판, 얇은 철판, 머리카락, 끈, 종이, 옷감, 강삭 등을 자를 때 쓰인다.\n",
      "\n",
      "핑킹가위는 무늬를 내며 자를 때 사용하는 가위이다. 무늬의 종류는 여러가지이며 물결무늬 지그재그 톱니모양 등이 있다.\n",
      "\n",
      "쪽가위는 실 따위를 자를 때 사용하는 가위이다. 발견된 가위 중 가장 오래된 가위가 쪽가위 형태로 제작되었다. 16세기까지 유럽에서 사용되었으며, 오늘날에도 쪽가위의 형태를 변형한 가위를 찾을 수 있다.\n",
      "\n",
      "X자 형태의 날을 지닌 가위이다. 서기 100년경 고대 로마에서 쪽가위 디자인을 각색하면서 발명되었다.\n",
      "\n",
      "지렛대의 원리에 바탕을 둔 것으로 지레의 작용점 · 받침점 · 힘점의 상호관계에 의하여, 힘점이 작용점과 받침점 사이에 있는 원지점식(元支點式), 지레의 받침점이 힘점과 작용점의 사이에 있는 중간지점식, 작용점이 힘점과 받침점 사이에 있는 선(先)지점식의 3가지로 구별된다.\n",
      "\n",
      "따라서 이것을 응용한 가위도 3종으로 대별된다. 원지점식에 속하는 것으로서 손자수용 가위 · 잎따기가위 · 망(綱)베기가위 등이 있고, 중간지점식에 속하는 것으로는 재단가위 · 꽃가위 · 전정가위 · 전지가위 · 잔디가위 · 양철가위 · 버튼홀가위 · 의료가위 · 이용(理容)가위 등이 있다. 선지점식에 속하는 것은 눌러서 자르는 가위와 과일따기 가위 등이 있다.\n",
      "\n",
      "지금까지 발견된 세상에서 가장 오래된 가위는 기원전 1000년경 메소포타미아에서 만들어진 가위다. 특히 로마 시대의 유물로 가위가 많이 발견되었으며, 이 시대 가위는 라틴 문화 중기에 중부 및 북유럽 등으로 전해졌다. 라틴 문화의 가위는 남자의 무덤에 부장되어 있는 것으로 보아, 알려져있던 양모를 깎기 위한 것이 아니고 수염을 깎는 데 쓰인 것으로 추측된다. 그리고 로마 시대의 유물에서 발견된 날이 짧고 튼튼하게 만들어진 가위는 철사나 튼튼한 실, 얇은 철판등을 자르는 데 사용된 것으로 보인다.\n",
      "\n",
      "한국에서 발견된 가장 오래된 가위는 경주 분황사 모전석탑에서 발견된 가위이며, 모양이나 쓰임새가 중국에서 발견된 것과 같은 걸로 보아 중국에서 건너왔을 것이라고 학자들은 말한다. 전 세계에서 발견된 유물을 비교해볼 때 가위는 서양에서 처음 만들어져 사용되다가 중국에 전해졌을 거라고 추측할 수 있다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "위키\n",
      "\n",
      "위키(, )는 불특정 다수가 협업을 통해 직접 내용과 구조를 수정할 수 있는 웹사이트를 말한다.\n",
      "\n",
      "또한 일반적인 위키에서 텍스트는 단순화된 마크업 언어(위키 마크업)을 이용하여 작성되며, 리치 텍스트 에디터의 도움을 받아 편집하기도 한다. 위키는 지식경영이나 기록 등 다양한 용도로 이용된다. 공동체용 웹사이트나 조직 내 인트라넷에 쓰이기도 한다. 그러나 주로 개인적인 용도로 이용되는 위키도 있는데, 이를 개인 위키라고 한다.\n",
      "\n",
      "최초의 위키 소프트웨어인 위키위키웹(WikiWikiWeb)을 만든 워드 커닝엄은 위키를 \"동작하는 가장 단순한 온라인 데이터베이스\"라고 설명했다. \"위키\"는 \"빠른\"을 뜻하는 하와이어 \"wiki\"(발음은 위티[ˈwiti]나 비티[ˈviti])에서 따왔다.\n",
      "\n",
      "워드 커닝엄이 보 뢰프와 같이 쓴 《위키 방식: 웹 상의 빠른 협업(\"The Wiki Way: Quick Collaboration on the Web\")》이라는 책에서, 위키의 가장 핵심적인 개념을 다음과 같이 꼽았다.\n",
      "\n",
      "위키는 간단한 마크업 언어와 웹 브라우저를 이용, 함께 문서를 작성하는 공동체를 가능케 한다. 위키 웹사이트의 한 문서는 \"위키 문서\"라 부르며, 하이퍼링크로 서로 연결된 전체 문서를 \"위키\"라 한다. 위키는 본질적으로 정보를 만들고, 찾아보고, 검색하기 위한 데이터베이스다. 위키는 비선형적인, 진화하는, 복잡하게 얽힌 문서, 토론, 상호 작용을 할 수 있게 돕는다.\n",
      "\n",
      "위키 기술을 정의하는 특징은 문서를 간단히 만들고 고칠 수 있다는 점이다. 일반적으로 수정이 반영되기 전에 승인이나 검토의 과정이 없다. 대부분의 위키는 사용자 등록을 요구하지 않고, 일반에게 공개되어 있다. 많은 편집자가 실시간으로 만들며, 즉시 온라인으로 배포된다. 단 이는 시스템의 남용을 유발할 수 있지만 주로 장점이 더 많다. 개인 위키는 문서를 고치거나 읽기 위해 사용자 인증을 요구하기도 한다.\n",
      "\n",
      "일반적으로 위키 문서는 위키 마크업이라 불리는 간단한 마크업 언어로 이뤄져 있다. 예를 들어 별표(*)로 시작하는 줄은 목록을 표시하는데 사용된다. 위키 마크업의 문법은 위키 소프트웨어마다 다르며, 일부는 HTML을 직접 사용할 수 있도록 하기도 한다.\n",
      "\n",
      "점차 사용자가 위지위그(WYSIWYG) 편집을 할 수 있도록 지원하는 위키가 늘고 있다. 위지위그 편집은 위키 마크업의 모든 기능을 제공하지 못하므로, 이들 사이트에서는 편집자가 위키 문서를 직접 수정하는 방법을 제공하기도 한다.\n",
      "\n",
      "대부분의 위키는 위키 문서의 변경 이력을 보존하고 있다. 편집자는 쉽게 문서를 예전 판의 내용으로 되돌릴 수 있으며, 이는 사용자의 실수나 고의적 훼손 때문에 필요한 기능이기도 하다. 미디어위키를 비롯한 많은 위키 소프트웨어는 문서를 편집할 때, \"편집 요약\"을 남길 수 있도록 한다. 이 편집 요약은 문서 본문에는 남지 않으나, 문서의 이력에서 편집 이유를 설명할 수 있도록 지원한다.\n",
      "\n",
      "대부분의 문서는 다른 문서를 가리키는 수많은 하이퍼링크를 포함하고 있다. 사용자는 필요에 따라 다른 문서의 목차나 색인을 따로 구축할 수도 있다. 여러 편집자가 임의로 문서를 만들고 삭제하기 때문에 수동으로 이런 목차나 색인을 유지하는 것은 쉬운 일은 아니다. 위키 소프트웨어는 이를 돕기 위해 분류나 태그 기능을 제공한다.\n",
      "\n",
      "대부분의 위키는 현 문서를 가리키는 다른 문서를 찾는 백링크 기능을 제공한다.\n",
      "\n",
      "위키에서 존재하지 않는 문서를 가리키는 링크를 만드는 것은 일반적인 일로, 다른 사용자가 자신이 아는 내용을 채울 수 있도록 유도한다.\n",
      "\n",
      "위키의 문서는 문서의 제목과 표기는 다르지만 발음이 같은 등의 경우에 해당되면 그 문서의 제목과 거의 같은 명칭, 혹은 그 문서의 제목과 같은 명칭이 아니지만 그 문서가 설명하는 대상을 가리키는 또 다른 명칭이 있는 경우 넘겨주기를 이용해서 넘겨주기 문서를 만들어 그 명칭으로도 그 문서가 설명하는 대상의 원래 제목과 같은 내용의 문서에 들어갈 수 있다.\n",
      "\n",
      "다른 문서에 대한 링크는 \"링크 패턴\"이라는 문법을 통해 지원된다. 원래 대부분의 위키는 낙타 표기법(CamelCase) 방식으로 문서를 만들고 연결했다. 단어의 첫 글자를 대문자로 하고, 사이의 공백을 지워서 만들 수 있다. 이 방식은 로마자를 쓰는 경우, 쉽게 링크를 만들 수 있다. 한 단어로 되어 있는 문서를 만들 경우, 단어 중간의 한 글자를 임의로 대문자로 만들어서 이용한다. (예를 들어 \"wiki\"라는 문서를 \"WiKi\"로 표기한다거나 한다.) 낙타 표기법을 쓰는 위키는 \"TableOfContents\" 등을 링크로 사용하므로 쉽게 알아챌 수 있다.\n",
      "\n",
      "일부 소프트웨어는 두 단어 사이에 다시 공백을 넣어서 사용자가 보기 좋게 표시해주기도 한다. 그러나 대문자 표기를 되돌리는 건 쉽지 않다. 예를 들어 \"RichardWagner\"는 \"Richard Wagner\"처럼 각 단어가 대문자로 표시되어야 하나, \"PopularMusic\"은 소문자인 \"popular music\"로 표시되어야 한다. 일부 위키는 괄호를 이용한 자유 링크 기능을 지원하기도 하며, 일부는 낙타 표기법 링크 기능을 막기도 한다.\n",
      "\n",
      "대부분의 위키는 문서 제목을 이용한 검색을 지원하며, 일부 위키는 본문 검색을 지원하기도 한다. 검색의 확장성은 위키 엔진이 사용하는 데이터베이스에 따라 좌우된다. 일부 위키는 일반 파일을 사용하기도 한다. 미디어위키도 초기 버전에서는 일반 파일을 저장용으로 사용하기도 했으나, 2000년대 초에 데이터베이스를 사용하도록 다시 작성되었다. 데이터베이스의 색인 기능은 대형 위키에서 빠른 검색을 위해 필요하다. 대안으로 일부 위키는 구글 검색 등 외부의 웹 검색 엔진을 이용하기도 한다.\n",
      "\n",
      "최초의 위키 소프트웨어는 위키위키웹(WikiWikiWeb)으로, 워드 커닝엄이 창안했다. 커닝엄은 1995년에 위키위키웹을 만들기 시작하면서 처음으로 위키의 개념을 고안했고, 위키라는 이름도 지었다. 또한 최초의 위키 서버를 만들기까지 했다. 위키 소프트웨어는 디자인 패턴 모임에서 패턴 언어를 쓰면서 생겼으며, Portland Pattern Repository(PPR)가 최초의 위키였었다.\n",
      "\n",
      "위키에 참가하는 사용자에는 4가지 종류가 있다: 독자, 저자, 위키 관리자, 시스템 관리자. 시스템 관리자는 위키 엔진과 컨테이너 웹 서버의 설치와 유지보수를 책임지는 일을 맡는다. 위키 관리자는 위키의 내용을 유지보수하며 문서에 관한 추가 기능(문서 생성 및 삭제)을 제공받으며 사용자의 접근 권한을 조정(예: 편집 차단)할 수 있다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "지구과학\n",
      "\n",
      "지구과학(地球科學, )은 행성인 지구와 그 주위의 천체를 연구하는 학문들을 묶어 부르는 이름이다. 지구의 환경은 크게 육지, 바다, 대기로 나누어지며, 이러한 환경들은 각각 지구과학의 주요 분야라고 할 수 있는 지질과학, 수문과학, 대기과학 분야의 주요연구대상이 된다. 일반적으로 지구과학으로 불리는 학문들은 대기에서 일어나는 현상을 대상으로 하는 기상학, 지구 표면의 물질을 주로 대상으로 하는 지질학, 바다 현상을 대상으로 하는 해양학, 지구의 깊은 속에서 일어나는 현상을 대상으로 하는 지구물리학과 실용적인 응용분야로서 환경공학 등이 있다.\n",
      "\n",
      "지구과학에는 많은 전문 분야가 포괄되지만 대체로 여섯 가지로 나뉜다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "아오조라 문고\n",
      "\n",
      "아오조라 문고()는 ‘일본어판 구텐베르크 프로젝트’로 불리는 일본의 인터넷 전자도서관으로, 저작권이 풀린 문학작품을 수집, 전자문서화해서 인터넷에 공개하고 있다. 저자 사후 50년이 지난 메이지, 쇼와 시대 초기의 일본 문학 작품이 그 대부분을 차지하고 있고, 일본어 외 문학 작품의 일본어 번역 작품도 다수 있다. 1997년 2월 도미타 미치오, 노구치 에이치, 야마키 미에, 란무로 사테이 등 4명이 창설하여 시작되었다. 2016년 연간 방문객수는 940만 건 이상이다.\n",
      "\n",
      "아오조라 문고에 수록된 작품은 JIS X 0208에 해당되는 한자 범위 내에서 자원봉사자에 의해 아오조라 문고 형식 텍스트파일이나 HTML 파일로 전자화된다. 또 아오조라 문고 수록파일 취급기준에 따라 자유롭게 이용할 수 있기 때문에, 수록된 작품을 PC는 물론 PDA와 휴대전화로도 볼 수 있다. 텍스트 파일을 큰 글자로 인쇄하거나 전용 소프트웨어에 불러들여 시각장애인용으로 이용하는 방안도 기대되고 있다. 아오조라 문고의 열람 소프트웨어는 따로 개발 및 제공되고 있는 것은 없지만, 전자사전이나 아이폰용 어플리케이션 등은 타사에서 개발하여 출시되어 있다.\n",
      "\n",
      "저자 사망 이후 50년이 지나 저작권이 소멸한 메이지 시대부터 쇼와 시대 초기까지의 서적 대부분이 존재한다. 외국 번역작품이나 저자가 무료보기를 인정한 현대작품도 포함된다. 장르는 정치부터 취미까지 다양하지만, 비교적 문학작품(시대소설, 추리소설등의 오락작품 포함)이 많다. 유명작가의 작품이 모두 갖춰져있진 않지만 그래도 일본어작품에 관련해서는 충실하게 갖춰진 편이다. (번역작품의 경우 번역저작권을 문제로 수가 많지 않다.)\n",
      "\n",
      "잘 알려지지 않은 작품을 보존, 소개하는 장점도 있다. 작품 텍스트화는 지금도 현재진행형이며 2011년 3월 15일 현재 등록작품수가 1만권이 넘었다.\n",
      "\n",
      "고전작가인 모리 오가이, 나츠메 소세키, 아쿠타가와 류노스케, 최근의 작가로는 나카지마 아츠시, 다자이 오사무, 하야시 후미코, 미야모토 유리코, 호리 다쓰오, 사카구치 안고, 다카무라 고타로, 나가이 가후, 요시카와 에이지 등 인물의 작품이 있다.\n",
      "\n",
      "아오조라 문고는 자원봉사로 운영되며 열람 역시 무료이다. 서비스 개시 초반에는 보이저 사에서 서버를 제공하였다. 1998년부터 1999년까지는 토미타가 작업 수칙과 매뉴얼을 만들었다.\n",
      "\n",
      "자원봉사로 운영되기 때문에 작품의 입력과 교정 역시 자원봉사자가 한다. 입력은 원본을 보면서 타자입력이나 스캐너로 입력하는 방법으로 이뤄진다. 또 작품을 입력하는 '입력자'와 입력된 작품을 교정하는 '교정자'는 별도의 자원봉사자가 담당한다. 따라서 작품이 공개되기 전까지는 작품을 입력한 뒤 교정자가 교정을 예약할 때까지 '교정대기' (校正待ち)가 되고, 작업을 멈추게 된다. 즉, 입력하는 자원봉사자가 작품을 입력해 교정을 맡은 자원봉사자가 교정예약을 해서, 교정작업을 완료하기 전까지는 작품을 공개할 수 없다. 때문에 입력이 완료되어도 작업 상태가 '교정대기' 상태인 작품이 증가하고\n",
      "\n",
      "있다. 이는 입력에 비해 교정 작업이 부족하기 때문으로, 아오조라 문고 출범 당시부터 안고 있는 문제점이기도 하다. 이 문제에 대해서는 작품의 교정작업을 하지 않고 공개하는 방안과 입력자가 교정한 것도 인정하자는 방안이 제기된 적이 있지만 현재까지도 이 방안은 채택되지 못하고 있다. 대신 2011년 12월 16일 공개분부터는 기부금을 재원으로 삼은 '유상교정' 서비스가 진행되고 있다.\n",
      "\n",
      "2013년 8월 아오조라 문고의 설립자인 토미타가 사망한 것을 계기로, 아오조라 문고에 지속적인 지원을 해줄 '책의 미래 기금' (本の未来基金)이 설립됐다. 하지만 2015년부터는 엔지니어가 없는 상태로 서버를 강제로 돌리고 있으며, 서버 자체도 노후화되고 있다는 점이 문제되고 있다. 이 때문에 2015년 5월 \"'Code for 아오조라 문고' 아이디어 송\"이 개최되어 향후 시스템 운용에 대한 의견 교환이 이뤄졌다. 그 이후에는 해당 모임을 바탕으로 시스템 관리와 코드수정 등을 맡는 'aozorahack' 프로젝트가 진행되고 있다.\n",
      "\n",
      "텍스트 파일을 아오조라 문고에 수록할 때, 텍스트 파일이 갖추어야 할 서식을 '아오조라 문고' 형식이라 부른다.\n",
      "\n",
      "아오조라 문고 형식은 텍스트 파일로서 많은 환경에서 읽을 수 있도록 규격화되어있다. 때문에 가능한 한 원본의 충실한 재현을 목표로 삼고 있지만, 줄 바꿈이나 삽화 등의 정보는 원칙적으로 포함되지 않는다.\n",
      "\n",
      "아오조라 문고 형식에 대응하는 텍스트 뷰어와 텍스트 편집기도 존재하며, 올림문자와 방점 등도 재현할 수 있다. 또 이러한 텍스트 뷰어에서는 본래 아오조라 문고 형식에 포함되지 않았던 삽화 정보를 삽입하거나 세로쓰기로 표시할 수 있으며, 텍스트를 읽기 쉽도록 만드는 다양한 기능이 포함되어 있다. 이러한 소프트웨어는 유료와 무료를 불문하고 종류가 다양하다.\n",
      "\n",
      "일본어 표기에 많이 쓰이는 올림문자 (후리가나)는 그대로 올려쓰지 않고 '｜'나 '《》'로 표시한다. 올림문자를 《》 로 묶거나 ｜로 올릴 문자열을 특정하는 방식은 일본 시각장애인 독서지원협회 (BBA)의 원문입력 수칙에 따른 것이다.\n",
      "\n",
      "이 같은 방식을 예시로 들자면 다음과 같다.\n",
      "\n",
      "라고 표기했다면 'ぶんこ' (분코)라는 올림표기가 '文庫' 부분에 걸려 있는 것이다. 다만,\n",
      "\n",
      "처럼 올림표기를 쓸 한자가 가나로 충분히 구분된다면 ｜를 써서 분리할 필요가 없으므로 쓰지 않는다. 또한,\n",
      "\n",
      "처럼 가나에 올림표기를 강제로 쓰는 것도 가능하다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "프로젝트 구텐베르크\n",
      "\n",
      "프로젝트 구텐베르크(Project Gutenberg,PG)는 인류의 자료를 모아서 전자정보로 저장하고 배포하는 프로젝트로, 1971년 미국인 마이클 하트(Michael Hart)가 시작했다.\n",
      "\n",
      "인쇄술을 통해 지식의 전달을 급속도로 확장시킨 요하네스 구텐베르크의 이름에서 따온 것으로, 인터넷에 전자화된 문서(e-text)를 저장해 놓고 누구나 무료로 책을 받아 읽을 수 있는 가상 도서관을 만드는 것을 목표로 한다. 수많은 자원봉사자들이 인터넷을 이용해 기여하여 만들어지는 프로젝트로 수많은 고전의 원문이 모여 있다.\n",
      "\n",
      "2006년 3월 프로젝트 구텐베르크 발표에 따르면, 프로젝트는 18,000개 항목 이상의 전자문서를 보유하고 있으며, 매주 50여개의 새로운 전자책이 새롭게 등록되고 있다고 한다.\n",
      "\n",
      "프로젝트에 등록된 전자책은 대부분이 서구의 문학작품으로 이루어져 있다. 소설, 시, 단편소설, 드라마 등의 문학작품 외에 요리책, 사전류, 정기간행물이 포함되어 있다. 또한 일부 오디오 파일과 음악 악보 파일도 갖고 있다.\n",
      "\n",
      "대부분은 영문 서적이지만, 독일어, 프랑스어, 이탈리아어, 에스파냐어, 네덜란드어, 핀란드어, 중국어, 포르투갈어, 라틴어, 스웨덴어, 라틴어, 에스페란토로 된 책도 있으며, 여타 언어 문서도 꾸준히 증가하고 있다.\n",
      "\n",
      "문서는 주로 아스키 문자 집합, 때때로 ISO-8859-1 문자 집합으로 인코딩된 텍스트문서를 언제나 내려받을 수 있으며, HTML등의 다른 형식의 문서도 받을 수 있다. 편집이 어려운 PDF 등의 문서형식은 프로젝트가 지향하는 바와 맞지 않는 것으로 여겨지지만, PDF형식을 이용할 수 있는 문서도 있다. 최근 수년동안 XML형식을 도입할지에 대한 토론이 있었지만, 토론은 지지부진하다.\n",
      "\n",
      "1990년대 들어 스캐닝과 OCR기술에 힘입어 마이클 하트는 컴퓨터 제조회사에서 스캐닝장비를 기증받아 문서를 스캐닝한후 OCR소프트웨어로 이를 텍스트화하는 작업을 구축하였다. 이러한 형태의 발전된 프로세스는 현재 주요한 작업기술이다. 한편 PG는 다중원본제공을 지원하며 또한 사용자 제공 콘텐츠 절차를 지원한다. 이는 셀프 출판을 의미한다.\n",
      "\n",
      "프로젝트 구텐베르크 라이선스(The Project Gutenberg License,PGL)는 아래와 같은 2개의 큰 맥락을 갖는다.\n",
      "\n",
      "이러한 프로젝트 구텐베르크 라이선스는 이후 몇몇 추가된 라이선스를 도입했으며 이전의 라이선스와 추가변형된 라이선스는 '프로젝트 구텐베르크'의 공식웹사이트에서 전문을 확인할 수 있다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "겐지모노가타리\n",
      "\n",
      "《겐지모노가타리》()는 일본 헤이안 시대 중기에 성립한 일본의 모노가타리계 장편이야기이자 소설이다. 문헌 처음으로 나온 것은 1008년 (간코 5년)이다. 작가는 무라사키 시키부로, 그녀 생애 유일한 모노가타리 작품이다. 주인공인 히카루 겐지를 통해, 연애, 영광과 몰락, 정치적 욕망과 권력투쟁 등 헤이안 시대의 귀족사회를 그렸다.\n",
      "\n",
      "하급 귀족 출신인 무라사키 시키부는 20대 후반에 후지와라노 노부타카와 결혼해 1녀를 두었으나, 결혼 후 3년만에 남편과 사별하면서 현실을 잊기 위해 이야기를 쓰기 시작했다. 이것이 《겐지모노가타리》의 시작이다. 당시에는 종이가 귀했기 때문에, 종이 제공자가 있으면, 그때마다 쓰고, 동료들끼리 서로 비평하는 등 즐거워했는데, 그 이야기의 평판에 후지와라노 미치나가의 딸인 중궁 후지와라노 쇼시(아키코)의 가정교사로 무라사키 시키부를 불렀다. 이를 계기로 궁중에 들어간 무라사키 시키부는 궁에서 근무하면서, 후지와라노 미치나가의 지원 아래에 이야기를 계속 써, 54첩으로 구성된 《겐지모노가타리》가 완성됐다.\n",
      "\n",
      "또한, 겐지모노가타리는 문헌이 처음 나온지 약 150년 만인 헤이안 시대 말기에, 〈겐지모노가타리 에마키〉로 회화화되었다. 현존하는 에마키 중, 도쿠가와 미술관과 고토 미술관 소장품은 국보로 지정되어있다. 또, 현재 《겐지모노가타리》는 일본 뿐아니라, 20개 언어 이상의 번역을 통해, 세계 각국에서 읽히고 있다.\n",
      "\n",
      "고사본은 제목이 적혀 있지 않은 것도 많고, 기록되어 있는 경우에도 내용은 다양하다. 《겐지모노가타리》의 경우에는 책자의 표제로써 《겐지모노가타리》 내지 그에 해당하는 이야기 전체의 표제가 적혀 있는 경우보다 각각의 첩명이 적혀 있는 경우가 적지 않다. 이러한 경위로 보아, 현재 일반적으로 《겐지모노가타리》라고 불리는 이 이야기가 쓰여질 당시의 제목이 무엇이었는지는 분명치 않다. 옛 사본이나 주석서 등의 문헌에 나와 있는 명칭은 크게 다음과 같은 계통으로 나뉜다.\n",
      "\n",
      "이들은 모두 겐지(源氏 (光源氏) 또는 무라사키노우에(紫の上)라는 주인공의 이름을 그대로 이야기 제목으로 한 것이어서 이야기의 고유한 명칭이라고 보기는 어렵다. 또한, 집필 시 저자가 명명했다면 이처럼 다양한 제목이 생겨날 것으로 보기 어렵기 때문에, 이들이 작자에 의한 것이 아닐 가능성이 높다고 본다.\n",
      "\n",
      "『무라사키 시키부 일기』, 『사라시나 일기』, 『미즈가카미』 등, 이 이야기의 성립 시기에 가까운 주요 문헌에 《겐지모노가타리》라고 되어 있는 점 등으로 말미암아, 이야기의 성립 초기부터 이 이름으로 불렸다고 생각되지만, 작가의 일반적인 통칭인 「무라사키 시키부」가 《겐지모노가타리》 (=《무라사키노모노가타리》)의 작자라는 데서 유래한다면, 그 바탕이 된 《무라사키노모노가타리》나 《무라사키노유카리노모노가타리》라는 명칭은 상당히 이른 시기부터 존재했을 것으로 보이며, 「겐지(源氏)」를 표제로 내세운 제목보다 오래되었다는 견해도 있다. 《무라사키노모노가타리》라고 부르는 경우에는, 현재의 《겐지모노가타리》 54첩 전체를 가리키는 것이 아니라, 「와카무라사키(若紫)」를 비롯한 무라사키노우에가 등장하는 권 (이른바 《무라사키노우에모노가타리》)만을 지칭한다는 설도 있다.\n",
      "\n",
      "『카카이쇼(河海抄)』 등의 고전승에는 「源氏の物語」라고 불리는 이야기가 여러 개 존재하고, 그 중에서 가장 뛰어난 것이 「光源氏物語」라고 하는 것이 있다. 그러나, 현재 《겐지모노가타리》라고 불리는 이야기 이외의 《겐지모노가타리》의 존재를 확인할 수 없기 때문에, 이케다 키칸 등은 이 전승을 다루기에 부족한 기괴한 설에 불과하다며, 사실이 아니라고 밝혔다. 이에 대해 와츠지 테츠로는 현재의 《겐지모노가타리》에는 독자들에게 현재 알려지지 않은 히카루 겐지에 대한 모종의 주지의 이야기가 존재하는 것을 전제로 처음 이해할 수 있는 부분이 존재한다며, \"이것은 갑자기 척척 해야할 설이 아닐라고 생각한다\"고 말했다.\n",
      "\n",
      "이 밖에, 「원어 (源語/げんご)」, 「자문 (紫文/しぶん)」, 「자사 (紫史/しし)」 등의 한자어풍 명칭으로 불리기도 하지만, 이들은 한어의 영향을 받은 것으로, 그다지 오래된 것은 아닌 것으로 보인다. 이케다에 의하면, 그 사용은 에도 시대를 거슬러 올라가지 않는다고 여겼다.\n",
      "\n",
      "헤이안 시대 중기 11세기 초에 성립된 장편 소설(모노가타리, 物語)이다. ≪겐지 모노가타리(源氏物語)≫는 오랫동안 특정한 명칭 없이 ≪源氏の物語≫, ≪光源氏物語≫, ≪紫の物語≫, ≪光源氏≫, ≪源氏≫, ≪源語≫, ≪紫文≫ 등으로 불려 오다가, 오늘날에는 일반적으로 ≪源氏物語≫라는 서명으로 불리게 되었다. 전체 54권으로 나뉘어 있으며 200자 원고지 5000매가 넘는 세계 최고(最古), 최장(最長)의 고전 소설로 치밀한 구성과 인간의 심리 묘사, 표현의 정교함과 미의식 등으로 일본 문학사상 최고 걸작으로 평가된다.\n",
      "\n",
      "당시의 전형적인 이야기가 보통 ‘옛날에 남자가 있었다’라고 시작되는 것과는 달리, ≪겐지 모노가타리≫는 ‘어느 천황의 치세 때였는지’라는 독창적인 서두로 시작된다. 작품 전체는 400여 명의 등장인물과 기리쓰보(桐壷), 스자쿠(朱雀), 레이제이(冷泉), 금상(今上)에 이르는 4대 천황에 걸친 70여 년간의 이야기로, 히카루겐지(光源氏, 이하 겐지)라고 하는 주인공의 비현실적이라 할 만큼 이상적인 일생과 그 후손인 가오루(薫)와 니오미야(匂宮) 등의 인간관계를 그리고 있다. 또한 본문은 수많은 전기(伝奇)적 화형(話型)과 함께 795수의 와카(和歌)가 산재되어 있어 긴장감 있는 문체를 이루고 있다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "귄터 그라스\n",
      "\n",
      "귄터 그라스(, 1927년 10월 16일 ~ 2015년 4월 13일)는 독일의 소설가이자 극작가다.\n",
      "\n",
      "독일 단치히 자유시(오늘날 폴란드의 그단스크)에서 식료품 상인이었던 독일계 아버지와 슬라브계 어머니 사이에서 태어났다. 하버드 대학에서 명예박사학위를 받았다. 1999년에 노벨 문학상을 수상하였다.\n",
      "\n",
      "제2차 세계 대전 당시 독일 제국노동봉사대(RAD)에서 근무하던 중, 1944년에 무장친위대에 입대하여 10 SS기갑사단 프른즈베르크로 발령받아 참전했다. 징집당한 것이라는 얘기도 있으나, 당시 친위대의 독일인 대원들은 징집 대상이 아니라 자원 입대가 기본이었다(국방군 육군은 징병제였다). 종전후 부상당한 채 미군 포로로 잡혀 1946년까지 포로 수용소에 수감되었다. 이런 사실은 그라스 자신이 최근 발간한 자서전에서 인정했다.\n",
      "\n",
      "전후 1947~48년에는 광산에서 일하며 석공 기술 과정을 마친다. 이어 1948년부터 1952년까지는 뒤셀도르프 미술대학에서 그래픽과 조각을, 1953년부터 1956년까지는 베를린 예술대학에서 조각을 배웠다.\n",
      "\n",
      "1955년 슈투트가르트 방송국의 서정시 경연대회에 입상하고, 1956~57년에 예술 작품 전시와 별도로 작가 활동을 시작했다. 1958년까지 단문, 시, 희곡 등을 발표한다. 1954년에 결혼을 하고, 1960년부터 계속 베를린에 산다. 1959년에 매우 묘사적인 언어로 나중에 영화화 되기까지 한 《양철북》을 발표했다. 이 작품으로 그는 제2차 세계 대전 후 처음으로 세계 문학계에 이름을 날린 독일 작가가 된다. 이어 <고양이와 쥐> <개의 해>에서도 전쟁 전과 전쟁 후에 걸친 시대의 과오와 대결하고 있으며, 무대는 다같이 단치히이다. 이밖의 작품에 <달팽이의 일기에서> <넙치> 등이 있다. 1996년 유럽문화공로상을 받았다.\n",
      "\n",
      "그는 소설가로 활약하는 한편, 부조리극적인 소품(小品)인 <요리사> <홍수> <버팔로까지 앞으로 10분> 등을 발표한 바 있는데, 현대정치에도 직접 행동으로 참가하여 동·서 독일의 분열이라는 가장 현실적인 문제에 대담하게 도전한 <천민의 폭동연습>(1965)을 발표했다. 1953년 동독의 폭동 당시 브레히트를 모델로 하여 예술과 정치의 관련을 추구한 작품으로 <독일의 비극>이 있다.\n",
      "\n",
      "그라스는 전후 독일 사회민주당의 주요 지지자가 되어 외국인 혐오증, 신나치주의 등에 반대하는 사회활동에 적극 참여하였다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "일반 상대성이론\n",
      "\n",
      "일반 상대성이론(一般相對性理論, , ) 또는 일반상대론(一般相對論, )은 마르셀 그로스만, 다비드 힐베르트, 알베르트 아인슈타인 등에 의해 발전되고 아인슈타인과 힐베르트가 1915년에 발표한, 중력을 상대론적으로 다루는 물리학 이론이다. 핀란드의 이론물리학자 노르드스트룀도 일반 상대론의 많은 부분을 논문으로 발표했었다. 일반 상대론은 현재까지 알려진, 중력을 다루는 이론 가운데 가장 정확하게 실험적으로 검증되었다.\n",
      "\n",
      "특수 상대성 이론에서 수학자 헤르만 민코프스키가 민코프스키 공간을 도입하여 평평한 시공간을 기하학적으로 다루었다. 일반 상대성 이론은 중력의 영향을 시공간의 휘어짐으로 기술한다. 일반상대론에서 시공간의 수학적 구조는 특별한 종류의 준 리만 다양체이며 국소적(locally)으로 민코프스키 공간이다. 시공간의 휘어짐은 수학적으로 준 리만 다양체의 곡률에 해당한다(더 정확히는 준 리만 다양체 중에서도 특수한 로런츠 다양체의 곡률). 즉, 일반상대론은 1850년대에 만들어진 수학인 리만 기하학으로 기술된다. 시공의 곡률(아인슈타인 텐서)은 (우주 상수를 무시하면) 4차원 운동량 밀도에 비례하는데, 이를 아인슈타인 방정식이라고 한다. 일반 상대성 이론에서는 관성계뿐만 아니라 비관성계를 포함한 임의의 좌표계에 대해 물리 법칙이 동등한 형태를 유지하여야 한다.\n",
      "\n",
      "자유낙하하는 승강기와 승강기 바닥에서 승강기 천장으로 쏘여진 빛을 떠올려보면, 승강기 안에서 승강기와 같이 자유낙하하는 관찰자는 빛에서 어떠한 도플러 효과도 보지 못할 것이다. 왜냐하면 등가원리를 따르면, 중력장 내에서 자유낙하하는 관찰자는 중력장이 없는 관성계의 관찰자와 같으며, 중력장이 없는 관성계에서는 빛에 어떠한 변형도 일어나지 않기 때문이다. 따라서 자유낙하하는 관찰자는 승강기 천장에 설치된 빛 감지기에서 어떠한 도플러 효과도 나타나지 않을 것이라고 결론짓는다. 하지만 승강기 밖에서 땅 위에 서있는 관찰자는 빛에서 도플러 효과를 기대한다. 왜냐하면, 승강기가 자유낙하를 시작할 때 빛이 출발했다고 가정하면, 빛이 승강기 바닥에서 승강기 천장으로 가는 시간 formula_1 동안 승강기 천장은 formula_2만큼 빠르게 되고, 이 속도에 따라 빛에 대한 청색편이를 감지해야 하기 때문이다. 여기서 청색편이는 느린 속도 근사식 formula_3만큼 일어났다고 가정한다.\n",
      "\n",
      "감지기가 어떤 관찰자에게는 도플러 효과가 없다고 감지하고, 어떤 관찰자에게는 청색편이의 도플러 효과가 있다고 감지할 수는 없으므로, 우리는 청색편이의 결과를 상쇄시켜 자유낙하하는 관찰자의 결과와 일치시킬 어떤 것을 필요로 한다. 다행히, 중력장이란 존재가 있으므로, 중력장이 청색편이를 상쇄시키는 적색편이를 일으켰다고 할 수 있다. 중력 적색편이는 formula_4만큼 일어나며, 여기에 빛이 감지되었을 때의 승강기 천장의 속도와, 빛이 승강기 천장으로 가는 시간을 대입하면 formula_5라는, 중력 퍼텐셜의 차이 formula_6에 따른 적색편이의 식을 얻을 수 있다. 그러므로 승강기에서처럼 빛 방출기와 빛 감지기가 서로 상대적인 운동에 있는 상황이 아니라, 서로에 대해서 정지해있는 상황이라면, 빛의 감지기는 청색편이로 상쇄되지 않는 중력 적색편이를 감지할 것이다.\n",
      "\n",
      "빛의 감지기가 빛의 방출기에 대해서 정적인 상황에서, 어떻게 서로 다른 진동수를 얻을 수 있을까? 다시 말해, 빛의 감지기와 빛의 방출기가 단위 시간 당 서로 다른 개수의 파면을 받아들일까? 아인슈타인은 여기에 대해서 파면의 개수는 동일하지만, 빛의 감지기와 빛의 방출기가 서로 다른 시간 단위를 갖는다고 지적했다. 즉, 서로 다른 중력 퍼텐셜에 위치한 시계에서는 서로 다른 빠르기로 시침이 움직인다는 뜻이다. 진동수는 그 곳의 고유 시간에 반비례 하므로, formula_7이며, 이를 중력 적색편이 식에 집어넣으면, formula_8의 식을 얻을 수 있다.\n",
      "\n",
      "일반 상대성 이론에서는 시공을 특수 상대성 이론의 민코프스키 공간에서 임의의 (로런츠 계량 부호수 −+++를 가진) 준 리만 다양체로 확장한다. 다양체의 계량 텐서 formula_9로서 시공간의 곡률을 정의하고, 이 곡률을 중력으로 재해석한다. 뉴턴 역학에서 중력은 (중력적) 질량의 밀도에 의하여 결정된다. 질량의 밀도를 자연스럽게 상대화하면 에너지-운동량 텐서를 얻는다. 아인슈타인과 다비트 힐베르트는 아인슈타인-힐베르트 작용을 통해 다음과 같은 장 방정식을 얻었으며, 이는 오늘날 아인슈타인 방정식으로 알려져 있다.\n",
      "\n",
      "여기서 기호는 다음과 같다.\n",
      "\n",
      "이 식으로부터, 중력장이 약하다고 가정하면 뉴턴의 역제곱 법칙을 비상대론적 극한으로 얻는다.\n",
      "\n",
      "공간 좌표를 formula_17으로 하고 시간 좌표를 formula_18로 하면, 세계선의 선소 formula_19는 formula_20 로 표시된다.\n",
      "\n",
      "formula_21와 formula_22는 시간과 공간의 좌표를 나타내는 인덱스로 0은 시간, 1,2,3은 공간 성분을 표시한다. formula_9는 시공간 사이의 변환을 나타내는 계량 텐서이다. 예를 들어 가장 평탄한 시공간을 나타내는 민코프스키 계량 텐서의 경우\n",
      "\n",
      "이다.\n",
      "\n",
      "일반 상대성 이론에서, 중력 밖의 다른 힘이 작용하지 않고, 그 무게가 무시할 만큼 작은 입자는 시공간의 측지선을 따라 움직인다. 측지선은 시공에서 고유 시간을 극대화하는 경로이다. 즉, formula_25이다.\n",
      "\n",
      "일반적으로 중력에 의해 시공간이 휘어지는 것을 알 수 있다. 질량이 큰 물체는 시공간을 휘게 할 수 있고 그것이 중력을 제공하는 역할을 한다\n",
      "\n",
      "일반 상대성 이론은 실험적으로 성공적이나, 이를 주로 양자장론과 관련하여 여러 가지로 확장할 수 있다. 일반상대론에 비틀림을 더한 이론은 아인슈타인-카르탕 이론이고, 중력상수를 스칼라장으로 승진시키면 브랜스-딕 이론을 얻는다. 일반 상대성 이론에 추가 차원을 도입하여 다른 상호작용을 포함시키는 이론은 칼루차-클라인 이론이며, 초대칭을 도입하면 초중력 이론을 얻는다. 또한 초끈이론에서는 아인슈타인-힐베르트 작용을 자연스럽게 얻을 수 있으며, 고리 양자 중력에서는 아인슈타인-힐베르트 작용을 가지고 이를 양자화 한다는 것에서 시작한다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "데니스 리치\n",
      "\n",
      "데니스 매캘리스터 리치(, 1941년 9월 9일~2011년 10월 12일)는 미국의 저명한 전산학자이자 현대 컴퓨터의 선구자이다. C와 유닉스의 개발자로 알려져 있다.\n",
      "\n",
      "미국의 뉴욕주 브롱크스빌(Bronxville)에서 태어났으며, 1968년 하버드 대학교에서 응용수학 박사학위를 얻었다. 1968년부터 벨 연구소 컴퓨터 연구 센터에서 일했다. 2007년 루슨트 테크놀로지의 시스템 소프트웨어 연구부장으로 은퇴했다. 홀로 살고 있던 그는 미국 시각으로 2011년 10월 12일 뉴저지주 버클리 헤이츠의 자택에서 사망한 채로 발견되었다 (향년 71세).\n",
      "\n",
      "켄 톰슨(Ken Thompson) 등과 함께 최초의 유닉스(Unix) 시스템을 개발했고, 1971년 최초의 〈Unix Programmer's Manual〉을 썼다. 또한 C 언어를 개발한 후 브라이언 커니핸과 함께 〈C 프로그래밍 언어〉(The C Programming Language)를 기술했다. 커니핸과 〈C 프로그래밍 언어〉책을 썼기에 커니핸이 C 언어 개발에 참여한 것으로 종종 오해받으나 커니핸의 말에 따르면 자신은 C언어 개발에 참여하지 않았다고 한다.\n",
      "\n",
      "ALTRAN, B언어, BCPL, Multics 등의 개발에도 영향을 끼친 것으로도 알려져 있다.\n",
      "\n",
      "1983년에 켄 톰프슨과 \"범용 운영체제 이론개발, 특히 유닉스 운영체제의 구현에 대한 공로\"로 튜링상을 수상했다.\n",
      "\n",
      "미국의 경제 전문지 '비즈니스 인사이더'에서는 '현재의 애플 컴퓨터는 거의 모두 데니스 리치의 업적에 기반하고 있다'이라며 그의 업적을 평가했다. 현재 애플 매킨토시의 macOS와 아이폰의 iOS는 모두 유닉스 운영체제를 기반으로 만들어져 있다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "주기율표\n",
      "\n",
      "주기율표(週期律表, , ) 또는 주기표(週期表)는 원소를 구분하기 쉽게 성질에 따라 배열한 표로, 러시아의 드미트리 멘델레예프가 처음 제안했다. 1915년 헨리 모즐리는 멘델레예프의 주기율표를 개량시켜서 원자번호순으로 배열했는데, 이는 현대의 원소 주기율표와 유사하다. 원자 번호가 커짐에 따라 성질이 비슷한 원소가 주기적으로 나타나는 성질인 주기성을 기준으로 원소들을 배열하였다. 주기율표의 가로행은 주기라 부르고, 세로열은 족이라 부른다. 주기마다 같은 성질의 원소가 반복적으로 나타나기 때문에, 같은 족의 원소들은 서로 유사한 화학적 특성을 보인다. 전자를 가지고 있으려 하는 비금속성은 대체로 오른쪽이 더 높으며, 반대로 전자를 주려고 하는 금속성은 대체로 왼쪽이 더 높다. 이러한 화학적 성질은 각 원소의 전자 배치에 기인한다.\n",
      "\n",
      "1869년 러시아의 화학자 드미트리 멘델레예프가 원자 질량에 따라 원소의 화학적 성질이 주기적으로 변화하는 것에 착안하여 주기율표를 처음으로 만들었다. 당시에는 모든 원소가 발견되지 않았기 때문에 원소 사이에 공백이 남아있었는데, 멘델레예프는 원소의 주기성에 착안하여 원소를 새로 발견하기도 하였다. 원소의 주기성은 19세기 후반에 사실로 인식되었으며, 원자 번호가 발견되고 20세기 초에 양자역학을 통해 원자의 내부 구조를 탐구하며 재확인되었다. 글렌 T. 시보그가 1945년에 악티늄족이 d-블록 원소가 아닌 f-블록 원소라는 사실을 발견함으로써 현대의 주기율표 틀이 완성되었다.\n",
      "\n",
      "주기율표는 과학의 발전에 따라 계속 개정되고 있다. 자연계에서는 원자 번호 94까지 존재하는 원소들만 존재하는데, 과학자들은 실험실에서 원자번호 94보다 더 무거운 원소들을 합성하고 있다. 현재에는 118개의 원소들이 알려져 있으며 표의 처음 일곱 주기를 빈틈 없이 채우고 있다. 이 일곱 줄을 넘어서 표가 얼마나 뻗어나갈지, 표의 알려진 부분의 주기율이 언제까지 이어질지는 아직 알려지지 않았다. 또한 일부 원소가 주기율표에 올바르게 배치되었는지에 대한 과학적 논의가 계속되고 있다.\n",
      "\n",
      "주기율표의 역사는 요한 볼프강 되베라이너의 \"세 쌍 원소\"로부터 시작된다. 그는 실험을 통해 세 개의 원소로 이루어진 무리 중 어떤 원소들은 첫 번째 원소와 세 번째 원소의 물리량 평균이 두 번째 원소의 물리량과 같음을 확인했다. 그 구체적인 예로는 '칼슘(Ca), 스트론튬(Sr), 바륨(Ba)'의 세 원소가 있다 여기서 스트론튬(Sr)의 물리량은 칼슘(Ca)과 바륨(Ba) 원소의 물리량을 합하여 2로 나눈 평균값과 비슷하거나 같다. 되베라이너는 이들을 세 쌍의 원소라고 불렀다. 이러한 세 쌍 원소 관계를 만족하는 원소들은 칼슘-스트론튬-바륨, 염소-브로민-아이오딘, 그리고 리튬-나트륨-칼륨이 대표적인데 이를 만족하는 원소수가 적어 인정받지 못하였다. 세 쌍 원소는 현대 주기율표에서 같은 족에 해당된다.\n",
      "\n",
      "영국의 과학자 존 뉴랜즈는 원소들을 원자량의 순으로 배열하면 8번째 원소마다 비슷한 성질의 원소가 나타나는 것을 발견하였고, 이를 피아노의 개념에 대입하였지만 이 대응성은 3번째 줄에서부터 어긋나기 시작했고, 처음 이 이론이 발표되었을 때만 해도 그는 웃음거리가 되었으나 이후 여러 가지 실험이 뉴랜즈의 법칙의 중요성을 보였다. 현대 주기율표에서 주기개념의 시초가 되었다.\n",
      "\n",
      "드미트리 멘델레예프는 화학 교수였다. 멘델레예프는 원소의 규칙을 밝히기 위해 이런저런 시도를 하다가 결국 원소들을 원자량순으로 나열하면 되베라이너의 세쌍원소, 뉴랜즈의 옥타브 법칙을 만족하게 된다는 것을 알게 되었다. 그는 원소가 어떤 함수의 결과라는 것을 확실히 믿었지만 비활성 기체가 발견되면서 그의 주기율표는 바뀌기 시작했다. 멘델레예프가 만든 주기율표에는 빈자리가 있었다. 그리고 그 빈자리에 언젠가는 빈 칸을 채울 원소가 발견될 것이라고 주장했다. 멘델레예프의 주기율표는 양성자의 수의 순서로 첫 칸부터 118번째 칸까지 채워지게 된다.\n",
      "\n",
      "멘델레예프의 문제는 영국의 모즐리에 의해 풀렸다. 그는 음극선관을 이용하여 생성되는 X선의 파장을 연구하여 양성자 수에 따라 화학적 성질이 달라진다는 것을 밝혀냈다. 이를 모즐리의 법칙이라하며, 이것을 기본으로 현대적 의미의 주기율표가 탄생하였다.\n",
      "\n",
      "유사한 성질을 가지는 원소들의 집합을 일컫는 용어가 여럿 있다. 그중 IUPAC이 인정하는 것은 알칼리 금속, 알칼리 토금속, 질소족, 칼코젠, 할로젠, 비활성 기체가 있다. 원소의 성질이 주기적으로 반복되기 때문에, 각 집합은 각각 하나의 족에 대응된다. 대응되는 이름이 없는 족의 경우, 가장 첫 번째 원소의 이름을 따 부르기도 한다. 예를 들어 6족 원소의 경우 크롬으로부터 따와 크롬족(chromium group)이라고 부르기도 한다. 이와는 반대로 IUPAC이 깔끔히 정의내리지는 않았지만 통용되는 원소의 분류로는 금속, 비금속, 준금속의 분류가 있다. 이에 대해 일치된 견해는 없다. 전이 금속의 뒤를 잇는 금속들을 부르는 용어 역시 제대로 된 합의가 이루어지지 않았기 때문에 전이후(post-transition) 금속 또는 불량(poor) 금속이라고 불린다. 일부 논문에서는 상당히 다른 화학적 특성을 간혹 보인다는 이유로 12족 원소를 전이 금속에서 제외하지만, 보편적인 인식은 아니다.\n",
      "\n",
      "란타넘족은 란타넘 (57번, La)에서 루테튬 (71번, Lu)까지의 희토류 원소이다. 란타넘족은 원자번호가 늘어나면서 4f 오비탈을 채운다. 과거에는 세륨(Ce)부터 루테늄까지를 한묶음으로 분류했지만, 현대에는 란타넘까지 묶는 표기가 일반적으로 사용되고 있다. 여기에 스칸듐과 이트륨을 더해 희토류 원소라고 부른다.\n",
      "\n",
      "이와 마찬가지로 악티늄족은 악티늄(89번, Ac)에서 로렌슘(103번, Lr)까지의 원소를 가리킨다. 악티늄족은 원자번호가 늘어나면서 5f 오비탈을 채운다. 이 역시 과거에는 토륨(Th)부터 로렌슘까지를 한묶음으로 분류했지만, 현대에는 악티늄까지 묶는 표기가 일반적으로 사용되고 있다. 란타넘족 원소보다는 같은 족 원소끼리의 성질차이가 훨씬 크다. IUPAC는 -ide 접미사가 일반적으로 음이온을 나타내므로 모호성을 피하기 위해 란타노이드와 액티노이드라 부를 것을 권고한다. 루테튬과 로렌슘을 3족 원소로 생각하는 일부 학자들은 란타넘족 원소를 란타넘에서 이터븀(Yb)까지로 정의하고, 악티늄족 원소를 악티늄에서 노벨륨(No)까지로 정의하여 f-블록과 일치시키기도 한다.\n",
      "\n",
      "위에 나열한 분류 외에도 분야에 따라서 여러 분류를 사용한다. 천체물리학에서는 원자 번호가 2보다 큰 원소, 즉 수소와 헬륨을 제외한 모든 원소를 금속이라 부른다. 반금속이라는 분류도 물리학에서 화학에서 서로 다르게 분류한다. 예를 들어 비스무트는 물리학의 정의에서는 반금속이지만, 대부분의 화학자들은 금속으로 간주한다. 중금속처럼 널리 사용되지만, 실제로는 엄밀하게 정의되지 않은 분류도 존재한다.\n",
      "\n",
      "학자들마다 사용하는 용어에도 차이가 있다. 예를 들어, IUPAC는 매우 방사성이 강한 초중금속 오가네손을 포함한 모든 18족 원소를 비활성 기체로 분류한다. 그러나 오가네손의 실제 화학적 성질을 계산한 결과는, 오가네손이 상대론적 효과로 인해 비활성이 아닐 것이며 심지어는 상온에서 기체도 아닐 수 있다고 예측한다. 일본의 학자들은 알칼리 토금속에 베릴륨과 마그네슘을 포함시키지 않는 경우가 있는데, 이는 마그네슘보다 더 무거운 2족 원소들과 성질에 차이가 있기 때문이다.\n",
      "\n",
      "주기율표에는 현대에도 여러 논쟁거리가 남아있다.\n",
      "\n",
      "수소와 헬륨의 위치에 대한 논쟁이 이어지고 있다. 현재의 주기율표에서는 수소를 알칼리 금속과 마찬가지로 가장 바깥쪽 껍질에 전자를 하나 가진 리튬 위에 배열한다. 그러나 일부에서는 수소는 금속 원소가 아니며 수소가 전자의 구조 면에서는 알칼리 금속이 아닌 할로겐에게 가깝고 할로젠 원소와 성질이 비슷하다고 주장하며, 수소의 위치를 17족 원소로 옮겨야 한다고 주장한다.\n",
      "\n",
      "마찬가지로 생각해서, 수소가 1족 원소라면 헬륨도 베릴륨 위에 2족 원소로 배치해야 한다는 설이 있다. 그러나 헬륨은 비활성 기체이므로 현재처럼 네온 위인 18족 원소가 가장 적당하다고 한다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "아미노산\n",
      "\n",
      "아미노산()은 아미노기(생물학적 조건에서 양성자화된 −NH 형태), 카복실기(생물학적 조건에서 탈양성자화된 −COO 형태), 특정한 곁사슬(R기)를 가지고 있는 유기 화합물이다. 모든 아미노산에 존재하는 원소는 탄소(C), 수소(H), 산소(O), 질소(N)이다. 또한 황(S)은 시스테인과 메티오닌의 곁사슬에 존재하고, 셀레늄(Se)은 덜 일반적인 아미노산인 셀레노시스테인의 곁사슬에 존재한다. 2020년을 기준으로 500가지 이상의 자연적으로 생성되는 아미노산들이 존재한다. 이 중 일부는 단백질을 비롯한 펩타이드의 단량체 단위를 구성하는 것으로 알려져 있지만 유전 부호에는 22가지의 α-아미노산만 나타나며 그 중 20가지는 고유한 지정된 코돈을 가지고 있고, 나머지 2가지(모든 진핵생물에 존재하는 셀레노시스테인과 일부 원핵생물에 존재하는 피롤리신)는 특수 코딩 메커니즘을 가지고 있다.\n",
      "\n",
      "아미노산은 핵심적인 구조 작용기의 위치에 따라 알파-아미노산(α-아미노산), 베타-아미노산(β-아미노산), 감마-아미노산(γ-아미노산) 또는 델타-아미노산(δ-아미노산)으로 분류할 수 있다. 다른 분류 범주는 극성, 이온화 및 곁사슬 작용기의 유형(지방족, 비고리형, 방향족, 하이드록실기 또는 황의 함유 여부 등)과 관련된다. 사람의 근육 및 기타 조직에서 단백질의 형태로서의 아미노산 잔기들은 두 번째로 큰 구성 성분(물이 가장 큼)을 차지한다. 아미노산은 단백질의 잔기로서의 역할 외에도 신경전달물질, 생합성과 같은 여러 과정들에 관여한다. 이는 지구상의 생명체의 출현을 가능하게 하는 데 핵심적인 역할을 한 것으로 생각된다.\n",
      "\n",
      "아미노산은 그림에 표시된 가상의 \"중성\" 구조의 관점에서 IUPAC-IUBMB 생화학 명명 공동 위원회에 의해 공식적으로 명명되었다. 예를 들어 알라닌의 계통명은 화학식 에 기반한 2-아미노프로판산이다. IUPAC-IUBMB 생화학 명명 공동 위원회는 이러한 접근 방식을 다음과 같이 정당화했다.\n",
      "\n",
      "1800년대 초에 몇몇 아미노산들이 최초로 발견되었다. 1806년에 프랑스의 화학자 루이니콜라 보클랭과 피에르 장 로비케는 아스파라거스로부터 화합물을 분리하였는데, 이 화합물은 최초로 발견된 아미노산이었으며 아스파라긴으로 명명되었다. 시스틴은 1810년에 발견되었지만 시스틴의 단량체인 시스테인은 1884년에 이르러서야 발견되었다. 1820년에는 글리신과 류신이 발견되었다. 20가지 표준 아미노산들 중 마지막으로 발견된 아미노산은 트레오닌으로 1935년에 윌리엄 커밍 로즈가 발견하였다. 로즈는 또한 필수 아미노산을 결정하고 최적의 생장을 위한 모든 아미노산들의 최소 일일 요구량을 설정했다.\n",
      "\n",
      "아미노산들의 화학적 범주의 단일성은 1865년에 샤를 아돌프 뷔르츠에 의해 인식되었지만 그는 이것에 대해 특별한 명칭을 부여하지 않았다. 영어에서 \"아미노산()\"이라는 용어가 처음으로 사용된 것은 1898년부터이며 독일어에서 \"아미노산()\"이라는 용어는 영어에서보다 더 일찍 사용되었다. 단백질이 효소적으로 소화되거나 산성 가수분해되면 아미노산으로 분해된다는 것이 밝혀졌다. 1902년에 에밀 피셔와 프란츠 호프마이스터는 각각 독립적으로 단백질이 많은 아미노산들로부터 형성되며, 이 과정에서 한 아미노산의 아미노기와 다른 아미노산의 카복실기 사이에 결합이 형성되어 선형 구조를 생성한다고 제안했다. 피셔는 이 선형 구조를 \"펩타이드\"라고 명명했다.\n",
      "\n",
      "그림에 표시된 구조에서 R은 각 아미노산의 특정한 곁사슬을 나타낸다. 카복실기 옆에 있는 탄소 원자를 α-탄소라고 한다. α-탄소에 직접적으로 결합된 아미노기를 가지고 있는 아미노산을 α-아미노산이라고 한다. 여기에는 2차 아민인 프롤린과 하이드록시프롤린이 포함된다. 과거에는 종종 이미노산이라고 불렸는데 이는 이민 부분()을 포함하지 않기 때문에 부적절한 명칭이다.\n",
      "\n",
      "일반적인 천연 형태의 아미노산은 아미노기(, 프롤린의 경우 )와 카복실기()가 동일한 α-탄소 원자에 결합되어 있기 때문에 α-아미노산이다. 비카이랄성인 글리신을 제외하고 천연 아미노산은 L-입체배치를 가지고 있으며 리보솜에서 번역되는 동안 단백질에서 발견되는 형태는 L-아미노산이다.\n",
      "\n",
      "아미노산의 입체배치에 대한 L 및 D 규칙은 아미노산 자체의 광학 활성을 따른 것이 아니라 이론산 그 아미노산이 합성될 수 있는 글리세르알데하이드의 이성질체의 광학 활성을 따른 것이다. D-글리세르알데하이드는 우선성, L-글리세르알데하이드는 좌선성이다.\n",
      "\n",
      "다른 규칙은 (\"S\") 및 (\"R\") 지정자를 사용하여 절대배치를 지정하는 것이다. 단백질의 거의 모든 아미노산은 α-탄소에 (\"S\")가 있고, 시스테인은 (\"R\")이며, 글리신은 카이랄성이 아니다. 시스테인은 다른 아미노산들과 동일한 기하학적 위치에 곁사슬을 가지고 있지만, \"R\"/\"S\" 용어는 칸-인골드-프렐로그 순위 규칙에 의해 곁사슬에 더 높은 우선 순위를 부여하는 카복실 산소에 비해 황의 원자 번호가 더 높디 때문에 반대이다. 대부분의 다른 곁사슬에 있는 원자들은 카복실기에 비해 우선 순위가 낮다.\n",
      "\n",
      "드물게 D-아미노산 잔기가 단백질에서 발견되며 번역 후 변형으로 L-아미노산으로부터 전환된다.\n",
      "\n",
      "아미노산은 아미노기의 질소 원자가 카복실기 탄소 옆의 탄소 원자인 α-탄소에 결합될 때 α-아미노산으로 지정된다. 아미노산을 분류하는 방법에는 여러 가지가 있다. 그러나 이들은 종종 이 섹션의 머리 부분에 있는 그래픽에 묘사된 것처럼 곁사슬의 극성에 따라 분류된다.\n",
      "\n",
      "이 단락 아래의 모든 경우에서 formula_1값(있는 경우)은 단백질의 아미노산 잔기로서 작용기의 이온화를 나타낸다. 이는 유리 아미노산(생화학적 중요성이 거의 없음)에 대한 formula_1값이 아니다.\n",
      "\n",
      "여러 곁사슬들은 H와 C만 가지고 있으며 이온화되지 않는다. 해당하는 아미노산들은 다음과 같다(괄호 안에 세 문자 약어 및 한 문자 약어 포함).\n",
      "\n",
      "두 가지 아미노산은 곁사슬에 하이드록실기를 포함하고 있다. 이들은 정상적인 조건에서 이온화되지 않지만 세린은 세린 프로테에이스에 의한 촉매 작용 동안 탈양성자화된다. 이것은 심하게 교란되는 예이며 일반적인 세린 잔기의 특징은 아니다.\n",
      "\n",
      "트레오닌은 2개의 카이랄 중심을 가지고 있는데 이는 카이랄성이 아닌 글리신을 제외한 모든 아미노산들이 공유하고 있는 α-탄소의 L(2\"S\") 카이랄 중심 뿐만 아니라 β-탄소의 (3\"R\") 카이랄 중심을 가지고 있다. 전체 입체화학적 사양은 L-트레오닌(2\"S\",3\"R\")이다.\n",
      "\n",
      "다음의 2가지 아미노산은 아마이드 곁사슬을 가지고 있다.\n",
      "\n",
      "이러한 곁사슬은 정상 범위의 pH에서 이온화되지 않는다.\n",
      "\n",
      "다음의 2가지 아미노산의 곁사슬에는 황 원자가 포함되어 있으며, 그 중 하나는 정상 범위(formula_1로 표시됨)에서 이온화되고 다른 하나는 이온화되지 않는다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(out_file,\"r\") as f:\n",
    "    for i in range(500):\n",
    "        line = f.readline() #한 줄씩 읽기\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c3df765-2597-4bb2-9683-fcaf5e56f429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.99\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e244f023-9d64-4868-a14a-c473826ad6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\t  kowiki     naver_news_csv.py\t    stackoverflow.py\n",
      "WikiExtractor.py  kowiki.py  save_gpt_pretrain.pth\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a820928f-412d-4bca-ae74-aa0611b55af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/qkrwnstj/backup/GPTv1/web-crawler/kowiki\n"
     ]
    }
   ],
   "source": [
    "%cd kowiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c695150c-b7be-4403-a786-a34b4076b70b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=./kowiki.txt --model_prefix=kowiki --vocab_size=8007 --model_type=bpe --max_sentence_length=999999 --pad_id=0 --pad_piece=[PAD] --unk_id=1 --unk_piece=[UNK] --bos_id=2 --bos_piece=[BOS] --eos_id=3 --eos_piece=[EOS] --user_defined_symbols=[SEP],[CLS],[MASK]\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./kowiki.txt\n",
      "  input_format: \n",
      "  model_prefix: kowiki\n",
      "  model_type: BPE\n",
      "  vocab_size: 8007\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 999999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: [SEP]\n",
      "  user_defined_symbols: [CLS]\n",
      "  user_defined_symbols: [MASK]\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: [UNK]\n",
      "  bos_piece: [BOS]\n",
      "  eos_piece: [EOS]\n",
      "  pad_piece: [PAD]\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(351) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(183) LOG(INFO) Loading corpus: ./kowiki.txt\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 1000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 2000000 lines\n",
      "trainer_interface.cc(145) LOG(INFO) Loaded 3000000 lines\n",
      "trainer_interface.cc(122) LOG(WARNING) Too many sentences are loaded! (3109261), which may slow down training.\n",
      "trainer_interface.cc(124) LOG(WARNING) Consider using --input_sentence_size=<size> and --shuffle_input_sentence=true.\n",
      "trainer_interface.cc(127) LOG(WARNING) They allow to randomly sample <size> sentences from the entire corpus.\n",
      "trainer_interface.cc(407) LOG(INFO) Loaded all 3109261 sentences\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: [PAD]\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: [UNK]\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: [BOS]\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: [EOS]\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: [SEP]\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: [CLS]\n",
      "trainer_interface.cc(423) LOG(INFO) Adding meta_piece: [MASK]\n",
      "trainer_interface.cc(428) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(537) LOG(INFO) all chars count=367105352\n",
      "trainer_interface.cc(548) LOG(INFO) Done: 99.95% characters are covered.\n",
      "trainer_interface.cc(558) LOG(INFO) Alphabet size=4376\n",
      "trainer_interface.cc(559) LOG(INFO) Final character coverage=0.9995\n",
      "trainer_interface.cc(591) LOG(INFO) Done! preprocessed 3108309 sentences.\n",
      "trainer_interface.cc(597) LOG(INFO) Tokenizing input sentences with whitespace: 3108309\n",
      "trainer_interface.cc(608) LOG(INFO) Done! 8457483\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=2278677 min_freq=449\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=749255 size=20 all=637768 active=42119 piece=▁전\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=496446 size=40 all=647765 active=52116 piece=▁경\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=388310 size=60 all=657746 active=62097 piece=한다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=308407 size=80 all=667159 active=71510 piece=▁해\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=247143 size=100 all=674156 active=78507 piece=▁만\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=245397 min_freq=499\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=224856 size=120 all=682311 active=41465 piece=▁역\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=197995 size=140 all=690864 active=50018 piece=되었\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=180564 size=160 all=699305 active=58459 piece=▁이후\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=162290 size=180 all=705139 active=64293 piece=▁일본\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=148459 size=200 all=710436 active=69590 piece=▁S\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=148252 min_freq=498\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=136631 size=220 all=715830 active=40833 piece=는데\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=128783 size=240 all=723975 active=48978 piece=▁C\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=121166 size=260 all=730557 active=55560 piece=▁따라\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=112530 size=280 all=736453 active=61456 piece=▁영화\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=104799 size=300 all=742780 active=67783 piece=▁간\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=104315 min_freq=488\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=98936 size=320 all=748163 active=42152 piece=하다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=93660 size=340 all=753898 active=47887 piece=▁15\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=87485 size=360 all=759147 active=53136 piece=▁B\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=83230 size=380 all=764122 active=58111 piece=▁천\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=78804 size=400 all=769346 active=63335 piece=▁살\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=78787 min_freq=480\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=73597 size=420 all=775021 active=43827 piece=는다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=70539 size=440 all=779076 active=47882 piece=▁연구\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=67055 size=460 all=783699 active=52505 piece=보다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=64723 size=480 all=791297 active=60103 piece=▁순\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=62252 size=500 all=795933 active=64739 piece=▁규\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=62201 min_freq=467\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=59191 size=520 all=802660 active=46354 piece=▁H\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=57421 size=540 all=807892 active=51586 piece=▁음반\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=55541 size=560 all=813148 active=56842 piece=▁길\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=53856 size=580 all=817114 active=60808 piece=▁접\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=51478 size=600 all=820684 active=64378 piece=세기\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=51409 min_freq=458\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=49533 size=620 all=825220 active=45308 piece=▁태어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=48354 size=640 all=830951 active=51039 piece=리가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=46950 size=660 all=838847 active=58935 piece=▁위치한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=45682 size=680 all=844281 active=64369 piece=▁귀\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=44369 size=700 all=849423 active=69511 piece=▁관계\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=44348 min_freq=444\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=43084 size=720 all=854271 active=47111 piece=도를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=42204 size=740 all=859645 active=52485 piece=▁엔\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=40452 size=760 all=864747 active=57587 piece=▁지원\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=39491 size=780 all=867766 active=60606 piece=▁범\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=38553 size=800 all=873324 active=66164 piece=▁와\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=38529 min_freq=435\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=37804 size=820 all=878038 active=48041 piece=▁2012\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=36962 size=840 all=881968 active=51971 piece=▁벌\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35938 size=860 all=888810 active=58813 piece=▁아니라\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=35195 size=880 all=893486 active=63489 piece=▁아들\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=34293 size=900 all=898144 active=68147 piece=에서의\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=34278 min_freq=424\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=33086 size=920 all=905288 active=51188 piece=일부터\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=32179 size=940 all=910160 active=56060 piece=군은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31701 size=960 all=914826 active=60726 piece=수를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=31003 size=980 all=920523 active=66423 piece=▁유명\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=30337 size=1000 all=924342 active=70242 piece=점을\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=30327 min_freq=411\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29574 size=1020 all=929651 active=51185 piece=남도\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=29039 size=1040 all=934310 active=55844 piece=▁이미\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28630 size=1060 all=939564 active=61098 piece=해야\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=28097 size=1080 all=946922 active=68456 piece=▁않은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=27417 size=1100 all=952229 active=73763 piece=▁29\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=27390 min_freq=397\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26758 size=1120 all=956724 active=52070 piece=▁중요한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=26366 size=1140 all=962065 active=57411 piece=▁퍼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25841 size=1160 all=965799 active=61145 piece=▁항공\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=25342 size=1180 all=970873 active=66219 piece=레스\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24837 size=1200 all=975855 active=71201 piece=▁여자\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=24810 min_freq=386\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24389 size=1220 all=980293 active=53021 piece=▁노동\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=24136 size=1240 all=983470 active=56198 piece=치를\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23553 size=1260 all=987594 active=60322 piece=▁콜\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=23146 size=1280 all=992114 active=64842 piece=▁거쳐\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22832 size=1300 all=995768 active=68496 piece=학적\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=22826 min_freq=378\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22504 size=1320 all=1001420 active=55186 piece=▁놓\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=22198 size=1340 all=1006997 active=60763 piece=▁전문\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21681 size=1360 all=1012326 active=66092 piece=▁인간\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21468 size=1380 all=1017128 active=70894 piece=▁그래\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=21219 size=1400 all=1021326 active=75092 piece=▁명칭\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=21218 min_freq=367\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20860 size=1420 all=1026102 active=55738 piece=명은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20631 size=1440 all=1030808 active=60444 piece=▁궁\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20320 size=1460 all=1034333 active=63969 piece=▁가수\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=20065 size=1480 all=1040104 active=69740 piece=▁경찰\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19764 size=1500 all=1043402 active=73038 piece=▁소설\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=19762 min_freq=360\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19537 size=1520 all=1048916 active=57550 piece=▁뉴욕\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=19279 size=1540 all=1052946 active=61580 piece=▁언급\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18954 size=1560 all=1056628 active=65262 piece=체가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18599 size=1580 all=1061991 active=70625 piece=▁풀\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18348 size=1600 all=1065781 active=74415 piece=▁자기\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18314 min_freq=352\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=18073 size=1620 all=1070668 active=57880 piece=60\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17810 size=1640 all=1073628 active=60840 piece=▁챔피언\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17634 size=1660 all=1076775 active=63987 piece=트리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17319 size=1680 all=1081043 active=68255 piece=▁효과\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=17075 size=1700 all=1085892 active=73104 piece=▁앤\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=17072 min_freq=345\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16939 size=1720 all=1090905 active=59155 piece=▁더욱\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16801 size=1740 all=1095300 active=63550 piece=▁이름은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16523 size=1760 all=1100597 active=68847 piece=▁소유\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16396 size=1780 all=1104194 active=72444 piece=이어\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16206 size=1800 all=1107954 active=76204 piece=한다는\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=16205 min_freq=336\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=16058 size=1820 all=1111633 active=58531 piece=일본\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15851 size=1840 all=1116075 active=62973 piece=▁제한\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15629 size=1860 all=1119679 active=66577 piece=이지만\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15457 size=1880 all=1125336 active=72234 piece=▁덴\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15354 size=1900 all=1129660 active=76558 piece=▁거두\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=15321 min_freq=328\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15162 size=1920 all=1134194 active=60937 piece=일랜드\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=15000 size=1940 all=1137606 active=64349 piece=▁전자\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14852 size=1960 all=1142017 active=68760 piece=학의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14704 size=1980 all=1146765 active=73508 piece=▁방문\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14557 size=2000 all=1152313 active=79056 piece=▁우리\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=14540 min_freq=319\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14379 size=2020 all=1158229 active=63325 piece=시대\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14197 size=2040 all=1164340 active=69436 piece=▁하지\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=14073 size=2060 all=1167019 active=72115 piece=▁친구\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13947 size=2080 all=1172879 active=77975 piece=▁이곳\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13753 size=2100 all=1176237 active=81333 piece=\",\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13747 min_freq=311\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13585 size=2120 all=1180552 active=63019 piece=▁세워\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13422 size=2140 all=1184188 active=66655 piece=》()\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13279 size=2160 all=1188820 active=71287 piece=▁의하여\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13169 size=2180 all=1192576 active=75043 piece=▁1988\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=13057 size=2200 all=1195879 active=78346 piece=▁해결\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=13055 min_freq=305\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12905 size=2220 all=1200532 active=64294 piece=▁사용된다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12776 size=2240 all=1203464 active=67226 piece=거리\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12625 size=2260 all=1208841 active=72603 piece=▁공립\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12532 size=2280 all=1213524 active=77286 piece=▁그대로\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12423 size=2300 all=1217675 active=81437 piece=▁영어\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=12423 min_freq=298\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12311 size=2320 all=1222069 active=65087 piece=▁이야기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12238 size=2340 all=1225294 active=68312 piece=▁스테\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=12123 size=2360 all=1230574 active=73592 piece=▁다르\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11994 size=2380 all=1235113 active=78131 piece=▁여름\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11901 size=2400 all=1239203 active=82221 piece=▁팀의\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11896 min_freq=291\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11797 size=2420 all=1244025 active=66781 piece=▁The\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11708 size=2440 all=1248668 active=71424 piece=▁이스\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11608 size=2460 all=1252572 active=75328 piece=▁놀\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11519 size=2480 all=1256769 active=79525 piece=▁오스트레일리아\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11369 size=2500 all=1259569 active=82325 piece=시를\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=11356 min_freq=285\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11270 size=2520 all=1264730 active=67523 piece=▁나무\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11200 size=2540 all=1268588 active=71381 piece=시가\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11113 size=2560 all=1273494 active=76287 piece=▁80\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=11029 size=2580 all=1276453 active=79246 piece=▁낳\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10945 size=2600 all=1281604 active=84397 piece=▁위해서\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10942 min_freq=279\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10865 size=2620 all=1285482 active=67910 piece=▁이렇게\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10798 size=2640 all=1289070 active=71498 piece=음이의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10684 size=2660 all=1290965 active=73393 piece=▁동생\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10590 size=2680 all=1293968 active=76396 piece=▁사이에서\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10515 size=2700 all=1297876 active=80304 piece=▁계열\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10514 min_freq=275\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10465 size=2720 all=1301834 active=68728 piece=안을\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10378 size=2740 all=1306187 active=73081 piece=▁대륙\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10309 size=2760 all=1309497 active=76391 piece=▁종합\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10217 size=2780 all=1313996 active=80890 piece=86\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10154 size=2800 all=1318857 active=85751 piece=▁프로듀\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=10148 min_freq=269\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=10092 size=2820 all=1321853 active=68919 piece=▁본래\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9984 size=2840 all=1325116 active=72182 piece=45\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9894 size=2860 all=1329595 active=76661 piece=계는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9828 size=2880 all=1334939 active=82005 piece=했기\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9741 size=2900 all=1338630 active=85696 piece=▁납\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9738 min_freq=263\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9683 size=2920 all=1342456 active=70574 piece=▁가입\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9626 size=2940 all=1347003 active=75121 piece=▁경우에는\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9531 size=2960 all=1349867 active=77985 piece=▁계산\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9464 size=2980 all=1353909 active=82027 piece=▁빼\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9380 size=3000 all=1356183 active=84301 piece=졌으며\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9378 min_freq=259\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9318 size=3020 all=1360226 active=71756 piece=상과\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9269 size=3040 all=1364098 active=75628 piece=▁불린다\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9197 size=3060 all=1368860 active=80390 piece=▁국방\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9124 size=3080 all=1372477 active=84007 piece=▁사회주의\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=9043 size=3100 all=1377340 active=88870 piece=▁재직\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=9041 min_freq=254\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8994 size=3120 all=1380779 active=72231 piece=▁1973\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8915 size=3140 all=1384887 active=76339 piece=데미\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8868 size=3160 all=1389103 active=80555 piece=▁500\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8818 size=3180 all=1392148 active=83600 piece=라운드\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8753 size=3200 all=1395802 active=87254 piece=▁연맹\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8749 min_freq=249\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8649 size=3220 all=1401440 active=75309 piece=▁1976\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8591 size=3240 all=1407612 active=81481 piece=포르\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8548 size=3260 all=1411300 active=85169 piece=사령\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8482 size=3280 all=1414211 active=88080 piece=▁동계\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8411 size=3300 all=1417969 active=91838 piece=▁덴마\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8410 min_freq=244\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8352 size=3320 all=1421920 active=74836 piece=▁시장\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8303 size=3340 all=1425684 active=78600 piece=▁지역은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8255 size=3360 all=1429798 active=82714 piece=틀랜드\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8207 size=3380 all=1433115 active=86031 piece=셔널\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8145 size=3400 all=1437560 active=90476 piece=▁북서\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=8140 min_freq=240\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8103 size=3420 all=1441293 active=75523 piece=세대\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8052 size=3440 all=1446092 active=80322 piece=▁흘\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=8011 size=3460 all=1450527 active=84757 piece=▁짧은\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "corpus = \"./kowiki.txt\"\n",
    "prefix = \"kowiki\"\n",
    "vocab_size = 8000\n",
    "spm.SentencePieceTrainer.train(\n",
    "    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size+7}\" +\n",
    "    \" --model_type=bpe\" +\n",
    "        \" --max_sentence_length=999999\" + #문장최대길이\n",
    "        \" --pad_id=0 --pad_piece=[PAD]\" + #pad (0)\n",
    "        \" --unk_id=1 --unk_piece=[UNK]\" + #unknown (1)\n",
    "        \" --bos_id=2 --bos_piece=[BOS]\" + #begin of sequence (2)\n",
    "        \" --eos_id=3 --eos_piece=[EOS]\" + #end of sequence (3)\n",
    "        \" --user_defined_symbols=[SEP],[CLS],[MASK]\" #사용자 지정 토큰\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35449093-9db7-4800-bbac-718c10b66243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "겨울이 되어서 날씨가 무척 추워요.\n",
      "['▁겨울', '이', '▁되어', '서', '▁날', '씨', '가', '▁무', '척', '▁추', '워', '요', '.']\n",
      "[3221, 3632, 681, 3646, 718, 4082, 3643, 108, 4235, 199, 4001, 3802, 3634]\n",
      "\n",
      "이번 성탄절은 화이트 크리스마스가 될까요?\n",
      "['▁이번', '▁성', '탄', '절', '은', '▁화', '이트', '▁크리스', '마', '스가', '▁될', '까', '요', '?']\n",
      "[2928, 90, 4013, 3968, 3648, 270, 645, 1901, 3706, 713, 1448, 3841, 3802, 4320]\n",
      "\n",
      "겨울에 감기 조심하시고 행복한 연말 되세요.\n",
      "['▁겨울', '에', '▁감', '기', '▁조', '심', '하', '시', '고', '▁행', '복', '한', '▁연', '말', '▁되', '세', '요', '.']\n",
      "[3221, 3635, 192, 3650, 54, 3879, 3640, 3657, 3645, 251, 3918, 3647, 62, 3878, 475, 3726, 3802, 3634]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "vocab_file = \"./kowiki.model\"\n",
    "vocab = spm.SentencePieceProcessor()\n",
    "vocab.load(vocab_file)\n",
    "\n",
    "lines = [\n",
    "    \"겨울이 되어서 날씨가 무척 추워요.\",\n",
    "    \"이번 성탄절은 화이트 크리스마스가 될까요?\",\n",
    "    \"겨울에 감기 조심하시고 행복한 연말 되세요.\"\n",
    "]\n",
    "#문장 -> 토큰화 -> 정수 임베딩 \n",
    "for line in lines:\n",
    "    pieces = vocab.encode_as_pieces(line)\n",
    "    ids = vocab.encode_as_ids(line)\n",
    "    print(line)\n",
    "    print(pieces)\n",
    "    print(ids)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebc82ea1-3b63-49cf-af3e-4f3ad4c87d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=6fb0cd95bca909b9b3a46089ff9728ff49b424e59d2a2384443110c9fe8642bc\n",
      "  Stored in directory: /home/qkrwnstj/.cache/pip/wheels/04/5f/3e/46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0399aee0-8d06-4d12-b897-06bacd99e156",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb89643-22f8-4285-aff5-6a4c01c67dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm, trange\n",
    "import sentencepiece as spm\n",
    "import wget\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd3cc9-2303-4f1d-9c8e-c9a9a1521fa4",
   "metadata": {},
   "source": [
    "# 1. Pre-train GPTv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25b7d217-5874-4e89-a9a1-ba53bd7262ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sentencepiece.SentencePieceProcessor; proxy of <Swig Object of type 'sentencepiece::SentencePieceProcessor *' at 0x7f2f58baaf30> >"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c22b3f4-c4b0-4273-aec4-4312e652b389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_dec_vocab': 8007, 'n_dec_seq': 256, 'n_layer': 1, 'd_hidn': 128, 'i_pad': 0, 'd_ff': 512, 'n_head': 4, 'd_head': 32, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': 'cuda'}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" configuration json을 읽어들이는 class\"\"\"\n",
    "class Config(dict):\n",
    "    __getattr__ = dict.__getitem__\n",
    "    __setattr__ = dict.__setitem__\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, file):\n",
    "        with open(file, 'r') as f:\n",
    "            config = json.loads(f.read(0))\n",
    "            return Config(config)\n",
    "\n",
    "config = Config({\n",
    "    \"n_dec_vocab\" : len(vocab),\n",
    "    \"n_dec_seq\" : 256,\n",
    "    \"n_layer\" : 1,\n",
    "    \"d_hidn\" : 128,\n",
    "    \"i_pad\" : 0,\n",
    "    \"d_ff\" : 512,\n",
    "    \"n_head\" : 4,\n",
    "    \"d_head\" : 32,\n",
    "    \"dropout\" : 0.1,\n",
    "    \"layer_norm_epsilon\" : 1e-12,\n",
    "    \"device\" : 'cuda'\n",
    "})\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e15036e8-6904-4b70-be7f-7be735be2fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.d_hidn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8de904a9-93d3-470d-ba99-b166a305664a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"attention pad mask\"\"\"\n",
    "def get_attn_pad_mask(seq_q, seq_k, i_pad):\n",
    "    #(bs, q_seq_len), (bs, k_seq_len)\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    #(bs, k_seq_len) -> (bs, 1, k_seq_len) -> (bs, q_seq_len, k_seq_len) : \n",
    "    #(1, k_seq_len)를 아래로, q_seq_len 만큼 복사\n",
    "    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)\n",
    "    return pad_attn_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a04c4bcf-25e2-4219-a47b-75027e451bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"attention decoder mask\"\"\"\n",
    "def get_attn_decoder_mask(seq):\n",
    "    #(bs, seq_len, seq_len)\n",
    "    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
    "    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n",
    "    return subsequent_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d23faf6f-d86e-446c-b4e0-d0005cbf1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"scale dot product attention\"\"\"\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "        self.scale = 1 / (self.config.d_head ** 0.5) #d_head : head dimension, n_head * d_head = d_hidn\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        #(bs, n_head, n_q_seq, n_k_seq)\n",
    "        scores = torch.matmul(Q, K.transpose(-1,-2)).mul_(self.scale)\n",
    "        scores.masked_fill_(attn_mask, -1e9)\n",
    "        #(bs, n_head, n_q_seq, n_k_seq)\n",
    "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
    "        attn_prob = self.dropout(attn_prob)\n",
    "        #(bs, n_head, n_q_seq, d_v)\n",
    "        context = torch.matmul(attn_prob, V)\n",
    "        #(bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_k_seq)\n",
    "        return context, attn_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f85134f0-a274-4d99-b4ba-7bd53aa780a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"multi-head attention\"\"\"\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
    "        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
    "        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n",
    "        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
    "        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, K, Q, V, attn_mask):\n",
    "        batch_size = Q.size(0)\n",
    "        #(bs, n_head, n_q_seq, d_head)\n",
    "        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n",
    "\n",
    "        #(bs, n_head, n_q_seq, n_k_seq)\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1,self.config.n_head,1 ,1)\n",
    "        \n",
    "        #(bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
    "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
    "        #(bs, n_q_seq, n_head * d_head)\n",
    "        context = context.transpose(1,2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n",
    "        #(bs, n_head, n_q_seq, d_hidn)\n",
    "        output = self.linear(context)\n",
    "        output = self.dropout(output)\n",
    "        #(bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
    "        return output, attn_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba1e1a94-2f28-4969-86bb-18ca8cf2447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"feed forward\"\"\"\n",
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels = self.config.d_hidn, out_channels = self.config.d_ff, kernel_size = 1)\n",
    "        self.conv2 = nn.Conv1d(in_channels = self.config.d_ff, out_channels = self.config.d_hidn, kernel_size = 1)\n",
    "        self.active = F.gelu\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        #(bs, d_ff, n_seq)\n",
    "        output = self.active(self.conv1(inputs.transpose(1,2)))\n",
    "        #(bs, n_seq, d_hidn)\n",
    "        output = self.conv2(output).transpose(1,2)\n",
    "        output = self.dropout(output)\n",
    "        #(bs, n_seq, d_hidn)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "655dd7c7-fe8d-4bf5-bba5-13688294ab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"decoder layer\"\"\"\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(self.config)\n",
    "        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps = self.config.layer_norm_epsilon)\n",
    "        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n",
    "        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps = self.config.layer_norm_epsilon)\n",
    "\n",
    "    def forward(self, dec_inputs, self_attn_mask):\n",
    "        #(bs, n_dec_seq, d_hidn), (bs, n_head, n_dec,seq, n_dec_seq)\n",
    "        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
    "        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n",
    "        #(bs, n_dec_seq, d_hidn)\n",
    "        ffn_outputs = self.pos_ffn(self_att_outputs)\n",
    "        ffn_outputs = self.layer_norm3(self_att_outputs + ffn_outputs)\n",
    "        #(bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n",
    "        return ffn_outputs, self_attn_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9be89424-cdaf-4bb5-a9a4-1e96fef5b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"decoder\"\"\"\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
    "        self.pos_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n",
    "\n",
    "        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n",
    "\n",
    "    def forward(self, dec_inputs):\n",
    "        positions = torch.arange(dec_inputs.size(1), device = dec_inputs.device, dtype = dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
    "        pos_mask = dec_inputs.eq(self.config.i_pad)\n",
    "        positions.masked_fill_(pos_mask, 0)\n",
    "\n",
    "        #(bs, n_dec_seq, d_hidn)\n",
    "        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
    "\n",
    "        #(bs, n_dec_seq, n_dec_seq)\n",
    "        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n",
    "        #(bs, n_dec_seq, n_dec_seq)\n",
    "        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
    "        #(bs, n_dec_seq, n_dec_seq)\n",
    "        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask),0)\n",
    "\n",
    "        self_attn_probs = []\n",
    "        for layer in self.layers:\n",
    "            #(bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq)\n",
    "            dec_outputs, self_attn_prob = layer(dec_outputs, dec_self_attn_mask)\n",
    "            self_attn_probs.append(self_attn_prob)\n",
    "\n",
    "        #(bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)])\n",
    "        return dec_outputs, self_attn_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6d63039-7524-439d-8c08-82f0c2fbc2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"gpt\"\"\"\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.decoder = Decoder(self.config)\n",
    "\n",
    "    def forward(self, dec_inputs):\n",
    "        #(bs, n_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
    "        dec_outputs, dec_self_attn_probs = self.decoder(dec_inputs)\n",
    "        #(bs, n_dec_seq, n_dec_vocab), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
    "        return dec_outputs, dec_self_attn_probs\n",
    "\n",
    "    def save(self, epoch, loss ,path):\n",
    "        torch.save({\n",
    "            \"epoch\" : epoch,\n",
    "            \"loss\" : loss,\n",
    "            \"state_dict\" : self.state_dict()\n",
    "        },path)\n",
    "\n",
    "    def load(self, path):\n",
    "        save = torch.load(path)\n",
    "        self.load_state_dict(save[\"state_dict\"])\n",
    "        return save[\"epoch\"], save[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4056c9a5-a61a-410e-93c4-117d04120944",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"gpt pre-train\"\"\"\n",
    "class GPTPretrain(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.gpt = GPT(self.config)\n",
    "        #lm\n",
    "        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_dec_vocab, bias = False)\n",
    "        self.projection_lm.weight = self.gpt.decoder.dec_emb.weight\n",
    "\n",
    "    def forward(self, dec_inputs):\n",
    "        #(bs, n_dec_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
    "        dec_outputs, dec_self_attn_probs = self.gpt(dec_inputs)\n",
    "        #(bs, n_dec_seq, n_dec_vocab)\n",
    "        logits_lm = self.projection_lm(dec_outputs)\n",
    "        # (bs, n_dec_seq - 1, n_dec_vocab), (bs, n_output), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
    "        # logits_lm[:, :-1, :] -> input을 [<sos> ~ <eos>] 로 넣기 때문에 output은 [~ <eos>, trash]로 나온다. 해서 마지막은 버리고 output으로 가져옴\n",
    "        return logits_lm[:, :-1, :].contiguous(), dec_self_attn_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fe2c90f-c10e-4935-a652-de5a7f220085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "document 별 pretrain data generation\n",
    "단락을 여러 개의 pretrain data로 만든다.\n",
    "\"\"\"\n",
    "def create_pretrain_instances(doc, n_seq):\n",
    "    # for [BOS], [EOS]\n",
    "    max_seq = n_seq - 2\n",
    "    tgt_seq = max_seq\n",
    "    \n",
    "    instances = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for i in range(len(doc)):\n",
    "        current_chunk.append(doc[i]) # line\n",
    "        current_length += len(doc[i])\n",
    "        if i == len(doc) - 1 or current_length >= tgt_seq:\n",
    "            if 0 < len(current_chunk):\n",
    "                tokens = []\n",
    "                for chunk in current_chunk: tokens.extend(chunk)\n",
    "                tokens = tokens[:tgt_seq]\n",
    "                if 1 < len(tokens):\n",
    "                    instance = {\n",
    "                        \"tokens\": [\"[BOS]\"] + tokens + [\"[EOS]\"],\n",
    "                    }\n",
    "                    instances.append(instance)\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16e286a0-73aa-4461-82be-8d5509ac97e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pretrain 데이터 생성 \"\"\"\n",
    "def make_pretrain_data(vocab, in_file, out_file, n_seq):\n",
    "    line_cnt = 0\n",
    "    with open(in_file, \"r\") as in_f:\n",
    "        for line in in_f:\n",
    "            line_cnt += 1\n",
    "\n",
    "    docs = []\n",
    "    with open(in_file, \"r\") as f:\n",
    "        doc = []\n",
    "        with tqdm(total=line_cnt, desc=f\"Loading\") as pbar:\n",
    "            for i, line in enumerate(f):\n",
    "                line = line.strip()\n",
    "                if line == \"\":\n",
    "                    if 0 < len(doc):\n",
    "                        docs.append(doc)\n",
    "                        doc = []\n",
    "                else:\n",
    "                    pieces = vocab.encode_as_pieces(line)\n",
    "                    if 0 < len(pieces):\n",
    "                        doc.append(pieces)\n",
    "                pbar.update(1)\n",
    "        if doc:\n",
    "            docs.append(doc)\n",
    "\n",
    "    with open(out_file, \"w\") as out_f:\n",
    "        with tqdm(total=len(docs), desc=f\"Making\") as pbar:\n",
    "            for i, doc in enumerate(docs):\n",
    "                instances = create_pretrain_instances(doc, n_seq)\n",
    "                for instance in instances:\n",
    "                    out_f.write(json.dumps(instance))\n",
    "                    out_f.write(\"\\n\")\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9a6e9e29-b776-4590-8e32-2ab98143f3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA  AD\tAG  kowiki-latest-pages-meta-current.xml.bz2  kowiki.vocab\n",
      "AB  AE\tAH  kowiki.model\t\t\t      kowiki_20230815.csv\n",
      "AC  AF\tAI  kowiki.txt\t\t\t\t      kowiki_gpt.json\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d9bebc1-948c-4c78-bf56-9c5295644127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./kowiki_gpt.json exists\n"
     ]
    }
   ],
   "source": [
    "in_file = \"./kowiki.txt\"\n",
    "out_file = \"./kowiki_gpt.json\"\n",
    "n_seq = 256\n",
    "\n",
    "if not os.path.isfile(out_file):\n",
    "    make_pretrain_data(vocab, in_file, out_file, n_seq)\n",
    "else:\n",
    "    print(f\"{out_file} exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d356676-06ae-4f98-bf2d-c0869477dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pretrain 데이터셋 \"\"\"\n",
    "class PretrainDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, vocab, infile):\n",
    "        self.vocab = vocab\n",
    "        self.sentences = []\n",
    "\n",
    "        line_cnt = 0\n",
    "        with open(infile, \"r\") as f:\n",
    "            for line in f:\n",
    "                line_cnt += 1\n",
    "\n",
    "        with open(infile, \"r\") as f:\n",
    "            with tqdm(total=line_cnt, desc=f\"Loading\") as pbar:\n",
    "                for i, line in enumerate(f):\n",
    "                    instance = json.loads(line)\n",
    "                    self.sentences.append([vocab.piece_to_id(p) for p in instance[\"tokens\"]])\n",
    "                    pbar.update(1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return (torch.tensor(self.sentences[item]), torch.tensor(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73528ffe-7114-4c80-a335-9bcfc3586148",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" pretrain data collate_fn \"\"\"\n",
    "def pretrin_collate_fn(inputs):\n",
    "    dec_inputs, item = list(zip(*inputs))\n",
    "\n",
    "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n",
    "\n",
    "    batch = [\n",
    "        dec_inputs,\n",
    "        torch.stack(item, dim=0),\n",
    "    ]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b92332b4-95c2-4a1f-88ec-609bb7beca7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (8.1.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipywidgets) (8.12.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipywidgets) (3.0.8)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipywidgets) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipywidgets) (4.0.8)\n",
      "Requirement already satisfied: backcall in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (2.14.0)\n",
      "Requirement already satisfied: matplotlib-inline in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: typing-extensions in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: stack-data in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.2)\n",
      "Requirement already satisfied: decorator in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.38)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.6)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: six in /home/qkrwnstj/anaconda3/envs/qkrwnstj/lib/python3.9/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c9b489-663d-4968-8466-3fb7af4ae7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  96%|███████████████▍| 1008711/1049545 [02:37<00:04, 9083.66it/s]"
     ]
    }
   ],
   "source": [
    "\"\"\" pretrain 데이터 로더 \"\"\"\n",
    "batch_size = 2#128로 하면 24G도 튕긴다.\n",
    "dataset = PretrainDataSet(vocab, f\"./kowiki_gpt.json\")\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, collate_fn= pretrin_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6665971-3864-4624-8c00-37ab26200296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" 모델 epoch 학습 \"\"\"\n",
    "def train_epoch(config, epoch, model, criterion_lm, optimizer, train_loader):\n",
    "    losses = []\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
    "        for i, value in enumerate(train_loader):\n",
    "            dec_inputs, _ = map(lambda v: v.to(config.device), value)\n",
    "            #<sos> 제외, target은 [~ <eos>]\n",
    "            labels_lm = dec_inputs[:, 1:].contiguous()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            #output은 [~ <eos>]\n",
    "            outputs = model(dec_inputs)\n",
    "            logits_lm = outputs[0]\n",
    "\n",
    "            loss_lm = criterion_lm(logits_lm.view(-1, logits_lm.size(2)), labels_lm.view(-1))\n",
    "            loss = loss_lm \n",
    "\n",
    "            loss_val = loss_lm.item()\n",
    "            losses.append(loss_val)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302882d3-3a77-44d7-877b-3436844d5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(config)\n",
    "\n",
    "learning_rate = 5e-5\n",
    "n_epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa8a3d7-a69b-4bbe-93f6-980e7456b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820519a6-c498-4fd4-9d2a-4ac8f30446d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e5751b-7f14-4e22-82ab-2ece2a1d0b5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                       | 0/20 [00:00<?, ?it/s]\n",
      "Train(0):   0%|                                | 0/262387 [00:00<?, ?it/s]\u001b[A\n",
      "Train(0):   0%|                    | 1/262387 [00:01<140:26:33,  1.93s/it]\u001b[A\n",
      "Train(0):   0%| | 1/262387 [00:01<140:26:33,  1.93s/it, Loss: 74.306 (74.3\u001b[A\n",
      "Train(0):   0%| | 2/262387 [00:01<140:26:31,  1.93s/it, Loss: 49.960 (62.1\u001b[A\n",
      "Train(0):   0%| | 3/262387 [00:01<140:26:29,  1.93s/it, Loss: 43.689 (55.9\u001b[A\n",
      "Train(0):   0%| | 4/262387 [00:02<140:26:27,  1.93s/it, Loss: 50.497 (54.6\u001b[A\n",
      "Train(0):   0%| | 5/262387 [00:02<22:47:45,  3.20it/s, Loss: 50.497 (54.61\u001b[A\n",
      "Train(0):   0%| | 5/262387 [00:02<22:47:45,  3.20it/s, Loss: 44.761 (52.64\u001b[A\n",
      "Train(0):   0%| | 6/262387 [00:02<22:47:45,  3.20it/s, Loss: 39.996 (50.53\u001b[A\n",
      "Train(0):   0%| | 7/262387 [00:02<15:33:44,  4.68it/s, Loss: 39.996 (50.53\u001b[A\n",
      "Train(0):   0%| | 7/262387 [00:02<15:33:44,  4.68it/s, Loss: 42.656 (49.40\u001b[A\n",
      "Train(0):   0%| | 8/262387 [00:02<15:33:44,  4.68it/s, Loss: 65.413 (51.41\u001b[A\n",
      "Train(0):   0%| | 9/262387 [00:02<15:33:44,  4.68it/s, Loss: 35.299 (49.62\u001b[A\n",
      "Train(0):   0%| | 10/262387 [00:02<15:33:44,  4.68it/s, Loss: 26.683 (47.3\u001b[A\n",
      "Train(0):   0%| | 11/262387 [00:02<8:36:27,  8.47it/s, Loss: 26.683 (47.32\u001b[A\n",
      "Train(0):   0%| | 11/262387 [00:02<8:36:27,  8.47it/s, Loss: 50.804 (47.64\u001b[A\n",
      "Train(0):   0%| | 12/262387 [00:02<8:36:27,  8.47it/s, Loss: 32.508 (46.38\u001b[A\n",
      "Train(0):   0%| | 13/262387 [00:02<8:36:27,  8.47it/s, Loss: 63.312 (47.68\u001b[A\n",
      "Train(0):   0%| | 14/262387 [00:02<8:36:27,  8.47it/s, Loss: 51.692 (47.97\u001b[A\n",
      "Train(0):   0%| | 15/262387 [00:02<5:54:10, 12.35it/s, Loss: 51.692 (47.97\u001b[A\n",
      "Train(0):   0%| | 15/262387 [00:02<5:54:10, 12.35it/s, Loss: 63.764 (49.02\u001b[A\n",
      "Train(0):   0%| | 16/262387 [00:02<5:54:10, 12.35it/s, Loss: 62.148 (49.84\u001b[A\n",
      "Train(0):   0%| | 17/262387 [00:02<5:54:10, 12.35it/s, Loss: 50.054 (49.85\u001b[A\n",
      "Train(0):   0%| | 18/262387 [00:02<5:54:10, 12.35it/s, Loss: 75.465 (51.27\u001b[A\n",
      "Train(0):   0%| | 19/262387 [00:02<4:22:53, 16.63it/s, Loss: 75.465 (51.27\u001b[A\n",
      "Train(0):   0%| | 19/262387 [00:02<4:22:53, 16.63it/s, Loss: 31.808 (50.25\u001b[A\n",
      "Train(0):   0%| | 20/262387 [00:02<4:22:53, 16.63it/s, Loss: 42.990 (49.89\u001b[A\n",
      "Train(0):   0%| | 21/262387 [00:02<4:22:53, 16.63it/s, Loss: 59.673 (50.35\u001b[A\n",
      "Train(0):   0%| | 22/262387 [00:02<4:22:53, 16.63it/s, Loss: 72.300 (51.35\u001b[A\n",
      "Train(0):   0%| | 23/262387 [00:02<3:30:45, 20.75it/s, Loss: 72.300 (51.35\u001b[A\n",
      "Train(0):   0%| | 23/262387 [00:02<3:30:45, 20.75it/s, Loss: 53.558 (51.44\u001b[A\n",
      "Train(0):   0%| | 24/262387 [00:02<3:30:45, 20.75it/s, Loss: 47.718 (51.29\u001b[A\n",
      "Train(0):   0%| | 25/262387 [00:02<3:30:45, 20.75it/s, Loss: 27.691 (50.35\u001b[A\n",
      "Train(0):   0%| | 26/262387 [00:02<3:30:45, 20.75it/s, Loss: 35.187 (49.76\u001b[A\n",
      "Train(0):   0%| | 27/262387 [00:02<2:58:17, 24.52it/s, Loss: 35.187 (49.76\u001b[A\n",
      "Train(0):   0%| | 27/262387 [00:02<2:58:17, 24.52it/s, Loss: 53.350 (49.89\u001b[A\n",
      "Train(0):   0%| | 28/262387 [00:02<2:58:17, 24.52it/s, Loss: 46.646 (49.78\u001b[A\n",
      "Train(0):   0%| | 29/262387 [00:02<2:58:17, 24.52it/s, Loss: 41.017 (49.48\u001b[A\n",
      "Train(0):   0%| | 30/262387 [00:02<2:58:17, 24.52it/s, Loss: 37.458 (49.08\u001b[A\n",
      "Train(0):   0%| | 31/262387 [00:02<2:53:56, 25.14it/s, Loss: 37.458 (49.08\u001b[A\n",
      "Train(0):   0%| | 31/262387 [00:02<2:53:56, 25.14it/s, Loss: 32.528 (48.54\u001b[A\n",
      "Train(0):   0%| | 32/262387 [00:02<2:53:56, 25.14it/s, Loss: 41.810 (48.33\u001b[A\n",
      "Train(0):   0%| | 33/262387 [00:02<2:53:56, 25.14it/s, Loss: 54.713 (48.52\u001b[A\n",
      "Train(0):   0%| | 34/262387 [00:02<2:53:56, 25.14it/s, Loss: 57.117 (48.78\u001b[A\n",
      "Train(0):   0%| | 35/262387 [00:02<2:33:43, 28.45it/s, Loss: 57.117 (48.78\u001b[A\n",
      "Train(0):   0%| | 35/262387 [00:02<2:33:43, 28.45it/s, Loss: 58.708 (49.06\u001b[A\n",
      "Train(0):   0%| | 36/262387 [00:02<2:33:43, 28.45it/s, Loss: 55.697 (49.24\u001b[A\n",
      "Train(0):   0%| | 37/262387 [00:03<2:33:42, 28.45it/s, Loss: 37.696 (48.93\u001b[A\n",
      "Train(0):   0%| | 38/262387 [00:03<2:33:42, 28.45it/s, Loss: 26.651 (48.35\u001b[A\n",
      "Train(0):   0%| | 39/262387 [00:03<2:29:33, 29.24it/s, Loss: 26.651 (48.35\u001b[A\n",
      "Train(0):   0%| | 39/262387 [00:03<2:29:33, 29.24it/s, Loss: 48.955 (48.36\u001b[A\n",
      "Train(0):   0%| | 40/262387 [00:03<2:29:33, 29.24it/s, Loss: 51.696 (48.44\u001b[A\n",
      "Train(0):   0%| | 41/262387 [00:03<2:29:33, 29.24it/s, Loss: 30.635 (48.01\u001b[A\n",
      "Train(0):   0%| | 42/262387 [00:03<2:29:32, 29.24it/s, Loss: 33.838 (47.67\u001b[A\n",
      "Train(0):   0%| | 43/262387 [00:03<2:21:35, 30.88it/s, Loss: 33.838 (47.67\u001b[A\n",
      "Train(0):   0%| | 43/262387 [00:03<2:21:35, 30.88it/s, Loss: 50.269 (47.73\u001b[A\n",
      "Train(0):   0%| | 44/262387 [00:03<2:21:35, 30.88it/s, Loss: 44.335 (47.66\u001b[A\n",
      "Train(0):   0%| | 45/262387 [00:03<2:21:35, 30.88it/s, Loss: 31.267 (47.29\u001b[A\n",
      "Train(0):   0%| | 46/262387 [00:03<2:21:35, 30.88it/s, Loss: 32.195 (46.96\u001b[A\n",
      "Train(0):   0%| | 47/262387 [00:03<2:19:21, 31.38it/s, Loss: 32.195 (46.96\u001b[A\n",
      "Train(0):   0%| | 47/262387 [00:03<2:19:21, 31.38it/s, Loss: 25.296 (46.50\u001b[A\n",
      "Train(0):   0%| | 48/262387 [00:03<2:19:20, 31.38it/s, Loss: 30.449 (46.17\u001b[A\n",
      "Train(0):   0%| | 49/262387 [00:03<2:19:20, 31.38it/s, Loss: 31.741 (45.87\u001b[A\n",
      "Train(0):   0%| | 50/262387 [00:03<2:19:20, 31.38it/s, Loss: 33.486 (45.63\u001b[A\n",
      "Train(0):   0%| | 51/262387 [00:03<2:12:01, 33.12it/s, Loss: 33.486 (45.63\u001b[A\n",
      "Train(0):   0%| | 51/262387 [00:03<2:12:01, 33.12it/s, Loss: 32.121 (45.36\u001b[A\n",
      "Train(0):   0%| | 52/262387 [00:03<2:12:01, 33.12it/s, Loss: 27.648 (45.02\u001b[A\n",
      "Train(0):   0%| | 53/262387 [00:03<2:12:01, 33.12it/s, Loss: 33.085 (44.79\u001b[A\n",
      "Train(0):   0%| | 54/262387 [00:03<2:12:01, 33.12it/s, Loss: 17.636 (44.29\u001b[A\n",
      "Train(0):   0%| | 55/262387 [00:03<2:13:09, 32.83it/s, Loss: 17.636 (44.29\u001b[A\n",
      "Train(0):   0%| | 55/262387 [00:03<2:13:09, 32.83it/s, Loss: 47.886 (44.36\u001b[A\n",
      "Train(0):   0%| | 56/262387 [00:03<2:13:09, 32.83it/s, Loss: 42.346 (44.32\u001b[A\n",
      "Train(0):   0%| | 57/262387 [00:03<2:13:09, 32.83it/s, Loss: 21.340 (43.92\u001b[A\n",
      "Train(0):   0%| | 58/262387 [00:03<2:13:09, 32.83it/s, Loss: 36.575 (43.79\u001b[A\n",
      "Train(0):   0%| | 59/262387 [00:03<2:14:47, 32.44it/s, Loss: 36.575 (43.79\u001b[A\n",
      "Train(0):   0%| | 59/262387 [00:03<2:14:47, 32.44it/s, Loss: 17.644 (43.35\u001b[A\n",
      "Train(0):   0%| | 60/262387 [00:03<2:14:47, 32.44it/s, Loss: 21.137 (42.98\u001b[A\n",
      "Train(0):   0%| | 61/262387 [00:03<2:14:47, 32.44it/s, Loss: 15.261 (42.52\u001b[A\n",
      "Train(0):   0%| | 62/262387 [00:03<2:14:47, 32.44it/s, Loss: 25.513 (42.25\u001b[A\n",
      "Train(0):   0%| | 63/262387 [00:03<2:08:20, 34.07it/s, Loss: 25.513 (42.25\u001b[A\n",
      "Train(0):   0%| | 63/262387 [00:03<2:08:20, 34.07it/s, Loss: 37.516 (42.17\u001b[A\n",
      "Train(0):   0%| | 64/262387 [00:03<2:08:20, 34.07it/s, Loss: 19.313 (41.82\u001b[A\n",
      "Train(0):   0%| | 65/262387 [00:03<2:08:20, 34.07it/s, Loss: 37.561 (41.75\u001b[A\n",
      "Train(0):   0%| | 66/262387 [00:03<2:08:20, 34.07it/s, Loss: 31.200 (41.59\u001b[A\n",
      "Train(0):   0%| | 67/262387 [00:03<2:04:15, 35.19it/s, Loss: 31.200 (41.59\u001b[A\n",
      "Train(0):   0%| | 67/262387 [00:03<2:04:15, 35.19it/s, Loss: 25.735 (41.35\u001b[A\n",
      "Train(0):   0%| | 68/262387 [00:03<2:04:15, 35.19it/s, Loss: 13.852 (40.95\u001b[A\n",
      "Train(0):   0%| | 69/262387 [00:03<2:04:15, 35.19it/s, Loss: 14.719 (40.57\u001b[A\n",
      "Train(0):   0%| | 70/262387 [00:03<2:04:15, 35.19it/s, Loss: 22.906 (40.32\u001b[A\n",
      "Train(0):   0%| | 71/262387 [00:03<2:01:20, 36.03it/s, Loss: 22.906 (40.32\u001b[A\n",
      "Train(0):   0%| | 71/262387 [00:03<2:01:20, 36.03it/s, Loss: 16.617 (39.98\u001b[A\n",
      "Train(0):   0%| | 72/262387 [00:04<2:01:20, 36.03it/s, Loss: 25.681 (39.78\u001b[A\n",
      "Train(0):   0%| | 73/262387 [00:04<2:01:20, 36.03it/s, Loss: 21.205 (39.53\u001b[A\n",
      "Train(0):   0%| | 74/262387 [00:04<2:01:20, 36.03it/s, Loss: 30.218 (39.40\u001b[A\n",
      "Train(0):   0%| | 75/262387 [00:04<2:07:51, 34.19it/s, Loss: 30.218 (39.40\u001b[A\n",
      "Train(0):   0%| | 75/262387 [00:04<2:07:51, 34.19it/s, Loss: 17.143 (39.11\u001b[A\n",
      "Train(0):   0%| | 76/262387 [00:04<2:07:51, 34.19it/s, Loss: 21.352 (38.87\u001b[A\n",
      "Train(0):   0%| | 77/262387 [00:04<2:07:51, 34.19it/s, Loss: 29.761 (38.75\u001b[A\n",
      "Train(0):   0%| | 78/262387 [00:04<2:07:51, 34.19it/s, Loss: 22.428 (38.55\u001b[A\n",
      "Train(0):   0%| | 79/262387 [00:04<2:04:45, 35.04it/s, Loss: 22.428 (38.55\u001b[A\n",
      "Train(0):   0%| | 79/262387 [00:04<2:04:45, 35.04it/s, Loss: 29.396 (38.43\u001b[A\n",
      "Train(0):   0%| | 80/262387 [00:04<2:04:45, 35.04it/s, Loss: 14.094 (38.13\u001b[A\n",
      "Train(0):   0%| | 81/262387 [00:04<2:04:45, 35.04it/s, Loss: 26.219 (37.98\u001b[A\n",
      "Train(0):   0%| | 82/262387 [00:04<2:04:45, 35.04it/s, Loss: 21.096 (37.77\u001b[A\n",
      "Train(0):   0%| | 83/262387 [00:04<2:04:45, 35.04it/s, Loss: 32.009 (37.70\u001b[A\n",
      "Train(0):   0%| | 84/262387 [00:04<1:53:28, 38.53it/s, Loss: 32.009 (37.70\u001b[A\n",
      "Train(0):   0%| | 84/262387 [00:04<1:53:28, 38.53it/s, Loss: 34.010 (37.66\u001b[A\n",
      "Train(0):   0%| | 85/262387 [00:04<1:53:28, 38.53it/s, Loss: 21.162 (37.46\u001b[A\n",
      "Train(0):   0%| | 86/262387 [00:04<1:53:28, 38.53it/s, Loss: 30.086 (37.38\u001b[A\n",
      "Train(0):   0%| | 87/262387 [00:04<1:53:28, 38.53it/s, Loss: 17.480 (37.15\u001b[A\n",
      "Train(0):   0%| | 88/262387 [00:04<1:53:28, 38.53it/s, Loss: 14.575 (36.89\u001b[A\n",
      "Train(0):   0%| | 89/262387 [00:04<1:47:19, 40.74it/s, Loss: 14.575 (36.89\u001b[A\n",
      "Train(0):   0%| | 89/262387 [00:04<1:47:19, 40.74it/s, Loss: 23.929 (36.75\u001b[A\n",
      "Train(0):   0%| | 90/262387 [00:04<1:47:18, 40.74it/s, Loss: 21.450 (36.58\u001b[A\n",
      "Train(0):   0%| | 91/262387 [00:04<1:47:18, 40.74it/s, Loss: 28.815 (36.49\u001b[A\n",
      "Train(0):   0%| | 92/262387 [00:04<1:47:18, 40.74it/s, Loss: 21.926 (36.33\u001b[A\n",
      "Train(0):   0%| | 93/262387 [00:04<1:47:18, 40.74it/s, Loss: 21.477 (36.17\u001b[A\n",
      "Train(0):   0%| | 94/262387 [00:04<1:46:53, 40.90it/s, Loss: 21.477 (36.17\u001b[A\n",
      "Train(0):   0%| | 94/262387 [00:04<1:46:53, 40.90it/s, Loss: 15.178 (35.95\u001b[A\n",
      "Train(0):   0%| | 95/262387 [00:04<1:46:53, 40.90it/s, Loss: 25.745 (35.84\u001b[A\n",
      "Train(0):   0%| | 96/262387 [00:04<1:46:52, 40.90it/s, Loss: 28.080 (35.76\u001b[A\n",
      "Train(0):   0%| | 97/262387 [00:04<1:46:52, 40.90it/s, Loss: 28.250 (35.68\u001b[A\n",
      "Train(0):   0%| | 98/262387 [00:04<1:46:52, 40.90it/s, Loss: 21.039 (35.54\u001b[A\n",
      "Train(0):   0%| | 99/262387 [00:04<1:47:15, 40.76it/s, Loss: 21.039 (35.54\u001b[A\n",
      "Train(0):   0%| | 99/262387 [00:04<1:47:15, 40.76it/s, Loss: 21.787 (35.40\u001b[A\n",
      "Train(0):   0%| | 100/262387 [00:04<1:47:15, 40.76it/s, Loss: 20.927 (35.2\u001b[A\n",
      "Train(0):   0%| | 101/262387 [00:04<1:47:15, 40.76it/s, Loss: 29.314 (35.1\u001b[A\n",
      "Train(0):   0%| | 102/262387 [00:04<1:47:15, 40.76it/s, Loss: 27.788 (35.1\u001b[A\n",
      "Train(0):   0%| | 103/262387 [00:04<1:47:15, 40.76it/s, Loss: 13.038 (34.9\u001b[A\n",
      "Train(0):   0%| | 104/262387 [00:04<1:52:16, 38.94it/s, Loss: 13.038 (34.9\u001b[A\n",
      "Train(0):   0%| | 104/262387 [00:04<1:52:16, 38.94it/s, Loss: 19.821 (34.7\u001b[A\n",
      "Train(0):   0%| | 105/262387 [00:04<1:52:16, 38.94it/s, Loss: 22.056 (34.6\u001b[A\n",
      "Train(0):   0%| | 106/262387 [00:04<1:52:16, 38.94it/s, Loss: 24.261 (34.5\u001b[A\n",
      "Train(0):   0%| | 107/262387 [00:04<1:52:16, 38.94it/s, Loss: 25.501 (34.4\u001b[A\n",
      "Train(0):   0%| | 108/262387 [00:04<1:52:16, 38.94it/s, Loss: 19.376 (34.3\u001b[A\n",
      "Train(0):   0%| | 109/262387 [00:04<1:52:16, 38.94it/s, Loss: 12.882 (34.1\u001b[A\n",
      "Train(0):   0%| | 110/262387 [00:04<1:41:59, 42.86it/s, Loss: 12.882 (34.1\u001b[A\n",
      "Train(0):   0%| | 110/262387 [00:04<1:41:59, 42.86it/s, Loss: 18.962 (33.9\u001b[A\n",
      "Train(0):   0%| | 111/262387 [00:04<1:41:59, 42.86it/s, Loss: 33.528 (33.9\u001b[A\n",
      "Train(0):   0%| | 112/262387 [00:04<1:41:59, 42.86it/s, Loss: 21.194 (33.8\u001b[A\n",
      "Train(0):   0%| | 113/262387 [00:05<1:41:59, 42.86it/s, Loss: 28.037 (33.8\u001b[A\n",
      "Train(0):   0%| | 114/262387 [00:05<1:41:59, 42.86it/s, Loss: 26.043 (33.7\u001b[A\n",
      "Train(0):   0%| | 115/262387 [00:05<1:43:16, 42.32it/s, Loss: 26.043 (33.7\u001b[A\n",
      "Train(0):   0%| | 115/262387 [00:05<1:43:16, 42.32it/s, Loss: 17.699 (33.6\u001b[A\n",
      "Train(0):   0%| | 116/262387 [00:05<1:43:16, 42.32it/s, Loss: 25.631 (33.5\u001b[A\n",
      "Train(0):   0%| | 117/262387 [00:05<1:43:16, 42.32it/s, Loss: 19.362 (33.4\u001b[A\n",
      "Train(0):   0%| | 118/262387 [00:05<1:43:16, 42.32it/s, Loss: 30.394 (33.3\u001b[A\n",
      "Train(0):   0%| | 119/262387 [00:05<1:43:16, 42.32it/s, Loss: 20.807 (33.2\u001b[A\n",
      "Train(0):   0%| | 120/262387 [00:05<1:49:48, 39.81it/s, Loss: 20.807 (33.2\u001b[A\n",
      "Train(0):   0%| | 120/262387 [00:05<1:49:48, 39.81it/s, Loss: 19.065 (33.1\u001b[A\n",
      "Train(0):   0%| | 121/262387 [00:05<1:49:48, 39.81it/s, Loss: 21.711 (33.0\u001b[A\n",
      "Train(0):   0%| | 122/262387 [00:05<1:49:48, 39.81it/s, Loss: 17.796 (32.9\u001b[A\n",
      "Train(0):   0%| | 123/262387 [00:05<1:49:48, 39.81it/s, Loss: 19.723 (32.8\u001b[A\n",
      "Train(0):   0%| | 124/262387 [00:05<1:49:48, 39.81it/s, Loss: 19.355 (32.7\u001b[A\n",
      "Train(0):   0%| | 125/262387 [00:05<1:46:25, 41.07it/s, Loss: 19.355 (32.7\u001b[A\n",
      "Train(0):   0%| | 125/262387 [00:05<1:46:25, 41.07it/s, Loss: 19.597 (32.6\u001b[A\n",
      "Train(0):   0%| | 126/262387 [00:05<1:46:25, 41.07it/s, Loss: 24.689 (32.5\u001b[A\n",
      "Train(0):   0%| | 127/262387 [00:05<1:46:25, 41.07it/s, Loss: 21.413 (32.4\u001b[A\n",
      "Train(0):   0%| | 128/262387 [00:05<1:46:25, 41.07it/s, Loss: 25.425 (32.4\u001b[A\n",
      "Train(0):   0%| | 129/262387 [00:05<1:46:25, 41.07it/s, Loss: 13.901 (32.2\u001b[A\n",
      "Train(0):   0%| | 130/262387 [00:05<1:46:16, 41.13it/s, Loss: 13.901 (32.2\u001b[A\n",
      "Train(0):   0%| | 130/262387 [00:05<1:46:16, 41.13it/s, Loss: 24.625 (32.2\u001b[A\n",
      "Train(0):   0%| | 131/262387 [00:05<1:46:16, 41.13it/s, Loss: 24.770 (32.1\u001b[A\n",
      "Train(0):   0%| | 132/262387 [00:05<1:46:16, 41.13it/s, Loss: 18.433 (32.0\u001b[A\n",
      "Train(0):   0%| | 133/262387 [00:05<1:46:16, 41.13it/s, Loss: 18.381 (31.9\u001b[A\n",
      "Train(0):   0%| | 134/262387 [00:05<1:46:16, 41.13it/s, Loss: 26.892 (31.9\u001b[A\n",
      "Train(0):   0%| | 135/262387 [00:05<1:46:10, 41.17it/s, Loss: 26.892 (31.9\u001b[A\n",
      "Train(0):   0%| | 135/262387 [00:05<1:46:10, 41.17it/s, Loss: 17.635 (31.8\u001b[A\n",
      "Train(0):   0%| | 136/262387 [00:05<1:46:10, 41.17it/s, Loss: 17.066 (31.7\u001b[A\n",
      "Train(0):   0%| | 137/262387 [00:05<1:46:09, 41.17it/s, Loss: 18.493 (31.6\u001b[A\n",
      "Train(0):   0%| | 138/262387 [00:05<1:46:09, 41.17it/s, Loss: 24.087 (31.5\u001b[A\n",
      "Train(0):   0%| | 139/262387 [00:05<1:46:09, 41.17it/s, Loss: 19.684 (31.4\u001b[A\n",
      "Train(0):   0%| | 140/262387 [00:05<1:46:16, 41.13it/s, Loss: 19.684 (31.4\u001b[A\n",
      "Train(0):   0%| | 140/262387 [00:05<1:46:16, 41.13it/s, Loss: 19.771 (31.3\u001b[A\n",
      "Train(0):   0%| | 141/262387 [00:05<1:46:15, 41.13it/s, Loss: 24.896 (31.3\u001b[A\n",
      "Train(0):   0%| | 142/262387 [00:05<1:46:15, 41.13it/s, Loss: 30.032 (31.3\u001b[A\n",
      "Train(0):   0%| | 143/262387 [00:05<1:46:15, 41.13it/s, Loss: 16.082 (31.2\u001b[A\n",
      "Train(0):   0%| | 144/262387 [00:05<1:46:15, 41.13it/s, Loss: 21.887 (31.1\u001b[A\n",
      "Train(0):   0%| | 145/262387 [00:05<1:46:27, 41.06it/s, Loss: 21.887 (31.1\u001b[A\n",
      "Train(0):   0%| | 145/262387 [00:05<1:46:27, 41.06it/s, Loss: 19.306 (31.0\u001b[A\n",
      "Train(0):   0%| | 146/262387 [00:05<1:46:27, 41.06it/s, Loss: 18.708 (30.9\u001b[A\n",
      "Train(0):   0%| | 147/262387 [00:05<1:46:27, 41.06it/s, Loss: 24.534 (30.9\u001b[A\n",
      "Train(0):   0%| | 148/262387 [00:05<1:46:27, 41.06it/s, Loss: 24.330 (30.9\u001b[A\n",
      "Train(0):   0%| | 149/262387 [00:05<1:46:27, 41.06it/s, Loss: 23.723 (30.8\u001b[A\n",
      "Train(0):   0%| | 150/262387 [00:05<1:46:39, 40.98it/s, Loss: 23.723 (30.8\u001b[A\n",
      "Train(0):   0%| | 150/262387 [00:05<1:46:39, 40.98it/s, Loss: 16.173 (30.7\u001b[A\n",
      "Train(0):   0%| | 151/262387 [00:05<1:46:39, 40.98it/s, Loss: 19.756 (30.6\u001b[A\n",
      "Train(0):   0%| | 152/262387 [00:06<1:46:39, 40.98it/s, Loss: 19.945 (30.6\u001b[A\n",
      "Train(0):   0%| | 153/262387 [00:06<1:46:39, 40.98it/s, Loss: 16.682 (30.5\u001b[A\n",
      "Train(0):   0%| | 154/262387 [00:06<1:46:39, 40.98it/s, Loss: 17.514 (30.4\u001b[A\n",
      "Train(0):   0%| | 155/262387 [00:06<1:55:28, 37.85it/s, Loss: 17.514 (30.4\u001b[A\n",
      "Train(0):   0%| | 155/262387 [00:06<1:55:28, 37.85it/s, Loss: 21.463 (30.3\u001b[A\n",
      "Train(0):   0%| | 156/262387 [00:06<1:55:28, 37.85it/s, Loss: 17.784 (30.2\u001b[A\n",
      "Train(0):   0%| | 157/262387 [00:06<1:55:28, 37.85it/s, Loss: 20.403 (30.2\u001b[A\n",
      "Train(0):   0%| | 158/262387 [00:06<1:55:28, 37.85it/s, Loss: 22.206 (30.1\u001b[A\n",
      "Train(0):   0%| | 159/262387 [00:06<1:54:21, 38.22it/s, Loss: 22.206 (30.1\u001b[A\n",
      "Train(0):   0%| | 159/262387 [00:06<1:54:21, 38.22it/s, Loss: 29.875 (30.1\u001b[A\n",
      "Train(0):   0%| | 160/262387 [00:06<1:54:21, 38.22it/s, Loss: 13.944 (30.0\u001b[A\n",
      "Train(0):   0%| | 161/262387 [00:06<1:54:21, 38.22it/s, Loss: 13.150 (29.9\u001b[A\n",
      "Train(0):   0%| | 162/262387 [00:06<1:54:21, 38.22it/s, Loss: 17.408 (29.8\u001b[A\n",
      "Train(0):   0%| | 163/262387 [00:06<1:59:43, 36.50it/s, Loss: 17.408 (29.8\u001b[A\n",
      "Train(0):   0%| | 163/262387 [00:06<1:59:43, 36.50it/s, Loss: 22.218 (29.8\u001b[A\n",
      "Train(0):   0%| | 164/262387 [00:06<1:59:43, 36.50it/s, Loss: 19.883 (29.7\u001b[A\n",
      "Train(0):   0%| | 165/262387 [00:06<1:59:43, 36.50it/s, Loss: 16.836 (29.7\u001b[A\n",
      "Train(0):   0%| | 166/262387 [00:06<1:59:43, 36.50it/s, Loss: 18.737 (29.6\u001b[A\n",
      "Train(0):   0%| | 167/262387 [00:06<1:59:43, 36.50it/s, Loss: 16.379 (29.5\u001b[A\n",
      "Train(0):   0%| | 168/262387 [00:06<1:55:57, 37.69it/s, Loss: 16.379 (29.5\u001b[A\n",
      "Train(0):   0%| | 168/262387 [00:06<1:55:57, 37.69it/s, Loss: 25.853 (29.5\u001b[A\n",
      "Train(0):   0%| | 169/262387 [00:06<1:55:56, 37.69it/s, Loss: 20.095 (29.4\u001b[A\n",
      "Train(0):   0%| | 170/262387 [00:06<1:55:56, 37.69it/s, Loss: 17.745 (29.4\u001b[A\n",
      "Train(0):   0%| | 171/262387 [00:06<1:55:56, 37.69it/s, Loss: 24.112 (29.3\u001b[A\n",
      "Train(0):   0%| | 172/262387 [00:06<2:01:18, 36.03it/s, Loss: 24.112 (29.3\u001b[A\n",
      "Train(0):   0%| | 172/262387 [00:06<2:01:18, 36.03it/s, Loss: 18.509 (29.3\u001b[A\n",
      "Train(0):   0%| | 173/262387 [00:06<2:01:18, 36.03it/s, Loss: 26.387 (29.3\u001b[A\n",
      "Train(0):   0%| | 174/262387 [00:06<2:01:18, 36.03it/s, Loss: 10.742 (29.2\u001b[A\n",
      "Train(0):   0%| | 175/262387 [00:06<2:01:18, 36.03it/s, Loss: 14.257 (29.1\u001b[A\n",
      "Train(0):   0%| | 176/262387 [00:06<2:04:21, 35.14it/s, Loss: 14.257 (29.1\u001b[A\n",
      "Train(0):   0%| | 176/262387 [00:06<2:04:21, 35.14it/s, Loss: 26.516 (29.1\u001b[A\n",
      "Train(0):   0%| | 177/262387 [00:06<2:04:21, 35.14it/s, Loss: 10.771 (28.9\u001b[A\n",
      "Train(0):   0%| | 178/262387 [00:06<2:04:21, 35.14it/s, Loss: 20.886 (28.9\u001b[A\n",
      "Train(0):   0%| | 179/262387 [00:06<2:04:21, 35.14it/s, Loss: 22.187 (28.9\u001b[A\n",
      "Train(0):   0%| | 180/262387 [00:06<2:07:31, 34.27it/s, Loss: 22.187 (28.9\u001b[A\n",
      "Train(0):   0%| | 180/262387 [00:06<2:07:31, 34.27it/s, Loss: 22.540 (28.8\u001b[A\n",
      "Train(0):   0%| | 181/262387 [00:06<2:07:31, 34.27it/s, Loss: 22.861 (28.8\u001b[A\n",
      "Train(0):   0%| | 182/262387 [00:06<2:07:31, 34.27it/s, Loss: 24.257 (28.8\u001b[A\n",
      "Train(0):   0%| | 183/262387 [00:06<2:07:31, 34.27it/s, Loss: 10.330 (28.7\u001b[A\n",
      "Train(0):   0%| | 184/262387 [00:06<2:07:31, 34.27it/s, Loss: 15.883 (28.6\u001b[A\n",
      "Train(0):   0%| | 185/262387 [00:06<1:55:23, 37.87it/s, Loss: 15.883 (28.6\u001b[A\n",
      "Train(0):   0%| | 185/262387 [00:06<1:55:23, 37.87it/s, Loss: 14.802 (28.5\u001b[A\n",
      "Train(0):   0%| | 186/262387 [00:06<1:55:23, 37.87it/s, Loss: 17.844 (28.5\u001b[A\n",
      "Train(0):   0%| | 187/262387 [00:06<1:55:23, 37.87it/s, Loss: 16.212 (28.4\u001b[A\n",
      "Train(0):   0%| | 188/262387 [00:06<1:55:23, 37.87it/s, Loss: 16.540 (28.3\u001b[A\n",
      "Train(0):   0%| | 189/262387 [00:07<1:55:23, 37.87it/s, Loss: 15.339 (28.3\u001b[A\n",
      "Train(0):   0%| | 190/262387 [00:07<1:53:11, 38.61it/s, Loss: 15.339 (28.3\u001b[A\n",
      "Train(0):   0%| | 190/262387 [00:07<1:53:11, 38.61it/s, Loss: 13.095 (28.2\u001b[A\n",
      "Train(0):   0%| | 191/262387 [00:07<1:53:10, 38.61it/s, Loss: 22.635 (28.2\u001b[A\n",
      "Train(0):   0%| | 192/262387 [00:07<1:53:10, 38.61it/s, Loss: 17.235 (28.1\u001b[A\n",
      "Train(0):   0%| | 193/262387 [00:07<1:53:10, 38.61it/s, Loss: 10.200 (28.0\u001b[A\n",
      "Train(0):   0%| | 194/262387 [00:07<2:02:01, 35.81it/s, Loss: 10.200 (28.0\u001b[A\n",
      "Train(0):   0%| | 194/262387 [00:07<2:02:01, 35.81it/s, Loss: 16.410 (28.0\u001b[A\n",
      "Train(0):   0%| | 195/262387 [00:07<2:02:01, 35.81it/s, Loss: 15.254 (27.9\u001b[A\n",
      "Train(0):   0%| | 196/262387 [00:07<2:02:01, 35.81it/s, Loss: 11.322 (27.8\u001b[A\n",
      "Train(0):   0%| | 197/262387 [00:07<2:02:01, 35.81it/s, Loss: 21.610 (27.8\u001b[A\n",
      "Train(0):   0%| | 198/262387 [00:07<1:59:45, 36.49it/s, Loss: 21.610 (27.8\u001b[A\n",
      "Train(0):   0%| | 198/262387 [00:07<1:59:45, 36.49it/s, Loss: 20.264 (27.7\u001b[A\n",
      "Train(0):   0%| | 199/262387 [00:07<1:59:45, 36.49it/s, Loss: 21.358 (27.7\u001b[A\n",
      "Train(0):   0%| | 200/262387 [00:07<1:59:45, 36.49it/s, Loss: 16.294 (27.6\u001b[A\n",
      "Train(0):   0%| | 201/262387 [00:07<1:59:45, 36.49it/s, Loss: 17.089 (27.6\u001b[A\n",
      "Train(0):   0%| | 202/262387 [00:07<2:08:47, 33.93it/s, Loss: 17.089 (27.6\u001b[A\n",
      "Train(0):   0%| | 202/262387 [00:07<2:08:47, 33.93it/s, Loss: 16.474 (27.5\u001b[A\n",
      "Train(0):   0%| | 203/262387 [00:07<2:08:47, 33.93it/s, Loss: 16.291 (27.5\u001b[A\n",
      "Train(0):   0%| | 204/262387 [00:07<2:08:47, 33.93it/s, Loss: 10.292 (27.4\u001b[A\n",
      "Train(0):   0%| | 205/262387 [00:07<2:08:47, 33.93it/s, Loss: 15.151 (27.3\u001b[A\n",
      "Train(0):   0%| | 206/262387 [00:07<2:04:34, 35.08it/s, Loss: 15.151 (27.3\u001b[A\n",
      "Train(0):   0%| | 206/262387 [00:07<2:04:34, 35.08it/s, Loss: 16.077 (27.3\u001b[A\n",
      "Train(0):   0%| | 207/262387 [00:07<2:04:34, 35.08it/s, Loss: 18.998 (27.2\u001b[A\n",
      "Train(0):   0%| | 208/262387 [00:07<2:04:34, 35.08it/s, Loss: 19.935 (27.2\u001b[A\n",
      "Train(0):   0%| | 209/262387 [00:07<2:04:34, 35.08it/s, Loss: 21.227 (27.2\u001b[A\n",
      "Train(0):   0%| | 210/262387 [00:07<2:09:36, 33.71it/s, Loss: 21.227 (27.2\u001b[A\n",
      "Train(0):   0%| | 210/262387 [00:07<2:09:36, 33.71it/s, Loss: 9.307 (27.13\u001b[A\n",
      "Train(0):   0%| | 211/262387 [00:07<2:09:36, 33.71it/s, Loss: 22.111 (27.1\u001b[A\n",
      "Train(0):   0%| | 212/262387 [00:07<2:09:36, 33.71it/s, Loss: 15.899 (27.0\u001b[A\n",
      "Train(0):   0%| | 213/262387 [00:07<2:09:36, 33.71it/s, Loss: 27.578 (27.0\u001b[A\n",
      "Train(0):   0%| | 214/262387 [00:07<2:05:00, 34.95it/s, Loss: 27.578 (27.0\u001b[A\n",
      "Train(0):   0%| | 214/262387 [00:07<2:05:00, 34.95it/s, Loss: 10.113 (26.9\u001b[A\n",
      "Train(0):   0%| | 215/262387 [00:07<2:05:00, 34.95it/s, Loss: 19.933 (26.9\u001b[A\n",
      "Train(0):   0%| | 216/262387 [00:07<2:05:00, 34.95it/s, Loss: 14.918 (26.8\u001b[A\n",
      "Train(0):   0%| | 217/262387 [00:07<2:05:00, 34.95it/s, Loss: 16.871 (26.8\u001b[A\n",
      "Train(0):   0%| | 218/262387 [00:07<2:07:42, 34.21it/s, Loss: 16.871 (26.8\u001b[A\n",
      "Train(0):   0%| | 218/262387 [00:07<2:07:42, 34.21it/s, Loss: 12.642 (26.7\u001b[A\n",
      "Train(0):   0%| | 219/262387 [00:07<2:07:42, 34.21it/s, Loss: 23.088 (26.7\u001b[A\n",
      "Train(0):   0%| | 220/262387 [00:07<2:07:42, 34.21it/s, Loss: 10.825 (26.6\u001b[A\n",
      "Train(0):   0%| | 221/262387 [00:07<2:07:42, 34.21it/s, Loss: 24.503 (26.6\u001b[A\n",
      "Train(0):   0%| | 222/262387 [00:07<2:07:42, 34.21it/s, Loss: 21.975 (26.6\u001b[A\n",
      "Train(0):   0%| | 223/262387 [00:07<1:59:28, 36.57it/s, Loss: 21.975 (26.6\u001b[A\n",
      "Train(0):   0%| | 223/262387 [00:07<1:59:28, 36.57it/s, Loss: 18.149 (26.6\u001b[A\n",
      "Train(0):   0%| | 224/262387 [00:08<1:59:28, 36.57it/s, Loss: 17.092 (26.5\u001b[A\n",
      "Train(0):   0%| | 225/262387 [00:08<1:59:28, 36.57it/s, Loss: 15.002 (26.5\u001b[A\n",
      "Train(0):   0%| | 226/262387 [00:08<1:59:28, 36.57it/s, Loss: 14.903 (26.4\u001b[A\n",
      "Train(0):   0%| | 227/262387 [00:08<1:56:53, 37.38it/s, Loss: 14.903 (26.4\u001b[A\n",
      "Train(0):   0%| | 227/262387 [00:08<1:56:53, 37.38it/s, Loss: 15.195 (26.4\u001b[A\n",
      "Train(0):   0%| | 228/262387 [00:08<1:56:53, 37.38it/s, Loss: 21.142 (26.4\u001b[A\n",
      "Train(0):   0%| | 229/262387 [00:08<1:56:53, 37.38it/s, Loss: 25.877 (26.4\u001b[A\n",
      "Train(0):   0%| | 230/262387 [00:08<1:56:53, 37.38it/s, Loss: 21.231 (26.3\u001b[A\n",
      "Train(0):   0%| | 231/262387 [00:08<1:56:53, 37.38it/s, Loss: 20.129 (26.3\u001b[A\n",
      "Train(0):   0%| | 232/262387 [00:08<1:48:12, 40.38it/s, Loss: 20.129 (26.3\u001b[A\n",
      "Train(0):   0%| | 232/262387 [00:08<1:48:12, 40.38it/s, Loss: 20.142 (26.3\u001b[A\n",
      "Train(0):   0%| | 233/262387 [00:08<1:48:12, 40.38it/s, Loss: 16.921 (26.2\u001b[A\n",
      "Train(0):   0%| | 234/262387 [00:08<1:48:12, 40.38it/s, Loss: 22.251 (26.2\u001b[A\n",
      "Train(0):   0%| | 235/262387 [00:08<1:48:12, 40.38it/s, Loss: 17.591 (26.2\u001b[A\n",
      "Train(0):   0%| | 236/262387 [00:08<1:48:12, 40.38it/s, Loss: 27.318 (26.2\u001b[A\n",
      "Train(0):   0%| | 237/262387 [00:08<1:46:40, 40.96it/s, Loss: 27.318 (26.2\u001b[A\n",
      "Train(0):   0%| | 237/262387 [00:08<1:46:40, 40.96it/s, Loss: 22.237 (26.2\u001b[A\n",
      "Train(0):   0%| | 238/262387 [00:08<1:46:40, 40.96it/s, Loss: 20.846 (26.1\u001b[A\n",
      "Train(0):   0%| | 239/262387 [00:08<1:46:40, 40.96it/s, Loss: 21.581 (26.1\u001b[A\n",
      "Train(0):   0%| | 240/262387 [00:08<1:46:40, 40.96it/s, Loss: 23.697 (26.1\u001b[A\n",
      "Train(0):   0%| | 241/262387 [00:08<1:46:40, 40.96it/s, Loss: 19.910 (26.1\u001b[A\n",
      "Train(0):   0%| | 242/262387 [00:08<1:47:33, 40.62it/s, Loss: 19.910 (26.1\u001b[A\n",
      "Train(0):   0%| | 242/262387 [00:08<1:47:33, 40.62it/s, Loss: 11.402 (26.0\u001b[A\n",
      "Train(0):   0%| | 243/262387 [00:08<1:47:33, 40.62it/s, Loss: 26.836 (26.0\u001b[A\n",
      "Train(0):   0%| | 244/262387 [00:08<1:47:33, 40.62it/s, Loss: 27.539 (26.0\u001b[A\n",
      "Train(0):   0%| | 245/262387 [00:08<1:47:33, 40.62it/s, Loss: 25.442 (26.0\u001b[A\n",
      "Train(0):   0%| | 246/262387 [00:08<1:47:33, 40.62it/s, Loss: 11.450 (26.0\u001b[A\n",
      "Train(0):   0%| | 247/262387 [00:08<1:53:59, 38.33it/s, Loss: 11.450 (26.0\u001b[A\n",
      "Train(0):   0%| | 247/262387 [00:08<1:53:59, 38.33it/s, Loss: 11.217 (25.9\u001b[A\n",
      "Train(0):   0%| | 248/262387 [00:08<1:53:59, 38.33it/s, Loss: 13.478 (25.9\u001b[A\n",
      "Train(0):   0%| | 249/262387 [00:08<1:53:59, 38.33it/s, Loss: 25.681 (25.9\u001b[A\n",
      "Train(0):   0%| | 250/262387 [00:08<1:53:59, 38.33it/s, Loss: 18.132 (25.8\u001b[A\n",
      "Train(0):   0%| | 251/262387 [00:08<1:55:19, 37.88it/s, Loss: 18.132 (25.8\u001b[A\n",
      "Train(0):   0%| | 251/262387 [00:08<1:55:19, 37.88it/s, Loss: 15.778 (25.8\u001b[A\n",
      "Train(0):   0%| | 252/262387 [00:08<1:55:19, 37.88it/s, Loss: 17.202 (25.8\u001b[A\n",
      "Train(0):   0%| | 253/262387 [00:08<1:55:19, 37.88it/s, Loss: 19.195 (25.7\u001b[A\n",
      "Train(0):   0%| | 254/262387 [00:08<1:55:19, 37.88it/s, Loss: 15.489 (25.7\u001b[A\n",
      "Train(0):   0%| | 255/262387 [00:08<1:56:10, 37.60it/s, Loss: 15.489 (25.7\u001b[A\n",
      "Train(0):   0%| | 255/262387 [00:08<1:56:10, 37.60it/s, Loss: 12.221 (25.6\u001b[A\n",
      "Train(0):   0%| | 256/262387 [00:08<1:56:10, 37.60it/s, Loss: 10.882 (25.6\u001b[A\n",
      "Train(0):   0%| | 257/262387 [00:08<1:56:10, 37.60it/s, Loss: 17.437 (25.6\u001b[A\n",
      "Train(0):   0%| | 258/262387 [00:08<1:56:10, 37.60it/s, Loss: 18.198 (25.5\u001b[A\n",
      "Train(0):   0%| | 259/262387 [00:08<1:56:10, 37.60it/s, Loss: 9.468 (25.51\u001b[A\n",
      "Train(0):   0%| | 260/262387 [00:08<1:53:59, 38.33it/s, Loss: 9.468 (25.51\u001b[A\n",
      "Train(0):   0%| | 260/262387 [00:08<1:53:59, 38.33it/s, Loss: 20.904 (25.4\u001b[A\n",
      "Train(0):   0%| | 261/262387 [00:08<1:53:59, 38.33it/s, Loss: 15.906 (25.4\u001b[A\n",
      "Train(0):   0%| | 262/262387 [00:08<1:53:59, 38.33it/s, Loss: 15.247 (25.4\u001b[A\n",
      "Train(0):   0%| | 263/262387 [00:09<1:53:59, 38.33it/s, Loss: 26.626 (25.4\u001b[A\n",
      "Train(0):   0%| | 264/262387 [00:09<1:53:59, 38.33it/s, Loss: 20.070 (25.4\u001b[A\n",
      "Train(0):   0%| | 265/262387 [00:09<1:49:12, 40.00it/s, Loss: 20.070 (25.4\u001b[A\n",
      "Train(0):   0%| | 265/262387 [00:09<1:49:12, 40.00it/s, Loss: 20.716 (25.3\u001b[A\n",
      "Train(0):   0%| | 266/262387 [00:09<1:49:12, 40.00it/s, Loss: 13.209 (25.3\u001b[A\n",
      "Train(0):   0%| | 267/262387 [00:09<1:49:12, 40.00it/s, Loss: 15.021 (25.3\u001b[A\n",
      "Train(0):   0%| | 268/262387 [00:09<1:49:12, 40.00it/s, Loss: 7.863 (25.23\u001b[A\n",
      "Train(0):   0%| | 269/262387 [00:09<1:49:12, 40.00it/s, Loss: 10.880 (25.1\u001b[A\n",
      "Train(0):   0%| | 270/262387 [00:09<1:47:21, 40.69it/s, Loss: 10.880 (25.1\u001b[A\n",
      "Train(0):   0%| | 270/262387 [00:09<1:47:21, 40.69it/s, Loss: 14.207 (25.1\u001b[A\n",
      "Train(0):   0%| | 271/262387 [00:09<1:47:21, 40.69it/s, Loss: 8.728 (25.08\u001b[A\n",
      "Train(0):   0%| | 272/262387 [00:09<1:47:21, 40.69it/s, Loss: 17.171 (25.0\u001b[A\n",
      "Train(0):   0%| | 273/262387 [00:09<1:47:20, 40.69it/s, Loss: 10.614 (24.9\u001b[A\n",
      "Train(0):   0%| | 274/262387 [00:09<1:47:20, 40.69it/s, Loss: 20.186 (24.9\u001b[A\n",
      "Train(0):   0%| | 275/262387 [00:09<1:58:18, 36.93it/s, Loss: 20.186 (24.9\u001b[A\n",
      "Train(0):   0%| | 275/262387 [00:09<1:58:18, 36.93it/s, Loss: 22.043 (24.9\u001b[A\n",
      "Train(0):   0%| | 276/262387 [00:09<1:58:18, 36.93it/s, Loss: 13.758 (24.9\u001b[A\n",
      "Train(0):   0%| | 277/262387 [00:09<1:58:18, 36.93it/s, Loss: 25.066 (24.9\u001b[A\n",
      "Train(0):   0%| | 278/262387 [00:09<1:58:18, 36.93it/s, Loss: 20.250 (24.9\u001b[A\n",
      "Train(0):   0%| | 279/262387 [00:09<1:58:17, 36.93it/s, Loss: 12.184 (24.8\u001b[A\n",
      "Train(0):   0%| | 280/262387 [00:09<1:51:53, 39.04it/s, Loss: 12.184 (24.8\u001b[A\n",
      "Train(0):   0%| | 280/262387 [00:09<1:51:53, 39.04it/s, Loss: 18.645 (24.8\u001b[A\n",
      "Train(0):   0%| | 281/262387 [00:09<1:51:53, 39.04it/s, Loss: 13.647 (24.8\u001b[A\n",
      "Train(0):   0%| | 282/262387 [00:09<1:51:53, 39.04it/s, Loss: 22.475 (24.7\u001b[A\n",
      "Train(0):   0%| | 283/262387 [00:09<1:51:53, 39.04it/s, Loss: 8.853 (24.74\u001b[A\n",
      "Train(0):   0%| | 284/262387 [00:09<1:52:18, 38.90it/s, Loss: 8.853 (24.74\u001b[A\n",
      "Train(0):   0%| | 284/262387 [00:09<1:52:18, 38.90it/s, Loss: 9.010 (24.68\u001b[A\n",
      "Train(0):   0%| | 285/262387 [00:09<1:52:18, 38.90it/s, Loss: 26.863 (24.6\u001b[A\n",
      "Train(0):   0%| | 286/262387 [00:09<1:52:18, 38.90it/s, Loss: 14.243 (24.6\u001b[A\n",
      "Train(0):   0%| | 287/262387 [00:09<1:52:18, 38.90it/s, Loss: 18.659 (24.6\u001b[A\n",
      "Train(0):   0%| | 288/262387 [00:09<1:52:18, 38.90it/s, Loss: 15.842 (24.6\u001b[A\n",
      "Train(0):   0%| | 289/262387 [00:09<1:52:18, 38.90it/s, Loss: 16.407 (24.5\u001b[A\n",
      "Train(0):   0%| | 290/262387 [00:09<1:39:04, 44.09it/s, Loss: 16.407 (24.5\u001b[A\n",
      "Train(0):   0%| | 290/262387 [00:09<1:39:04, 44.09it/s, Loss: 26.889 (24.5\u001b[A\n",
      "Train(0):   0%| | 291/262387 [00:09<1:39:04, 44.09it/s, Loss: 15.307 (24.5\u001b[A\n",
      "Train(0):   0%| | 292/262387 [00:09<1:39:04, 44.09it/s, Loss: 15.999 (24.5\u001b[A\n",
      "Train(0):   0%| | 293/262387 [00:09<1:39:04, 44.09it/s, Loss: 17.250 (24.4\u001b[A\n",
      "Train(0):   0%| | 294/262387 [00:09<1:39:04, 44.09it/s, Loss: 22.335 (24.4\u001b[A\n",
      "Train(0):   0%| | 295/262387 [00:09<1:43:13, 42.31it/s, Loss: 22.335 (24.4\u001b[A\n",
      "Train(0):   0%| | 295/262387 [00:09<1:43:13, 42.31it/s, Loss: 20.293 (24.4\u001b[A\n",
      "Train(0):   0%| | 296/262387 [00:09<1:43:13, 42.31it/s, Loss: 18.403 (24.4\u001b[A\n",
      "Train(0):   0%| | 297/262387 [00:09<1:43:13, 42.31it/s, Loss: 17.404 (24.4\u001b[A\n",
      "Train(0):   0%| | 298/262387 [00:09<1:43:13, 42.31it/s, Loss: 24.607 (24.4\u001b[A\n",
      "Train(0):   0%| | 299/262387 [00:09<1:43:13, 42.31it/s, Loss: 19.785 (24.4\u001b[A\n",
      "Train(0):   0%| | 300/262387 [00:09<1:47:07, 40.78it/s, Loss: 19.785 (24.4\u001b[A\n",
      "Train(0):   0%| | 300/262387 [00:09<1:47:07, 40.78it/s, Loss: 16.407 (24.3\u001b[A\n",
      "Train(0):   0%| | 301/262387 [00:09<1:47:06, 40.78it/s, Loss: 12.780 (24.3\u001b[A\n",
      "Train(0):   0%| | 302/262387 [00:09<1:47:06, 40.78it/s, Loss: 22.383 (24.3\u001b[A\n",
      "Train(0):   0%| | 303/262387 [00:09<1:47:06, 40.78it/s, Loss: 19.584 (24.3\u001b[A\n",
      "Train(0):   0%| | 304/262387 [00:09<1:47:06, 40.78it/s, Loss: 15.470 (24.3\u001b[A\n",
      "Train(0):   0%| | 305/262387 [00:09<1:47:06, 40.78it/s, Loss: 20.592 (24.2\u001b[A\n",
      "Train(0):   0%| | 306/262387 [00:10<1:38:51, 44.18it/s, Loss: 20.592 (24.2\u001b[A\n",
      "Train(0):   0%| | 306/262387 [00:10<1:38:51, 44.18it/s, Loss: 12.589 (24.2\u001b[A\n",
      "Train(0):   0%| | 307/262387 [00:10<1:38:51, 44.18it/s, Loss: 9.960 (24.20\u001b[A\n",
      "Train(0):   0%| | 308/262387 [00:10<1:38:51, 44.18it/s, Loss: 18.423 (24.1\u001b[A\n",
      "Train(0):   0%| | 309/262387 [00:10<1:38:51, 44.18it/s, Loss: 11.326 (24.1\u001b[A\n",
      "Train(0):   0%| | 310/262387 [00:10<1:38:51, 44.18it/s, Loss: 13.683 (24.1\u001b[A\n",
      "Train(0):   0%| | 311/262387 [00:10<1:43:55, 42.03it/s, Loss: 13.683 (24.1\u001b[A\n",
      "Train(0):   0%| | 311/262387 [00:10<1:43:55, 42.03it/s, Loss: 14.701 (24.0\u001b[A\n",
      "Train(0):   0%| | 312/262387 [00:10<1:43:55, 42.03it/s, Loss: 14.736 (24.0\u001b[A\n",
      "Train(0):   0%| | 313/262387 [00:10<1:43:55, 42.03it/s, Loss: 17.463 (24.0\u001b[A\n",
      "Train(0):   0%| | 314/262387 [00:10<1:43:55, 42.03it/s, Loss: 20.607 (24.0\u001b[A\n",
      "Train(0):   0%| | 315/262387 [00:10<1:43:55, 42.03it/s, Loss: 14.464 (23.9\u001b[A\n",
      "Train(0):   0%| | 316/262387 [00:10<1:41:56, 42.84it/s, Loss: 14.464 (23.9\u001b[A\n",
      "Train(0):   0%| | 316/262387 [00:10<1:41:56, 42.84it/s, Loss: 12.188 (23.9\u001b[A\n",
      "Train(0):   0%| | 317/262387 [00:10<1:41:56, 42.84it/s, Loss: 11.034 (23.9\u001b[A\n",
      "Train(0):   0%| | 318/262387 [00:10<1:41:56, 42.84it/s, Loss: 14.830 (23.8\u001b[A\n",
      "Train(0):   0%| | 319/262387 [00:10<1:41:56, 42.84it/s, Loss: 15.840 (23.8\u001b[A\n",
      "Train(0):   0%| | 320/262387 [00:10<1:41:56, 42.84it/s, Loss: 21.061 (23.8\u001b[A\n",
      "Train(0):   0%| | 321/262387 [00:10<1:45:16, 41.49it/s, Loss: 21.061 (23.8\u001b[A\n",
      "Train(0):   0%| | 321/262387 [00:10<1:45:16, 41.49it/s, Loss: 13.159 (23.8\u001b[A\n",
      "Train(0):   0%| | 322/262387 [00:10<1:45:16, 41.49it/s, Loss: 14.301 (23.7\u001b[A\n",
      "Train(0):   0%| | 323/262387 [00:10<1:45:16, 41.49it/s, Loss: 20.494 (23.7\u001b[A\n",
      "Train(0):   0%| | 324/262387 [00:10<1:45:16, 41.49it/s, Loss: 20.202 (23.7\u001b[A\n",
      "Train(0):   0%| | 325/262387 [00:10<1:45:16, 41.49it/s, Loss: 25.628 (23.7\u001b[A\n",
      "Train(0):   0%| | 326/262387 [00:10<1:51:09, 39.29it/s, Loss: 25.628 (23.7\u001b[A\n",
      "Train(0):   0%| | 326/262387 [00:10<1:51:09, 39.29it/s, Loss: 14.821 (23.7\u001b[A\n",
      "Train(0):   0%| | 327/262387 [00:10<1:51:09, 39.29it/s, Loss: 26.140 (23.7\u001b[A\n",
      "Train(0):   0%| | 328/262387 [00:10<1:51:09, 39.29it/s, Loss: 16.476 (23.7\u001b[A\n",
      "Train(0):   0%| | 329/262387 [00:10<1:51:09, 39.29it/s, Loss: 13.491 (23.6\u001b[A\n",
      "Train(0):   0%| | 330/262387 [00:10<1:51:09, 39.29it/s, Loss: 20.034 (23.6\u001b[A\n",
      "Train(0):   0%| | 331/262387 [00:10<1:47:15, 40.72it/s, Loss: 20.034 (23.6\u001b[A\n",
      "Train(0):   0%| | 331/262387 [00:10<1:47:15, 40.72it/s, Loss: 20.129 (23.6\u001b[A\n",
      "Train(0):   0%| | 332/262387 [00:10<1:47:15, 40.72it/s, Loss: 26.530 (23.6\u001b[A\n",
      "Train(0):   0%| | 333/262387 [00:10<1:47:15, 40.72it/s, Loss: 11.528 (23.6\u001b[A\n",
      "Train(0):   0%| | 334/262387 [00:10<1:47:15, 40.72it/s, Loss: 9.789 (23.60\u001b[A\n",
      "Train(0):   0%| | 335/262387 [00:10<1:47:15, 40.72it/s, Loss: 10.404 (23.5\u001b[A\n",
      "Train(0):   0%| | 336/262387 [00:10<1:52:36, 38.78it/s, Loss: 10.404 (23.5\u001b[A\n",
      "Train(0):   0%| | 336/262387 [00:10<1:52:36, 38.78it/s, Loss: 17.650 (23.5\u001b[A\n",
      "Train(0):   0%| | 337/262387 [00:10<1:52:36, 38.78it/s, Loss: 22.183 (23.5\u001b[A\n",
      "Train(0):   0%| | 338/262387 [00:10<1:52:36, 38.78it/s, Loss: 17.607 (23.5\u001b[A\n",
      "Train(0):   0%| | 339/262387 [00:10<1:52:36, 38.78it/s, Loss: 14.548 (23.5\u001b[A\n",
      "Train(0):   0%| | 340/262387 [00:10<2:04:30, 35.08it/s, Loss: 14.548 (23.5\u001b[A\n",
      "Train(0):   0%| | 340/262387 [00:10<2:04:30, 35.08it/s, Loss: 14.469 (23.4\u001b[A\n",
      "Train(0):   0%| | 341/262387 [00:10<2:04:30, 35.08it/s, Loss: 21.796 (23.4\u001b[A\n",
      "Train(0):   0%| | 342/262387 [00:11<2:04:30, 35.08it/s, Loss: 10.770 (23.4\u001b[A\n",
      "Train(0):   0%| | 343/262387 [00:11<2:04:30, 35.08it/s, Loss: 19.290 (23.4\u001b[A\n",
      "Train(0):   0%| | 344/262387 [00:11<2:08:59, 33.86it/s, Loss: 19.290 (23.4\u001b[A\n",
      "Train(0):   0%| | 344/262387 [00:11<2:08:59, 33.86it/s, Loss: 8.294 (23.37\u001b[A\n",
      "Train(0):   0%| | 345/262387 [00:11<2:08:59, 33.86it/s, Loss: 10.851 (23.3\u001b[A\n",
      "Train(0):   0%| | 346/262387 [00:11<2:08:59, 33.86it/s, Loss: 15.952 (23.3\u001b[A\n",
      "Train(0):   0%| | 347/262387 [00:11<2:08:59, 33.86it/s, Loss: 23.261 (23.3\u001b[A\n",
      "Train(0):   0%| | 348/262387 [00:11<2:06:16, 34.59it/s, Loss: 23.261 (23.3\u001b[A\n",
      "Train(0):   0%| | 348/262387 [00:11<2:06:16, 34.59it/s, Loss: 14.464 (23.2\u001b[A\n",
      "Train(0):   0%| | 349/262387 [00:11<2:06:16, 34.59it/s, Loss: 7.678 (23.24\u001b[A\n",
      "Train(0):   0%| | 350/262387 [00:11<2:06:16, 34.59it/s, Loss: 15.028 (23.2\u001b[A\n",
      "Train(0):   0%| | 351/262387 [00:11<2:06:16, 34.59it/s, Loss: 10.988 (23.1\u001b[A\n",
      "Train(0):   0%| | 352/262387 [00:11<2:06:54, 34.41it/s, Loss: 10.988 (23.1\u001b[A\n",
      "Train(0):   0%| | 352/262387 [00:11<2:06:54, 34.41it/s, Loss: 14.350 (23.1\u001b[A\n",
      "Train(0):   0%| | 353/262387 [00:11<2:06:54, 34.41it/s, Loss: 17.448 (23.1\u001b[A\n",
      "Train(0):   0%| | 354/262387 [00:11<2:06:54, 34.41it/s, Loss: 19.459 (23.1\u001b[A\n",
      "Train(0):   0%| | 355/262387 [00:11<2:06:54, 34.41it/s, Loss: 17.149 (23.1\u001b[A\n",
      "Train(0):   0%| | 356/262387 [00:11<2:07:22, 34.29it/s, Loss: 17.149 (23.1\u001b[A\n",
      "Train(0):   0%| | 356/262387 [00:11<2:07:22, 34.29it/s, Loss: 17.988 (23.1\u001b[A\n",
      "Train(0):   0%| | 357/262387 [00:11<2:07:22, 34.29it/s, Loss: 13.041 (23.0\u001b[A\n",
      "Train(0):   0%| | 358/262387 [00:11<2:07:22, 34.29it/s, Loss: 19.400 (23.0\u001b[A\n",
      "Train(0):   0%| | 359/262387 [00:11<2:07:22, 34.29it/s, Loss: 16.097 (23.0\u001b[A\n",
      "Train(0):   0%| | 360/262387 [00:11<2:07:22, 34.29it/s, Loss: 15.073 (23.0\u001b[A\n",
      "Train(0):   0%| | 361/262387 [00:11<2:06:18, 34.58it/s, Loss: 15.073 (23.0\u001b[A\n",
      "Train(0):   0%| | 361/262387 [00:11<2:06:18, 34.58it/s, Loss: 12.185 (22.9\u001b[A\n",
      "Train(0):   0%| | 362/262387 [00:11<2:06:18, 34.58it/s, Loss: 20.512 (22.9\u001b[A\n",
      "Train(0):   0%| | 363/262387 [00:11<2:06:18, 34.58it/s, Loss: 19.734 (22.9\u001b[A\n",
      "Train(0):   0%| | 364/262387 [00:11<2:06:18, 34.58it/s, Loss: 10.245 (22.9\u001b[A\n",
      "Train(0):   0%| | 365/262387 [00:11<2:06:18, 34.58it/s, Loss: 19.634 (22.9\u001b[A\n",
      "Train(0):   0%| | 366/262387 [00:11<1:59:50, 36.44it/s, Loss: 19.634 (22.9\u001b[A\n",
      "Train(0):   0%| | 366/262387 [00:11<1:59:50, 36.44it/s, Loss: 21.788 (22.9\u001b[A\n",
      "Train(0):   0%| | 367/262387 [00:11<1:59:50, 36.44it/s, Loss: 14.338 (22.9\u001b[A\n",
      "Train(0):   0%| | 368/262387 [00:11<1:59:50, 36.44it/s, Loss: 13.132 (22.8\u001b[A\n",
      "Train(0):   0%| | 369/262387 [00:11<1:59:50, 36.44it/s, Loss: 14.561 (22.8\u001b[A\n",
      "Train(0):   0%| | 370/262387 [00:11<1:59:50, 36.44it/s, Loss: 17.532 (22.8\u001b[A\n",
      "Train(0):   0%| | 371/262387 [00:11<1:55:39, 37.76it/s, Loss: 17.532 (22.8\u001b[A\n",
      "Train(0):   0%| | 371/262387 [00:11<1:55:39, 37.76it/s, Loss: 15.395 (22.8\u001b[A\n",
      "Train(0):   0%| | 372/262387 [00:11<1:55:39, 37.76it/s, Loss: 15.859 (22.8\u001b[A\n",
      "Train(0):   0%| | 373/262387 [00:11<1:55:39, 37.76it/s, Loss: 11.545 (22.7\u001b[A\n",
      "Train(0):   0%| | 374/262387 [00:11<1:55:39, 37.76it/s, Loss: 16.295 (22.7\u001b[A\n",
      "Train(0):   0%| | 375/262387 [00:11<1:55:39, 37.76it/s, Loss: 20.598 (22.7\u001b[A\n",
      "Train(0):   0%| | 376/262387 [00:11<1:52:44, 38.73it/s, Loss: 20.598 (22.7\u001b[A\n",
      "Train(0):   0%| | 376/262387 [00:11<1:52:44, 38.73it/s, Loss: 16.742 (22.7\u001b[A\n",
      "Train(0):   0%| | 377/262387 [00:11<1:52:44, 38.73it/s, Loss: 19.911 (22.7\u001b[A\n",
      "Train(0):   0%| | 378/262387 [00:11<1:52:44, 38.73it/s, Loss: 23.592 (22.7\u001b[A\n",
      "Train(0):   0%| | 379/262387 [00:11<1:52:44, 38.73it/s, Loss: 19.850 (22.7\u001b[A\n",
      "Train(0):   0%| | 380/262387 [00:12<1:57:06, 37.29it/s, Loss: 19.850 (22.7\u001b[A\n",
      "Train(0):   0%| | 380/262387 [00:12<1:57:06, 37.29it/s, Loss: 13.690 (22.7\u001b[A\n",
      "Train(0):   0%| | 381/262387 [00:12<1:57:06, 37.29it/s, Loss: 16.502 (22.6\u001b[A\n",
      "Train(0):   0%| | 382/262387 [00:12<1:57:06, 37.29it/s, Loss: 23.487 (22.6\u001b[A\n",
      "Train(0):   0%| | 383/262387 [00:12<1:57:06, 37.29it/s, Loss: 12.446 (22.6\u001b[A\n",
      "Train(0):   0%| | 384/262387 [00:12<1:57:06, 37.29it/s, Loss: 14.505 (22.6\u001b[A\n",
      "Train(0):   0%| | 385/262387 [00:12<1:53:33, 38.45it/s, Loss: 14.505 (22.6\u001b[A\n",
      "Train(0):   0%| | 385/262387 [00:12<1:53:33, 38.45it/s, Loss: 15.008 (22.6\u001b[A\n",
      "Train(0):   0%| | 386/262387 [00:12<1:53:33, 38.45it/s, Loss: 14.205 (22.5\u001b[A\n",
      "Train(0):   0%| | 387/262387 [00:12<1:53:33, 38.45it/s, Loss: 25.216 (22.6\u001b[A\n",
      "Train(0):   0%| | 388/262387 [00:12<1:53:33, 38.45it/s, Loss: 14.886 (22.5\u001b[A\n",
      "Train(0):   0%| | 389/262387 [00:12<1:53:00, 38.64it/s, Loss: 14.886 (22.5\u001b[A\n",
      "Train(0):   0%| | 389/262387 [00:12<1:53:00, 38.64it/s, Loss: 18.655 (22.5\u001b[A\n",
      "Train(0):   0%| | 390/262387 [00:12<1:53:00, 38.64it/s, Loss: 14.417 (22.5\u001b[A\n",
      "Train(0):   0%| | 391/262387 [00:12<1:53:00, 38.64it/s, Loss: 11.146 (22.5\u001b[A\n",
      "Train(0):   0%| | 392/262387 [00:12<1:53:00, 38.64it/s, Loss: 16.534 (22.5\u001b[A\n",
      "Train(0):   0%| | 393/262387 [00:12<1:58:21, 36.89it/s, Loss: 16.534 (22.5\u001b[A\n",
      "Train(0):   0%| | 393/262387 [00:12<1:58:21, 36.89it/s, Loss: 19.520 (22.5\u001b[A\n",
      "Train(0):   0%| | 394/262387 [00:12<1:58:21, 36.89it/s, Loss: 14.436 (22.4\u001b[A\n",
      "Train(0):   0%| | 395/262387 [00:12<1:58:21, 36.89it/s, Loss: 16.253 (22.4\u001b[A\n",
      "Train(0):   0%| | 396/262387 [00:12<1:58:21, 36.89it/s, Loss: 15.442 (22.4\u001b[A\n",
      "Train(0):   0%| | 397/262387 [00:12<1:57:10, 37.27it/s, Loss: 15.442 (22.4\u001b[A\n",
      "Train(0):   0%| | 397/262387 [00:12<1:57:10, 37.27it/s, Loss: 10.467 (22.4\u001b[A\n",
      "Train(0):   0%| | 398/262387 [00:12<1:57:10, 37.27it/s, Loss: 9.764 (22.38\u001b[A\n",
      "Train(0):   0%| | 399/262387 [00:12<1:57:10, 37.27it/s, Loss: 18.368 (22.3\u001b[A\n",
      "Train(0):   0%| | 400/262387 [00:12<1:57:10, 37.27it/s, Loss: 18.524 (22.3\u001b[A\n",
      "Train(0):   0%| | 401/262387 [00:12<1:56:04, 37.62it/s, Loss: 18.524 (22.3\u001b[A\n",
      "Train(0):   0%| | 401/262387 [00:12<1:56:04, 37.62it/s, Loss: 10.012 (22.3\u001b[A\n",
      "Train(0):   0%| | 402/262387 [00:12<1:56:04, 37.62it/s, Loss: 12.065 (22.3\u001b[A\n",
      "Train(0):   0%| | 403/262387 [00:12<1:56:04, 37.62it/s, Loss: 13.579 (22.2\u001b[A\n",
      "Train(0):   0%| | 404/262387 [00:12<1:56:04, 37.62it/s, Loss: 12.463 (22.2\u001b[A\n",
      "Train(0):   0%| | 405/262387 [00:12<1:55:10, 37.91it/s, Loss: 12.463 (22.2\u001b[A\n",
      "Train(0):   0%| | 405/262387 [00:12<1:55:10, 37.91it/s, Loss: 16.204 (22.2\u001b[A\n",
      "Train(0):   0%| | 406/262387 [00:12<1:55:10, 37.91it/s, Loss: 18.194 (22.2\u001b[A\n",
      "Train(0):   0%| | 407/262387 [00:12<1:55:10, 37.91it/s, Loss: 19.025 (22.2\u001b[A\n",
      "Train(0):   0%| | 408/262387 [00:12<1:55:10, 37.91it/s, Loss: 19.418 (22.2\u001b[A\n",
      "Train(0):   0%| | 409/262387 [00:12<1:54:56, 37.99it/s, Loss: 19.418 (22.2\u001b[A\n",
      "Train(0):   0%| | 409/262387 [00:12<1:54:56, 37.99it/s, Loss: 10.142 (22.1\u001b[A\n",
      "Train(0):   0%| | 410/262387 [00:12<1:54:56, 37.99it/s, Loss: 14.511 (22.1\u001b[A\n",
      "Train(0):   0%| | 411/262387 [00:12<1:54:56, 37.99it/s, Loss: 8.429 (22.14\u001b[A\n",
      "Train(0):   0%| | 412/262387 [00:12<1:54:56, 37.99it/s, Loss: 13.719 (22.1\u001b[A\n",
      "Train(0):   0%| | 413/262387 [00:12<2:01:15, 36.01it/s, Loss: 13.719 (22.1\u001b[A\n",
      "Train(0):   0%| | 413/262387 [00:12<2:01:15, 36.01it/s, Loss: 19.230 (22.1\u001b[A\n",
      "Train(0):   0%| | 414/262387 [00:12<2:01:15, 36.01it/s, Loss: 13.640 (22.0\u001b[A\n",
      "Train(0):   0%| | 415/262387 [00:12<2:01:15, 36.01it/s, Loss: 25.115 (22.1\u001b[A\n",
      "Train(0):   0%| | 416/262387 [00:13<2:01:14, 36.01it/s, Loss: 23.054 (22.1\u001b[A\n",
      "Train(0):   0%| | 417/262387 [00:13<1:59:35, 36.51it/s, Loss: 23.054 (22.1\u001b[A\n",
      "Train(0):   0%| | 417/262387 [00:13<1:59:35, 36.51it/s, Loss: 17.246 (22.0\u001b[A\n",
      "Train(0):   0%| | 418/262387 [00:13<1:59:35, 36.51it/s, Loss: 12.052 (22.0\u001b[A\n",
      "Train(0):   0%| | 419/262387 [00:13<1:59:35, 36.51it/s, Loss: 18.082 (22.0\u001b[A\n",
      "Train(0):   0%| | 420/262387 [00:13<1:59:35, 36.51it/s, Loss: 11.450 (22.0\u001b[A\n",
      "Train(0):   0%| | 421/262387 [00:13<1:56:50, 37.37it/s, Loss: 11.450 (22.0\u001b[A\n",
      "Train(0):   0%| | 421/262387 [00:13<1:56:50, 37.37it/s, Loss: 14.107 (22.0\u001b[A\n",
      "Train(0):   0%| | 422/262387 [00:13<1:56:50, 37.37it/s, Loss: 16.154 (22.0\u001b[A\n",
      "Train(0):   0%| | 423/262387 [00:13<1:56:50, 37.37it/s, Loss: 14.018 (21.9\u001b[A\n",
      "Train(0):   0%| | 424/262387 [00:13<1:56:50, 37.37it/s, Loss: 18.741 (21.9\u001b[A\n",
      "Train(0):   0%| | 425/262387 [00:13<1:56:12, 37.57it/s, Loss: 18.741 (21.9\u001b[A\n",
      "Train(0):   0%| | 425/262387 [00:13<1:56:12, 37.57it/s, Loss: 23.932 (21.9\u001b[A\n",
      "Train(0):   0%| | 426/262387 [00:13<1:56:12, 37.57it/s, Loss: 13.602 (21.9\u001b[A\n",
      "Train(0):   0%| | 427/262387 [00:13<1:56:12, 37.57it/s, Loss: 9.611 (21.93\u001b[A\n",
      "Train(0):   0%| | 428/262387 [00:13<1:56:12, 37.57it/s, Loss: 21.658 (21.9\u001b[A\n",
      "Train(0):   0%| | 429/262387 [00:13<1:58:55, 36.71it/s, Loss: 21.658 (21.9\u001b[A\n",
      "Train(0):   0%| | 429/262387 [00:13<1:58:55, 36.71it/s, Loss: 11.889 (21.9\u001b[A\n",
      "Train(0):   0%| | 430/262387 [00:13<1:58:55, 36.71it/s, Loss: 15.626 (21.8\u001b[A\n",
      "Train(0):   0%| | 431/262387 [00:13<1:58:55, 36.71it/s, Loss: 15.563 (21.8\u001b[A\n",
      "Train(0):   0%| | 432/262387 [00:13<1:58:55, 36.71it/s, Loss: 18.813 (21.8\u001b[A\n",
      "Train(0):   0%| | 433/262387 [00:13<1:58:54, 36.71it/s, Loss: 20.820 (21.8\u001b[A\n",
      "Train(0):   0%| | 434/262387 [00:13<1:58:54, 36.71it/s, Loss: 12.655 (21.8\u001b[A\n",
      "Train(0):   0%| | 435/262387 [00:13<1:46:46, 40.89it/s, Loss: 12.655 (21.8\u001b[A\n",
      "Train(0):   0%| | 435/262387 [00:13<1:46:46, 40.89it/s, Loss: 14.090 (21.8\u001b[A\n",
      "Train(0):   0%| | 436/262387 [00:13<1:46:46, 40.89it/s, Loss: 14.589 (21.8\u001b[A\n",
      "Train(0):   0%| | 437/262387 [00:13<1:46:46, 40.89it/s, Loss: 16.795 (21.8\u001b[A\n",
      "Train(0):   0%| | 438/262387 [00:13<1:46:46, 40.89it/s, Loss: 19.328 (21.7\u001b[A\n",
      "Train(0):   0%| | 439/262387 [00:13<1:46:46, 40.89it/s, Loss: 12.441 (21.7\u001b[A\n",
      "Train(0):   0%| | 440/262387 [00:13<1:48:54, 40.09it/s, Loss: 12.441 (21.7\u001b[A\n",
      "Train(0):   0%| | 440/262387 [00:13<1:48:54, 40.09it/s, Loss: 16.830 (21.7\u001b[A\n",
      "Train(0):   0%| | 441/262387 [00:13<1:48:54, 40.09it/s, Loss: 15.503 (21.7\u001b[A\n",
      "Train(0):   0%| | 442/262387 [00:13<1:48:54, 40.09it/s, Loss: 16.851 (21.7\u001b[A\n",
      "Train(0):   0%| | 443/262387 [00:13<1:48:54, 40.09it/s, Loss: 17.920 (21.7\u001b[A\n",
      "Train(0):   0%| | 444/262387 [00:13<1:48:53, 40.09it/s, Loss: 11.966 (21.7\u001b[A\n",
      "Train(0):   0%| | 445/262387 [00:13<1:49:08, 40.00it/s, Loss: 11.966 (21.7\u001b[A\n",
      "Train(0):   0%| | 445/262387 [00:13<1:49:08, 40.00it/s, Loss: 24.806 (21.7\u001b[A\n",
      "Train(0):   0%| | 446/262387 [00:13<1:49:08, 40.00it/s, Loss: 24.968 (21.7\u001b[A\n",
      "Train(0):   0%| | 447/262387 [00:13<1:49:08, 40.00it/s, Loss: 16.558 (21.7\u001b[A\n",
      "Train(0):   0%| | 448/262387 [00:13<1:49:08, 40.00it/s, Loss: 18.391 (21.7\u001b[A\n",
      "Train(0):   0%| | 449/262387 [00:13<1:51:30, 39.15it/s, Loss: 18.391 (21.7\u001b[A\n",
      "Train(0):   0%| | 449/262387 [00:13<1:51:30, 39.15it/s, Loss: 19.450 (21.6\u001b[A\n",
      "Train(0):   0%| | 450/262387 [00:13<1:51:30, 39.15it/s, Loss: 16.757 (21.6\u001b[A\n",
      "Train(0):   0%| | 451/262387 [00:13<1:51:30, 39.15it/s, Loss: 10.697 (21.6\u001b[A\n",
      "Train(0):   0%| | 452/262387 [00:13<1:51:30, 39.15it/s, Loss: 17.280 (21.6\u001b[A\n",
      "Train(0):   0%| | 453/262387 [00:13<1:51:30, 39.15it/s, Loss: 19.924 (21.6\u001b[A\n",
      "Train(0):   0%| | 454/262387 [00:13<1:44:34, 41.75it/s, Loss: 19.924 (21.6\u001b[A\n",
      "Train(0):   0%| | 454/262387 [00:13<1:44:34, 41.75it/s, Loss: 17.821 (21.6\u001b[A\n",
      "Train(0):   0%| | 455/262387 [00:13<1:44:34, 41.75it/s, Loss: 18.069 (21.6\u001b[A\n",
      "Train(0):   0%| | 456/262387 [00:13<1:44:34, 41.75it/s, Loss: 16.467 (21.6\u001b[A\n",
      "Train(0):   0%| | 457/262387 [00:13<1:44:34, 41.75it/s, Loss: 14.784 (21.6\u001b[A\n",
      "Train(0):   0%| | 458/262387 [00:14<1:44:34, 41.75it/s, Loss: 14.586 (21.5\u001b[A\n",
      "Train(0):   0%| | 459/262387 [00:14<1:46:20, 41.05it/s, Loss: 14.586 (21.5\u001b[A\n",
      "Train(0):   0%| | 459/262387 [00:14<1:46:20, 41.05it/s, Loss: 13.755 (21.5\u001b[A\n",
      "Train(0):   0%| | 460/262387 [00:14<1:46:20, 41.05it/s, Loss: 18.271 (21.5\u001b[A\n",
      "Train(0):   0%| | 461/262387 [00:14<1:46:20, 41.05it/s, Loss: 18.290 (21.5\u001b[A\n",
      "Train(0):   0%| | 462/262387 [00:14<1:46:20, 41.05it/s, Loss: 15.236 (21.5\u001b[A\n",
      "Train(0):   0%| | 463/262387 [00:14<1:46:20, 41.05it/s, Loss: 23.987 (21.5\u001b[A\n",
      "Train(0):   0%| | 464/262387 [00:14<1:48:44, 40.14it/s, Loss: 23.987 (21.5\u001b[A\n",
      "Train(0):   0%| | 464/262387 [00:14<1:48:44, 40.14it/s, Loss: 13.276 (21.5\u001b[A\n",
      "Train(0):   0%| | 465/262387 [00:14<1:48:44, 40.14it/s, Loss: 19.590 (21.5\u001b[A\n",
      "Train(0):   0%| | 466/262387 [00:14<1:48:44, 40.14it/s, Loss: 19.352 (21.5\u001b[A\n",
      "Train(0):   0%| | 467/262387 [00:14<1:48:44, 40.14it/s, Loss: 16.866 (21.5\u001b[A\n",
      "Train(0):   0%| | 468/262387 [00:14<1:48:44, 40.14it/s, Loss: 10.256 (21.4\u001b[A\n",
      "Train(0):   0%| | 469/262387 [00:14<1:47:54, 40.45it/s, Loss: 10.256 (21.4\u001b[A\n",
      "Train(0):   0%| | 469/262387 [00:14<1:47:54, 40.45it/s, Loss: 10.393 (21.4\u001b[A\n",
      "Train(0):   0%| | 470/262387 [00:14<1:47:54, 40.45it/s, Loss: 14.096 (21.4\u001b[A\n",
      "Train(0):   0%| | 471/262387 [00:14<1:47:54, 40.45it/s, Loss: 15.613 (21.4\u001b[A\n",
      "Train(0):   0%| | 472/262387 [00:14<1:47:54, 40.45it/s, Loss: 24.971 (21.4\u001b[A\n",
      "Train(0):   0%| | 473/262387 [00:14<1:47:54, 40.45it/s, Loss: 16.097 (21.4\u001b[A\n",
      "Train(0):   0%| | 474/262387 [00:14<1:47:52, 40.46it/s, Loss: 16.097 (21.4\u001b[A\n",
      "Train(0):   0%| | 474/262387 [00:14<1:47:52, 40.46it/s, Loss: 15.330 (21.4\u001b[A\n",
      "Train(0):   0%| | 475/262387 [00:14<1:47:52, 40.46it/s, Loss: 19.083 (21.4\u001b[A\n",
      "Train(0):   0%| | 476/262387 [00:14<1:47:52, 40.46it/s, Loss: 17.062 (21.4\u001b[A\n",
      "Train(0):   0%| | 477/262387 [00:14<1:47:52, 40.46it/s, Loss: 11.640 (21.3\u001b[A\n",
      "Train(0):   0%| | 478/262387 [00:14<1:47:52, 40.46it/s, Loss: 19.554 (21.3\u001b[A\n",
      "Train(0):   0%| | 479/262387 [00:14<1:46:21, 41.04it/s, Loss: 19.554 (21.3\u001b[A\n",
      "Train(0):   0%| | 479/262387 [00:14<1:46:21, 41.04it/s, Loss: 12.377 (21.3\u001b[A\n",
      "Train(0):   0%| | 480/262387 [00:14<1:46:21, 41.04it/s, Loss: 9.610 (21.33\u001b[A\n",
      "Train(0):   0%| | 481/262387 [00:14<1:46:21, 41.04it/s, Loss: 14.562 (21.3\u001b[A\n",
      "Train(0):   0%| | 482/262387 [00:14<1:46:21, 41.04it/s, Loss: 16.639 (21.3\u001b[A\n",
      "Train(0):   0%| | 483/262387 [00:14<1:46:21, 41.04it/s, Loss: 23.336 (21.3\u001b[A\n",
      "Train(0):   0%| | 484/262387 [00:14<1:55:33, 37.77it/s, Loss: 23.336 (21.3\u001b[A\n",
      "Train(0):   0%| | 484/262387 [00:14<1:55:33, 37.77it/s, Loss: 15.061 (21.3\u001b[A\n",
      "Train(0):   0%| | 485/262387 [00:14<1:55:33, 37.77it/s, Loss: 18.945 (21.3\u001b[A\n",
      "Train(0):   0%| | 486/262387 [00:14<1:55:33, 37.77it/s, Loss: 15.611 (21.2\u001b[A\n",
      "Train(0):   0%| | 487/262387 [00:14<1:55:33, 37.77it/s, Loss: 13.207 (21.2\u001b[A\n",
      "Train(0):   0%| | 488/262387 [00:14<1:54:23, 38.16it/s, Loss: 13.207 (21.2\u001b[A\n",
      "Train(0):   0%| | 488/262387 [00:14<1:54:23, 38.16it/s, Loss: 16.639 (21.2\u001b[A\n",
      "Train(0):   0%| | 489/262387 [00:14<1:54:23, 38.16it/s, Loss: 12.327 (21.2\u001b[A\n",
      "Train(0):   0%| | 490/262387 [00:14<1:54:23, 38.16it/s, Loss: 13.357 (21.2\u001b[A\n",
      "Train(0):   0%| | 491/262387 [00:14<1:54:23, 38.16it/s, Loss: 16.631 (21.2\u001b[A\n",
      "Train(0):   0%| | 492/262387 [00:14<1:54:23, 38.16it/s, Loss: 14.997 (21.2\u001b[A\n",
      "Train(0):   0%| | 493/262387 [00:14<1:52:49, 38.69it/s, Loss: 14.997 (21.2\u001b[A\n",
      "Train(0):   0%| | 493/262387 [00:14<1:52:49, 38.69it/s, Loss: 21.247 (21.2\u001b[A\n",
      "Train(0):   0%| | 494/262387 [00:14<1:52:49, 38.69it/s, Loss: 13.651 (21.1\u001b[A\n",
      "Train(0):   0%| | 495/262387 [00:14<1:52:49, 38.69it/s, Loss: 18.811 (21.1\u001b[A\n",
      "Train(0):   0%| | 496/262387 [00:15<1:52:49, 38.69it/s, Loss: 18.001 (21.1\u001b[A\n",
      "Train(0):   0%| | 497/262387 [00:15<1:52:49, 38.69it/s, Loss: 15.681 (21.1\u001b[A\n",
      "Train(0):   0%| | 498/262387 [00:15<1:50:30, 39.50it/s, Loss: 15.681 (21.1\u001b[A\n",
      "Train(0):   0%| | 498/262387 [00:15<1:50:30, 39.50it/s, Loss: 18.854 (21.1\u001b[A\n",
      "Train(0):   0%| | 499/262387 [00:15<1:50:30, 39.50it/s, Loss: 13.592 (21.1\u001b[A\n",
      "Train(0):   0%| | 500/262387 [00:15<1:50:30, 39.50it/s, Loss: 19.116 (21.1\u001b[A\n",
      "Train(0):   0%| | 501/262387 [00:15<1:50:30, 39.50it/s, Loss: 8.135 (21.12\u001b[A\n",
      "Train(0):   0%| | 502/262387 [00:15<2:01:27, 35.94it/s, Loss: 8.135 (21.12\u001b[A\n",
      "Train(0):   0%| | 502/262387 [00:15<2:01:27, 35.94it/s, Loss: 14.781 (21.1\u001b[A\n",
      "Train(0):   0%| | 503/262387 [00:15<2:01:27, 35.94it/s, Loss: 18.510 (21.1\u001b[A\n",
      "Train(0):   0%| | 504/262387 [00:15<2:01:27, 35.94it/s, Loss: 20.427 (21.1\u001b[A\n",
      "Train(0):   0%| | 505/262387 [00:15<2:01:27, 35.94it/s, Loss: 14.351 (21.0\u001b[A\n",
      "Train(0):   0%| | 506/262387 [00:15<2:05:07, 34.88it/s, Loss: 14.351 (21.0\u001b[A\n",
      "Train(0):   0%| | 506/262387 [00:15<2:05:07, 34.88it/s, Loss: 14.138 (21.0\u001b[A\n",
      "Train(0):   0%| | 507/262387 [00:15<2:05:07, 34.88it/s, Loss: 17.632 (21.0\u001b[A\n",
      "Train(0):   0%| | 508/262387 [00:15<2:05:07, 34.88it/s, Loss: 18.546 (21.0\u001b[A\n",
      "Train(0):   0%| | 509/262387 [00:15<2:05:07, 34.88it/s, Loss: 21.128 (21.0\u001b[A\n",
      "Train(0):   0%| | 510/262387 [00:15<2:08:30, 33.96it/s, Loss: 21.128 (21.0\u001b[A\n",
      "Train(0):   0%| | 510/262387 [00:15<2:08:30, 33.96it/s, Loss: 12.973 (21.0\u001b[A\n",
      "Train(0):   0%| | 511/262387 [00:15<2:08:30, 33.96it/s, Loss: 19.317 (21.0\u001b[A\n",
      "Train(0):   0%| | 512/262387 [00:15<2:08:30, 33.96it/s, Loss: 17.186 (21.0\u001b[A\n",
      "Train(0):   0%| | 513/262387 [00:15<2:08:30, 33.96it/s, Loss: 10.756 (21.0\u001b[A\n",
      "Train(0):   0%| | 514/262387 [00:15<2:08:30, 33.96it/s, Loss: 12.782 (20.9\u001b[A\n",
      "Train(0):   0%| | 515/262387 [00:15<1:56:09, 37.57it/s, Loss: 12.782 (20.9\u001b[A\n",
      "Train(0):   0%| | 515/262387 [00:15<1:56:09, 37.57it/s, Loss: 19.544 (20.9\u001b[A\n",
      "Train(0):   0%| | 516/262387 [00:15<1:56:09, 37.57it/s, Loss: 18.937 (20.9\u001b[A\n",
      "Train(0):   0%| | 517/262387 [00:15<1:56:09, 37.57it/s, Loss: 18.542 (20.9\u001b[A\n",
      "Train(0):   0%| | 518/262387 [00:15<1:56:09, 37.57it/s, Loss: 14.177 (20.9\u001b[A\n",
      "Train(0):   0%| | 519/262387 [00:15<2:02:38, 35.59it/s, Loss: 14.177 (20.9\u001b[A\n",
      "Train(0):   0%| | 519/262387 [00:15<2:02:38, 35.59it/s, Loss: 10.822 (20.9\u001b[A\n",
      "Train(0):   0%| | 520/262387 [00:15<2:02:38, 35.59it/s, Loss: 18.125 (20.9\u001b[A\n",
      "Train(0):   0%| | 521/262387 [00:15<2:02:38, 35.59it/s, Loss: 13.998 (20.9\u001b[A\n",
      "Train(0):   0%| | 522/262387 [00:15<2:02:38, 35.59it/s, Loss: 8.351 (20.91\u001b[A\n",
      "Train(0):   0%| | 523/262387 [00:15<2:00:14, 36.29it/s, Loss: 8.351 (20.91\u001b[A\n",
      "Train(0):   0%| | 523/262387 [00:15<2:00:14, 36.29it/s, Loss: 10.347 (20.8\u001b[A\n",
      "Train(0):   0%| | 524/262387 [00:15<2:00:14, 36.29it/s, Loss: 12.831 (20.8\u001b[A\n",
      "Train(0):   0%| | 525/262387 [00:15<2:00:14, 36.29it/s, Loss: 14.820 (20.8\u001b[A\n",
      "Train(0):   0%| | 526/262387 [00:15<2:00:14, 36.29it/s, Loss: 14.555 (20.8\u001b[A\n",
      "Train(0):   0%| | 527/262387 [00:15<1:58:35, 36.80it/s, Loss: 14.555 (20.8\u001b[A\n",
      "Train(0):   0%| | 527/262387 [00:15<1:58:35, 36.80it/s, Loss: 17.088 (20.8\u001b[A\n",
      "Train(0):   0%| | 528/262387 [00:15<1:58:35, 36.80it/s, Loss: 11.278 (20.8\u001b[A\n",
      "Train(0):   0%| | 529/262387 [00:15<1:58:35, 36.80it/s, Loss: 18.020 (20.8\u001b[A\n",
      "Train(0):   0%| | 530/262387 [00:15<1:58:35, 36.80it/s, Loss: 13.595 (20.8\u001b[A\n",
      "Train(0):   0%| | 531/262387 [00:15<1:57:26, 37.16it/s, Loss: 13.595 (20.8\u001b[A\n",
      "Train(0):   0%| | 531/262387 [00:16<1:57:26, 37.16it/s, Loss: 10.529 (20.7\u001b[A\n",
      "Train(0):   0%| | 532/262387 [00:16<1:57:26, 37.16it/s, Loss: 16.456 (20.7\u001b[A\n",
      "Train(0):   0%| | 533/262387 [00:16<1:57:26, 37.16it/s, Loss: 14.130 (20.7\u001b[A\n",
      "Train(0):   0%| | 534/262387 [00:16<1:57:26, 37.16it/s, Loss: 13.069 (20.7\u001b[A\n",
      "Train(0):   0%| | 535/262387 [00:16<2:01:43, 35.85it/s, Loss: 13.069 (20.7\u001b[A\n",
      "Train(0):   0%| | 535/262387 [00:16<2:01:43, 35.85it/s, Loss: 14.457 (20.7\u001b[A\n",
      "Train(0):   0%| | 536/262387 [00:16<2:01:43, 35.85it/s, Loss: 19.133 (20.7\u001b[A\n",
      "Train(0):   0%| | 537/262387 [00:16<2:01:43, 35.85it/s, Loss: 21.213 (20.7\u001b[A\n",
      "Train(0):   0%| | 538/262387 [00:16<2:01:43, 35.85it/s, Loss: 12.857 (20.7\u001b[A\n",
      "Train(0):   0%| | 539/262387 [00:16<1:59:57, 36.38it/s, Loss: 12.857 (20.7\u001b[A\n",
      "Train(0):   0%| | 539/262387 [00:16<1:59:57, 36.38it/s, Loss: 8.988 (20.70\u001b[A\n",
      "Train(0):   0%| | 540/262387 [00:16<1:59:57, 36.38it/s, Loss: 11.413 (20.6\u001b[A\n",
      "Train(0):   0%| | 541/262387 [00:16<1:59:57, 36.38it/s, Loss: 8.874 (20.66\u001b[A\n",
      "Train(0):   0%| | 542/262387 [00:16<1:59:57, 36.38it/s, Loss: 23.073 (20.6\u001b[A\n",
      "Train(0):   0%| | 543/262387 [00:16<2:09:22, 33.73it/s, Loss: 23.073 (20.6\u001b[A\n",
      "Train(0):   0%| | 543/262387 [00:16<2:09:22, 33.73it/s, Loss: 9.962 (20.64\u001b[A\n",
      "Train(0):   0%| | 544/262387 [00:16<2:09:22, 33.73it/s, Loss: 10.208 (20.6\u001b[A\n",
      "Train(0):   0%| | 545/262387 [00:16<2:09:22, 33.73it/s, Loss: 13.445 (20.6\u001b[A\n",
      "Train(0):   0%| | 546/262387 [00:16<2:09:22, 33.73it/s, Loss: 12.253 (20.6\u001b[A\n",
      "Train(0):   0%| | 547/262387 [00:16<2:10:37, 33.41it/s, Loss: 12.253 (20.6\u001b[A\n",
      "Train(0):   0%| | 547/262387 [00:16<2:10:37, 33.41it/s, Loss: 22.753 (20.6\u001b[A\n",
      "Train(0):   0%| | 548/262387 [00:16<2:10:37, 33.41it/s, Loss: 19.194 (20.6\u001b[A\n",
      "Train(0):   0%| | 549/262387 [00:16<2:10:37, 33.41it/s, Loss: 11.874 (20.5\u001b[A\n",
      "Train(0):   0%| | 550/262387 [00:16<2:10:37, 33.41it/s, Loss: 10.937 (20.5\u001b[A\n",
      "Train(0):   0%| | 551/262387 [00:16<2:05:52, 34.67it/s, Loss: 10.937 (20.5\u001b[A\n",
      "Train(0):   0%| | 551/262387 [00:16<2:05:52, 34.67it/s, Loss: 11.175 (20.5\u001b[A\n",
      "Train(0):   0%| | 552/262387 [00:16<2:05:52, 34.67it/s, Loss: 20.312 (20.5\u001b[A\n",
      "Train(0):   0%| | 553/262387 [00:16<2:05:52, 34.67it/s, Loss: 18.287 (20.5\u001b[A\n",
      "Train(0):   0%| | 554/262387 [00:16<2:05:52, 34.67it/s, Loss: 9.480 (20.52\u001b[A\n",
      "Train(0):   0%| | 555/262387 [00:16<2:02:34, 35.60it/s, Loss: 9.480 (20.52\u001b[A\n",
      "Train(0):   0%| | 555/262387 [00:16<2:02:34, 35.60it/s, Loss: 12.207 (20.5\u001b[A\n",
      "Train(0):   0%| | 556/262387 [00:16<2:02:34, 35.60it/s, Loss: 18.695 (20.5\u001b[A\n",
      "Train(0):   0%| | 557/262387 [00:16<2:02:34, 35.60it/s, Loss: 17.905 (20.5\u001b[A\n",
      "Train(0):   0%| | 558/262387 [00:16<2:02:34, 35.60it/s, Loss: 14.121 (20.4\u001b[A\n",
      "Train(0):   0%| | 559/262387 [00:16<1:59:58, 36.37it/s, Loss: 14.121 (20.4\u001b[A\n",
      "Train(0):   0%| | 559/262387 [00:16<1:59:58, 36.37it/s, Loss: 13.674 (20.4\u001b[A\n",
      "Train(0):   0%| | 560/262387 [00:16<1:59:58, 36.37it/s, Loss: 16.308 (20.4\u001b[A\n",
      "Train(0):   0%| | 561/262387 [00:16<1:59:58, 36.37it/s, Loss: 15.102 (20.4\u001b[A\n",
      "Train(0):   0%| | 562/262387 [00:16<1:59:58, 36.37it/s, Loss: 19.531 (20.4\u001b[A\n",
      "Train(0):   0%| | 563/262387 [00:16<2:01:23, 35.95it/s, Loss: 19.531 (20.4\u001b[A\n",
      "Train(0):   0%| | 563/262387 [00:16<2:01:23, 35.95it/s, Loss: 7.462 (20.44\u001b[A\n",
      "Train(0):   0%| | 564/262387 [00:16<2:01:23, 35.95it/s, Loss: 11.668 (20.4\u001b[A\n",
      "Train(0):   0%| | 565/262387 [00:16<2:01:23, 35.95it/s, Loss: 9.212 (20.40\u001b[A\n",
      "Train(0):   0%| | 566/262387 [00:17<2:01:23, 35.95it/s, Loss: 13.138 (20.3\u001b[A\n",
      "Train(0):   0%| | 567/262387 [00:17<2:11:21, 33.22it/s, Loss: 13.138 (20.3\u001b[A\n",
      "Train(0):   0%| | 567/262387 [00:17<2:11:21, 33.22it/s, Loss: 8.488 (20.37\u001b[A\n",
      "Train(0):   0%| | 568/262387 [00:17<2:11:21, 33.22it/s, Loss: 10.925 (20.3\u001b[A\n",
      "Train(0):   0%| | 569/262387 [00:17<2:11:21, 33.22it/s, Loss: 14.257 (20.3\u001b[A\n",
      "Train(0):   0%| | 570/262387 [00:17<2:11:21, 33.22it/s, Loss: 15.833 (20.3\u001b[A\n",
      "Train(0):   0%| | 571/262387 [00:17<2:06:13, 34.57it/s, Loss: 15.833 (20.3\u001b[A\n",
      "Train(0):   0%| | 571/262387 [00:17<2:06:13, 34.57it/s, Loss: 18.382 (20.3\u001b[A\n",
      "Train(0):   0%| | 572/262387 [00:17<2:06:13, 34.57it/s, Loss: 13.009 (20.3\u001b[A\n",
      "Train(0):   0%| | 573/262387 [00:17<2:06:13, 34.57it/s, Loss: 13.761 (20.3\u001b[A\n",
      "Train(0):   0%| | 574/262387 [00:17<2:06:13, 34.57it/s, Loss: 22.542 (20.3\u001b[A\n",
      "Train(0):   0%| | 575/262387 [00:17<2:02:39, 35.57it/s, Loss: 22.542 (20.3\u001b[A\n",
      "Train(0):   0%| | 575/262387 [00:17<2:02:39, 35.57it/s, Loss: 13.915 (20.3\u001b[A\n",
      "Train(0):   0%| | 576/262387 [00:17<2:02:39, 35.57it/s, Loss: 15.848 (20.2\u001b[A\n",
      "Train(0):   0%| | 577/262387 [00:17<2:02:39, 35.57it/s, Loss: 14.815 (20.2\u001b[A\n",
      "Train(0):   0%| | 578/262387 [00:17<2:02:39, 35.57it/s, Loss: 9.161 (20.26\u001b[A\n",
      "Train(0):   0%| | 579/262387 [00:17<2:06:52, 34.39it/s, Loss: 9.161 (20.26\u001b[A\n",
      "Train(0):   0%| | 579/262387 [00:17<2:06:52, 34.39it/s, Loss: 13.222 (20.2\u001b[A\n",
      "Train(0):   0%| | 580/262387 [00:17<2:06:52, 34.39it/s, Loss: 17.503 (20.2\u001b[A\n",
      "Train(0):   0%| | 581/262387 [00:17<2:06:52, 34.39it/s, Loss: 17.972 (20.2\u001b[A\n",
      "Train(0):   0%| | 582/262387 [00:17<2:06:52, 34.39it/s, Loss: 13.675 (20.2\u001b[A\n",
      "Train(0):   0%| | 583/262387 [00:17<2:03:04, 35.46it/s, Loss: 13.675 (20.2\u001b[A\n",
      "Train(0):   0%| | 583/262387 [00:17<2:03:04, 35.46it/s, Loss: 15.249 (20.2\u001b[A\n",
      "Train(0):   0%| | 584/262387 [00:17<2:03:04, 35.46it/s, Loss: 17.359 (20.2\u001b[A\n",
      "Train(0):   0%| | 585/262387 [00:17<2:03:04, 35.46it/s, Loss: 14.839 (20.2\u001b[A\n",
      "Train(0):   0%| | 586/262387 [00:17<2:03:04, 35.46it/s, Loss: 15.837 (20.2\u001b[A\n",
      "Train(0):   0%| | 587/262387 [00:17<2:01:01, 36.05it/s, Loss: 15.837 (20.2\u001b[A\n",
      "Train(0):   0%| | 587/262387 [00:17<2:01:01, 36.05it/s, Loss: 7.017 (20.17\u001b[A\n",
      "Train(0):   0%| | 588/262387 [00:17<2:01:01, 36.05it/s, Loss: 13.841 (20.1\u001b[A\n",
      "Train(0):   0%| | 589/262387 [00:17<2:01:01, 36.05it/s, Loss: 11.355 (20.1\u001b[A\n",
      "Train(0):   0%| | 590/262387 [00:17<2:01:01, 36.05it/s, Loss: 17.920 (20.1\u001b[A\n",
      "Train(0):   0%| | 591/262387 [00:17<1:59:13, 36.60it/s, Loss: 17.920 (20.1\u001b[A\n",
      "Train(0):   0%| | 591/262387 [00:17<1:59:13, 36.60it/s, Loss: 14.512 (20.1\u001b[A\n",
      "Train(0):   0%| | 592/262387 [00:17<1:59:13, 36.60it/s, Loss: 11.624 (20.1\u001b[A\n",
      "Train(0):   0%| | 593/262387 [00:17<1:59:13, 36.60it/s, Loss: 13.027 (20.1\u001b[A\n",
      "Train(0):   0%| | 594/262387 [00:17<1:59:13, 36.60it/s, Loss: 13.080 (20.1\u001b[A\n",
      "Train(0):   0%| | 595/262387 [00:17<1:59:13, 36.60it/s, Loss: 14.813 (20.0\u001b[A\n",
      "Train(0):   0%| | 596/262387 [00:17<1:55:39, 37.73it/s, Loss: 14.813 (20.0\u001b[A\n",
      "Train(0):   0%| | 596/262387 [00:17<1:55:39, 37.73it/s, Loss: 19.669 (20.0\u001b[A\n",
      "Train(0):   0%| | 597/262387 [00:17<1:55:39, 37.73it/s, Loss: 11.573 (20.0\u001b[A\n",
      "Train(0):   0%| | 598/262387 [00:17<1:55:39, 37.73it/s, Loss: 12.083 (20.0\u001b[A\n",
      "Train(0):   0%| | 599/262387 [00:17<1:55:39, 37.73it/s, Loss: 12.940 (20.0\u001b[A\n",
      "Train(0):   0%| | 600/262387 [00:17<1:55:39, 37.73it/s, Loss: 11.446 (20.0\u001b[A\n",
      "Train(0):   0%| | 601/262387 [00:17<1:48:08, 40.35it/s, Loss: 11.446 (20.0\u001b[A\n",
      "Train(0):   0%| | 601/262387 [00:17<1:48:08, 40.35it/s, Loss: 8.266 (20.01\u001b[A\n",
      "Train(0):   0%| | 602/262387 [00:17<1:48:08, 40.35it/s, Loss: 18.778 (20.0\u001b[A\n",
      "Train(0):   0%| | 603/262387 [00:17<1:48:08, 40.35it/s, Loss: 12.559 (20.0\u001b[A\n",
      "Train(0):   0%| | 604/262387 [00:18<1:48:08, 40.35it/s, Loss: 17.912 (20.0\u001b[A\n",
      "Train(0):   0%| | 605/262387 [00:18<1:48:08, 40.35it/s, Loss: 13.763 (19.9\u001b[A\n",
      "Train(0):   0%| | 606/262387 [00:18<1:42:57, 42.38it/s, Loss: 13.763 (19.9\u001b[A\n",
      "Train(0):   0%| | 606/262387 [00:18<1:42:57, 42.38it/s, Loss: 15.092 (19.9\u001b[A\n",
      "Train(0):   0%| | 607/262387 [00:18<1:42:57, 42.38it/s, Loss: 14.039 (19.9\u001b[A\n",
      "Train(0):   0%| | 608/262387 [00:18<1:42:57, 42.38it/s, Loss: 15.311 (19.9\u001b[A\n",
      "Train(0):   0%| | 609/262387 [00:18<1:42:57, 42.38it/s, Loss: 22.672 (19.9\u001b[A\n",
      "Train(0):   0%| | 610/262387 [00:18<1:42:56, 42.38it/s, Loss: 18.844 (19.9\u001b[A\n",
      "Train(0):   0%| | 611/262387 [00:18<1:40:36, 43.36it/s, Loss: 18.844 (19.9\u001b[A\n",
      "Train(0):   0%| | 611/262387 [00:18<1:40:36, 43.36it/s, Loss: 15.140 (19.9\u001b[A\n",
      "Train(0):   0%| | 612/262387 [00:18<1:40:36, 43.36it/s, Loss: 17.697 (19.9\u001b[A\n",
      "Train(0):   0%| | 613/262387 [00:18<1:40:36, 43.36it/s, Loss: 13.174 (19.9\u001b[A\n",
      "Train(0):   0%| | 614/262387 [00:18<1:40:36, 43.36it/s, Loss: 13.322 (19.9\u001b[A\n",
      "Train(0):   0%| | 615/262387 [00:18<1:40:36, 43.36it/s, Loss: 11.660 (19.9\u001b[A\n",
      "Train(0):   0%| | 616/262387 [00:18<1:51:36, 39.09it/s, Loss: 11.660 (19.9\u001b[A\n",
      "Train(0):   0%| | 616/262387 [00:18<1:51:36, 39.09it/s, Loss: 22.671 (19.9\u001b[A\n",
      "Train(0):   0%| | 617/262387 [00:18<1:51:36, 39.09it/s, Loss: 12.006 (19.9\u001b[A\n",
      "Train(0):   0%| | 618/262387 [00:18<1:51:36, 39.09it/s, Loss: 16.498 (19.9\u001b[A\n",
      "Train(0):   0%| | 619/262387 [00:18<1:51:36, 39.09it/s, Loss: 11.279 (19.8\u001b[A\n",
      "Train(0):   0%| | 620/262387 [00:18<1:51:36, 39.09it/s, Loss: 17.645 (19.8\u001b[A\n",
      "Train(0):   0%| | 621/262387 [00:18<1:51:36, 39.09it/s, Loss: 13.547 (19.8\u001b[A\n",
      "Train(0):   0%| | 622/262387 [00:18<1:41:46, 42.87it/s, Loss: 13.547 (19.8\u001b[A\n",
      "Train(0):   0%| | 622/262387 [00:18<1:41:46, 42.87it/s, Loss: 8.356 (19.86\u001b[A\n",
      "Train(0):   0%| | 623/262387 [00:18<1:41:46, 42.87it/s, Loss: 12.068 (19.8\u001b[A\n",
      "Train(0):   0%| | 624/262387 [00:18<1:41:46, 42.87it/s, Loss: 13.107 (19.8\u001b[A\n",
      "Train(0):   0%| | 625/262387 [00:18<1:41:46, 42.87it/s, Loss: 17.860 (19.8\u001b[A\n",
      "Train(0):   0%| | 626/262387 [00:18<1:41:46, 42.87it/s, Loss: 9.307 (19.81\u001b[A\n",
      "Train(0):   0%| | 627/262387 [00:18<1:43:52, 42.00it/s, Loss: 9.307 (19.81\u001b[A\n",
      "Train(0):   0%| | 627/262387 [00:18<1:43:52, 42.00it/s, Loss: 13.975 (19.8\u001b[A\n",
      "Train(0):   0%| | 628/262387 [00:18<1:43:52, 42.00it/s, Loss: 22.383 (19.8\u001b[A\n",
      "Train(0):   0%| | 629/262387 [00:18<1:43:52, 42.00it/s, Loss: 10.622 (19.7\u001b[A\n",
      "Train(0):   0%| | 630/262387 [00:18<1:43:52, 42.00it/s, Loss: 14.329 (19.7\u001b[A\n",
      "Train(0):   0%| | 631/262387 [00:18<1:43:52, 42.00it/s, Loss: 10.397 (19.7\u001b[A\n",
      "Train(0):   0%| | 632/262387 [00:18<1:44:02, 41.93it/s, Loss: 10.397 (19.7\u001b[A\n",
      "Train(0):   0%| | 632/262387 [00:18<1:44:02, 41.93it/s, Loss: 11.390 (19.7\u001b[A\n",
      "Train(0):   0%| | 633/262387 [00:18<1:44:02, 41.93it/s, Loss: 12.720 (19.7\u001b[A\n",
      "Train(0):   0%| | 634/262387 [00:18<1:44:02, 41.93it/s, Loss: 12.644 (19.7\u001b[A\n",
      "Train(0):   0%| | 635/262387 [00:18<1:44:02, 41.93it/s, Loss: 9.067 (19.72\u001b[A\n",
      "Train(0):   0%| | 636/262387 [00:18<1:44:02, 41.93it/s, Loss: 15.363 (19.7\u001b[A\n",
      "Train(0):   0%| | 637/262387 [00:18<1:46:00, 41.15it/s, Loss: 15.363 (19.7\u001b[A\n",
      "Train(0):   0%| | 637/262387 [00:18<1:46:00, 41.15it/s, Loss: 12.019 (19.7\u001b[A\n",
      "Train(0):   0%| | 638/262387 [00:18<1:46:00, 41.15it/s, Loss: 13.607 (19.6\u001b[A\n",
      "Train(0):   0%| | 639/262387 [00:18<1:46:00, 41.15it/s, Loss: 18.448 (19.6\u001b[A\n",
      "Train(0):   0%| | 640/262387 [00:18<1:46:00, 41.15it/s, Loss: 10.507 (19.6\u001b[A\n",
      "Train(0):   0%| | 641/262387 [00:18<1:46:00, 41.15it/s, Loss: 16.045 (19.6\u001b[A\n",
      "Train(0):   0%| | 642/262387 [00:18<1:51:24, 39.15it/s, Loss: 16.045 (19.6\u001b[A\n",
      "Train(0):   0%| | 642/262387 [00:18<1:51:24, 39.15it/s, Loss: 19.231 (19.6\u001b[A\n",
      "Train(0):   0%| | 643/262387 [00:18<1:51:24, 39.15it/s, Loss: 16.768 (19.6\u001b[A\n",
      "Train(0):   0%| | 644/262387 [00:18<1:51:24, 39.15it/s, Loss: 9.285 (19.65\u001b[A\n",
      "Train(0):   0%| | 645/262387 [00:19<1:51:24, 39.15it/s, Loss: 11.700 (19.6\u001b[A\n",
      "Train(0):   0%| | 646/262387 [00:19<1:59:25, 36.53it/s, Loss: 11.700 (19.6\u001b[A\n",
      "Train(0):   0%| | 646/262387 [00:19<1:59:25, 36.53it/s, Loss: 16.350 (19.6\u001b[A\n",
      "Train(0):   0%| | 647/262387 [00:19<1:59:25, 36.53it/s, Loss: 12.663 (19.6\u001b[A\n",
      "Train(0):   0%| | 648/262387 [00:19<1:59:25, 36.53it/s, Loss: 15.020 (19.6\u001b[A\n",
      "Train(0):   0%| | 649/262387 [00:19<1:59:25, 36.53it/s, Loss: 13.767 (19.6\u001b[A\n",
      "Train(0):   0%| | 650/262387 [00:19<1:59:20, 36.55it/s, Loss: 13.767 (19.6\u001b[A\n",
      "Train(0):   0%| | 650/262387 [00:19<1:59:20, 36.55it/s, Loss: 8.891 (19.58\u001b[A\n",
      "Train(0):   0%| | 651/262387 [00:19<1:59:20, 36.55it/s, Loss: 16.962 (19.5\u001b[A\n",
      "Train(0):   0%| | 652/262387 [00:19<1:59:20, 36.55it/s, Loss: 15.641 (19.5\u001b[A\n",
      "Train(0):   0%| | 653/262387 [00:19<1:59:20, 36.55it/s, Loss: 12.628 (19.5\u001b[A\n",
      "Train(0):   0%| | 654/262387 [00:19<1:59:20, 36.55it/s, Loss: 17.049 (19.5\u001b[A\n",
      "Train(0):   0%| | 655/262387 [00:19<1:50:16, 39.56it/s, Loss: 17.049 (19.5\u001b[A\n",
      "Train(0):   0%| | 655/262387 [00:19<1:50:16, 39.56it/s, Loss: 16.976 (19.5\u001b[A\n",
      "Train(0):   0%| | 656/262387 [00:19<1:50:16, 39.56it/s, Loss: 17.331 (19.5\u001b[A\n",
      "Train(0):   0%| | 657/262387 [00:19<1:50:16, 39.56it/s, Loss: 13.396 (19.5\u001b[A\n",
      "Train(0):   0%| | 658/262387 [00:19<1:50:16, 39.56it/s, Loss: 15.696 (19.5\u001b[A\n",
      "Train(0):   0%| | 659/262387 [00:19<1:50:16, 39.56it/s, Loss: 16.027 (19.5\u001b[A\n",
      "Train(0):   0%| | 660/262387 [00:19<1:51:45, 39.03it/s, Loss: 16.027 (19.5\u001b[A\n",
      "Train(0):   0%| | 660/262387 [00:19<1:51:45, 39.03it/s, Loss: 17.418 (19.5\u001b[A\n",
      "Train(0):   0%| | 661/262387 [00:19<1:51:45, 39.03it/s, Loss: 14.672 (19.5\u001b[A\n",
      "Train(0):   0%| | 662/262387 [00:19<1:51:45, 39.03it/s, Loss: 16.793 (19.5\u001b[A\n",
      "Train(0):   0%| | 663/262387 [00:19<1:51:45, 39.03it/s, Loss: 10.277 (19.5\u001b[A\n",
      "Train(0):   0%| | 664/262387 [00:19<2:13:42, 32.62it/s, Loss: 10.277 (19.5\u001b[A\n",
      "Train(0):   0%| | 664/262387 [00:19<2:13:42, 32.62it/s, Loss: 17.428 (19.5\u001b[A\n",
      "Train(0):   0%| | 665/262387 [00:19<2:13:42, 32.62it/s, Loss: 18.039 (19.5\u001b[A\n",
      "Train(0):   0%| | 666/262387 [00:19<2:13:42, 32.62it/s, Loss: 15.161 (19.4\u001b[A\n",
      "Train(0):   0%| | 667/262387 [00:19<2:13:42, 32.62it/s, Loss: 18.138 (19.4\u001b[A\n",
      "Train(0):   0%| | 668/262387 [00:19<2:13:42, 32.62it/s, Loss: 15.785 (19.4\u001b[A\n",
      "Train(0):   0%| | 669/262387 [00:19<2:02:42, 35.55it/s, Loss: 15.785 (19.4\u001b[A\n",
      "Train(0):   0%| | 669/262387 [00:19<2:02:42, 35.55it/s, Loss: 20.629 (19.4\u001b[A\n",
      "Train(0):   0%| | 670/262387 [00:19<2:02:42, 35.55it/s, Loss: 11.968 (19.4\u001b[A\n",
      "Train(0):   0%| | 671/262387 [00:19<2:02:42, 35.55it/s, Loss: 16.294 (19.4\u001b[A\n",
      "Train(0):   0%| | 672/262387 [00:19<2:02:42, 35.55it/s, Loss: 9.055 (19.45\u001b[A\n",
      "Train(0):   0%| | 673/262387 [00:19<2:01:04, 36.03it/s, Loss: 9.055 (19.45\u001b[A\n",
      "Train(0):   0%| | 673/262387 [00:19<2:01:04, 36.03it/s, Loss: 13.435 (19.4\u001b[A\n",
      "Train(0):   0%| | 674/262387 [00:19<2:01:04, 36.03it/s, Loss: 7.446 (19.43\u001b[A\n",
      "Train(0):   0%| | 675/262387 [00:19<2:01:04, 36.03it/s, Loss: 11.628 (19.4\u001b[A\n",
      "Train(0):   0%| | 676/262387 [00:19<2:01:04, 36.03it/s, Loss: 17.830 (19.4\u001b[A\n",
      "Train(0):   0%| | 677/262387 [00:19<2:04:40, 34.99it/s, Loss: 17.830 (19.4\u001b[A\n",
      "Train(0):   0%| | 677/262387 [00:19<2:04:40, 34.99it/s, Loss: 9.679 (19.40\u001b[A\n",
      "Train(0):   0%| | 678/262387 [00:19<2:04:40, 34.99it/s, Loss: 17.755 (19.4\u001b[A\n",
      "Train(0):   0%| | 679/262387 [00:19<2:04:40, 34.99it/s, Loss: 17.941 (19.3\u001b[A\n",
      "Train(0):   0%| | 680/262387 [00:20<2:04:39, 34.99it/s, Loss: 9.482 (19.38\u001b[A\n",
      "Train(0):   0%| | 681/262387 [00:20<2:05:37, 34.72it/s, Loss: 9.482 (19.38\u001b[A\n",
      "Train(0):   0%| | 681/262387 [00:20<2:05:37, 34.72it/s, Loss: 12.099 (19.3\u001b[A\n",
      "Train(0):   0%| | 682/262387 [00:20<2:05:37, 34.72it/s, Loss: 20.996 (19.3\u001b[A\n",
      "Train(0):   0%| | 683/262387 [00:20<2:05:37, 34.72it/s, Loss: 8.927 (19.36\u001b[A\n",
      "Train(0):   0%| | 684/262387 [00:20<2:05:37, 34.72it/s, Loss: 11.209 (19.3\u001b[A\n",
      "Train(0):   0%| | 685/262387 [00:20<2:01:30, 35.89it/s, Loss: 11.209 (19.3\u001b[A\n",
      "Train(0):   0%| | 685/262387 [00:20<2:01:30, 35.89it/s, Loss: 10.535 (19.3\u001b[A\n",
      "Train(0):   0%| | 686/262387 [00:20<2:01:30, 35.89it/s, Loss: 18.773 (19.3\u001b[A\n",
      "Train(0):   0%| | 687/262387 [00:20<2:01:30, 35.89it/s, Loss: 12.924 (19.3\u001b[A\n",
      "Train(0):   0%| | 688/262387 [00:20<2:01:30, 35.89it/s, Loss: 15.569 (19.3\u001b[A\n",
      "Train(0):   0%| | 689/262387 [00:20<2:05:34, 34.73it/s, Loss: 15.569 (19.3\u001b[A\n",
      "Train(0):   0%| | 689/262387 [00:20<2:05:34, 34.73it/s, Loss: 11.033 (19.3\u001b[A\n",
      "Train(0):   0%| | 690/262387 [00:20<2:05:34, 34.73it/s, Loss: 10.810 (19.2\u001b[A\n",
      "Train(0):   0%| | 691/262387 [00:20<2:05:34, 34.73it/s, Loss: 15.690 (19.2\u001b[A\n",
      "Train(0):   0%| | 692/262387 [00:20<2:05:34, 34.73it/s, Loss: 12.966 (19.2\u001b[A\n",
      "Train(0):   0%| | 693/262387 [00:20<2:01:21, 35.94it/s, Loss: 12.966 (19.2\u001b[A\n",
      "Train(0):   0%| | 693/262387 [00:20<2:01:21, 35.94it/s, Loss: 16.732 (19.2\u001b[A\n",
      "Train(0):   0%| | 694/262387 [00:20<2:01:21, 35.94it/s, Loss: 13.580 (19.2\u001b[A\n",
      "Train(0):   0%| | 695/262387 [00:20<2:01:21, 35.94it/s, Loss: 8.986 (19.25\u001b[A\n",
      "Train(0):   0%| | 696/262387 [00:20<2:01:21, 35.94it/s, Loss: 16.601 (19.2\u001b[A\n",
      "Train(0):   0%| | 697/262387 [00:20<1:58:05, 36.93it/s, Loss: 16.601 (19.2\u001b[A\n",
      "Train(0):   0%| | 697/262387 [00:20<1:58:05, 36.93it/s, Loss: 13.471 (19.2\u001b[A\n",
      "Train(0):   0%| | 698/262387 [00:20<1:58:05, 36.93it/s, Loss: 16.245 (19.2\u001b[A\n",
      "Train(0):   0%| | 699/262387 [00:20<1:58:05, 36.93it/s, Loss: 18.332 (19.2\u001b[A\n",
      "Train(0):   0%| | 700/262387 [00:20<1:58:05, 36.93it/s, Loss: 16.383 (19.2\u001b[A\n",
      "Train(0):   0%| | 701/262387 [00:20<1:55:27, 37.77it/s, Loss: 16.383 (19.2\u001b[A\n",
      "Train(0):   0%| | 701/262387 [00:20<1:55:27, 37.77it/s, Loss: 17.816 (19.2\u001b[A\n",
      "Train(0):   0%| | 702/262387 [00:20<1:55:27, 37.77it/s, Loss: 14.051 (19.2\u001b[A\n",
      "Train(0):   0%| | 703/262387 [00:20<1:55:27, 37.77it/s, Loss: 17.231 (19.2\u001b[A\n",
      "Train(0):   0%| | 704/262387 [00:20<1:55:27, 37.77it/s, Loss: 20.747 (19.2\u001b[A\n",
      "Train(0):   0%| | 705/262387 [00:20<1:53:38, 38.38it/s, Loss: 20.747 (19.2\u001b[A\n",
      "Train(0):   0%| | 705/262387 [00:20<1:53:38, 38.38it/s, Loss: 11.826 (19.2\u001b[A\n",
      "Train(0):   0%| | 706/262387 [00:20<1:53:38, 38.38it/s, Loss: 10.995 (19.2\u001b[A\n",
      "Train(0):   0%| | 707/262387 [00:20<1:53:38, 38.38it/s, Loss: 11.878 (19.1\u001b[A\n",
      "Train(0):   0%| | 708/262387 [00:20<1:53:38, 38.38it/s, Loss: 10.055 (19.1\u001b[A\n",
      "Train(0):   0%| | 709/262387 [00:20<1:53:55, 38.28it/s, Loss: 10.055 (19.1\u001b[A\n",
      "Train(0):   0%| | 709/262387 [00:20<1:53:55, 38.28it/s, Loss: 11.427 (19.1\u001b[A\n",
      "Train(0):   0%| | 710/262387 [00:20<1:53:55, 38.28it/s, Loss: 10.694 (19.1\u001b[A\n",
      "Train(0):   0%| | 711/262387 [00:20<1:53:55, 38.28it/s, Loss: 15.468 (19.1\u001b[A\n",
      "Train(0):   0%| | 712/262387 [00:20<1:53:55, 38.28it/s, Loss: 8.176 (19.13\u001b[A\n",
      "Train(0):   0%| | 713/262387 [00:20<1:53:55, 38.28it/s, Loss: 7.477 (19.11\u001b[A\n",
      "Train(0):   0%| | 714/262387 [00:20<1:50:36, 39.43it/s, Loss: 7.477 (19.11\u001b[A\n",
      "Train(0):   0%| | 714/262387 [00:20<1:50:36, 39.43it/s, Loss: 17.854 (19.1\u001b[A\n",
      "Train(0):   0%| | 715/262387 [00:20<1:50:36, 39.43it/s, Loss: 12.254 (19.1\u001b[A\n",
      "Train(0):   0%| | 716/262387 [00:20<1:50:36, 39.43it/s, Loss: 17.281 (19.1\u001b[A\n",
      "Train(0):   0%| | 717/262387 [00:20<1:50:36, 39.43it/s, Loss: 17.174 (19.1\u001b[A\n",
      "Train(0):   0%| | 718/262387 [00:21<1:56:21, 37.48it/s, Loss: 17.174 (19.1\u001b[A\n",
      "Train(0):   0%| | 718/262387 [00:21<1:56:21, 37.48it/s, Loss: 10.540 (19.0\u001b[A\n",
      "Train(0):   0%| | 719/262387 [00:21<1:56:21, 37.48it/s, Loss: 8.279 (19.07\u001b[A\n",
      "Train(0):   0%| | 720/262387 [00:21<1:56:21, 37.48it/s, Loss: 11.911 (19.0\u001b[A\n",
      "Train(0):   0%| | 721/262387 [00:21<1:56:21, 37.48it/s, Loss: 9.044 (19.05\u001b[A\n",
      "Train(0):   0%| | 722/262387 [00:21<1:56:21, 37.48it/s, Loss: 9.185 (19.03\u001b[A\n",
      "Train(0):   0%| | 723/262387 [00:21<1:49:39, 39.77it/s, Loss: 9.185 (19.03\u001b[A\n",
      "Train(0):   0%| | 723/262387 [00:21<1:49:39, 39.77it/s, Loss: 11.895 (19.0\u001b[A\n",
      "Train(0):   0%| | 724/262387 [00:21<1:49:39, 39.77it/s, Loss: 21.481 (19.0\u001b[A\n",
      "Train(0):   0%| | 725/262387 [00:21<1:49:39, 39.77it/s, Loss: 11.676 (19.0\u001b[A\n",
      "Train(0):   0%| | 726/262387 [00:21<1:49:39, 39.77it/s, Loss: 15.638 (19.0\u001b[A\n",
      "Train(0):   0%| | 727/262387 [00:21<1:55:20, 37.81it/s, Loss: 15.638 (19.0\u001b[A\n",
      "Train(0):   0%| | 727/262387 [00:21<1:55:20, 37.81it/s, Loss: 12.140 (19.0\u001b[A\n",
      "Train(0):   0%| | 728/262387 [00:21<1:55:20, 37.81it/s, Loss: 16.912 (19.0\u001b[A\n",
      "Train(0):   0%| | 729/262387 [00:21<1:55:20, 37.81it/s, Loss: 21.115 (19.0\u001b[A\n",
      "Train(0):   0%| | 730/262387 [00:21<1:55:20, 37.81it/s, Loss: 14.527 (19.0\u001b[A\n",
      "Train(0):   0%| | 731/262387 [00:21<1:57:14, 37.20it/s, Loss: 14.527 (19.0\u001b[A\n",
      "Train(0):   0%| | 731/262387 [00:21<1:57:14, 37.20it/s, Loss: 17.956 (18.9\u001b[A\n",
      "Train(0):   0%| | 732/262387 [00:21<1:57:14, 37.20it/s, Loss: 16.433 (18.9\u001b[A\n",
      "Train(0):   0%| | 733/262387 [00:21<1:57:14, 37.20it/s, Loss: 14.089 (18.9\u001b[A\n",
      "Train(0):   0%| | 734/262387 [00:21<1:57:14, 37.20it/s, Loss: 16.953 (18.9\u001b[A\n",
      "Train(0):   0%| | 735/262387 [00:21<1:57:56, 36.98it/s, Loss: 16.953 (18.9\u001b[A\n",
      "Train(0):   0%| | 735/262387 [00:21<1:57:56, 36.98it/s, Loss: 13.517 (18.9\u001b[A\n",
      "Train(0):   0%| | 736/262387 [00:21<1:57:56, 36.98it/s, Loss: 21.727 (18.9\u001b[A\n",
      "Train(0):   0%| | 737/262387 [00:21<1:57:56, 36.98it/s, Loss: 17.708 (18.9\u001b[A\n",
      "Train(0):   0%| | 738/262387 [00:21<1:57:56, 36.98it/s, Loss: 17.274 (18.9\u001b[A\n",
      "Train(0):   0%| | 739/262387 [00:21<2:00:49, 36.09it/s, Loss: 17.274 (18.9\u001b[A\n",
      "Train(0):   0%| | 739/262387 [00:21<2:00:49, 36.09it/s, Loss: 20.295 (18.9\u001b[A\n",
      "Train(0):   0%| | 740/262387 [00:21<2:00:49, 36.09it/s, Loss: 13.897 (18.9\u001b[A\n",
      "Train(0):   0%| | 741/262387 [00:21<2:00:49, 36.09it/s, Loss: 12.668 (18.9\u001b[A\n",
      "Train(0):   0%| | 742/262387 [00:21<2:00:49, 36.09it/s, Loss: 14.116 (18.9\u001b[A\n",
      "Train(0):   0%| | 743/262387 [00:21<2:00:34, 36.17it/s, Loss: 14.116 (18.9\u001b[A\n",
      "Train(0):   0%| | 743/262387 [00:21<2:00:34, 36.17it/s, Loss: 7.171 (18.94\u001b[A\n",
      "Train(0):   0%| | 744/262387 [00:21<2:00:34, 36.17it/s, Loss: 21.957 (18.9\u001b[A\n",
      "Train(0):   0%| | 745/262387 [00:21<2:00:34, 36.17it/s, Loss: 6.408 (18.92\u001b[A\n",
      "Train(0):   0%| | 746/262387 [00:21<2:00:34, 36.17it/s, Loss: 9.140 (18.91\u001b[A\n",
      "Train(0):   0%| | 747/262387 [00:21<2:06:56, 34.35it/s, Loss: 9.140 (18.91\u001b[A\n",
      "Train(0):   0%| | 747/262387 [00:21<2:06:56, 34.35it/s, Loss: 15.690 (18.9\u001b[A\n",
      "Train(0):   0%| | 748/262387 [00:21<2:06:56, 34.35it/s, Loss: 9.349 (18.89\u001b[A\n",
      "Train(0):   0%| | 749/262387 [00:21<2:06:56, 34.35it/s, Loss: 10.259 (18.8\u001b[A\n",
      "Train(0):   0%| | 750/262387 [00:21<2:06:56, 34.35it/s, Loss: 17.283 (18.8\u001b[A\n",
      "Train(0):   0%| | 751/262387 [00:21<2:11:17, 33.21it/s, Loss: 17.283 (18.8\u001b[A\n",
      "Train(0):   0%| | 751/262387 [00:21<2:11:17, 33.21it/s, Loss: 14.154 (18.8\u001b[A\n",
      "Train(0):   0%| | 752/262387 [00:21<2:11:17, 33.21it/s, Loss: 9.179 (18.86\u001b[A\n",
      "Train(0):   0%| | 753/262387 [00:22<2:11:17, 33.21it/s, Loss: 9.837 (18.85\u001b[A\n",
      "Train(0):   0%| | 754/262387 [00:22<2:11:17, 33.21it/s, Loss: 6.593 (18.83\u001b[A\n",
      "Train(0):   0%| | 755/262387 [00:22<2:06:09, 34.56it/s, Loss: 6.593 (18.83\u001b[A\n",
      "Train(0):   0%| | 755/262387 [00:22<2:06:09, 34.56it/s, Loss: 14.394 (18.8\u001b[A\n",
      "Train(0):   0%| | 756/262387 [00:22<2:06:09, 34.56it/s, Loss: 15.988 (18.8\u001b[A\n",
      "Train(0):   0%| | 757/262387 [00:22<2:06:09, 34.56it/s, Loss: 17.111 (18.8\u001b[A\n",
      "Train(0):   0%| | 758/262387 [00:22<2:06:09, 34.56it/s, Loss: 12.796 (18.8\u001b[A\n",
      "Train(0):   0%| | 759/262387 [00:22<2:07:01, 34.33it/s, Loss: 12.796 (18.8\u001b[A\n",
      "Train(0):   0%| | 759/262387 [00:22<2:07:01, 34.33it/s, Loss: 20.436 (18.8\u001b[A\n",
      "Train(0):   0%| | 760/262387 [00:22<2:07:01, 34.33it/s, Loss: 12.180 (18.8\u001b[A\n",
      "Train(0):   0%| | 761/262387 [00:22<2:07:01, 34.33it/s, Loss: 17.667 (18.8\u001b[A\n",
      "Train(0):   0%| | 762/262387 [00:22<2:07:01, 34.33it/s, Loss: 11.527 (18.8\u001b[A\n",
      "Train(0):   0%| | 763/262387 [00:22<2:07:01, 34.33it/s, Loss: 17.752 (18.7\u001b[A\n",
      "Train(0):   0%| | 764/262387 [00:22<1:57:59, 36.96it/s, Loss: 17.752 (18.7\u001b[A\n",
      "Train(0):   0%| | 764/262387 [00:22<1:57:59, 36.96it/s, Loss: 12.946 (18.7\u001b[A\n",
      "Train(0):   0%| | 765/262387 [00:22<1:57:59, 36.96it/s, Loss: 16.770 (18.7\u001b[A\n",
      "Train(0):   0%| | 766/262387 [00:22<1:57:59, 36.96it/s, Loss: 12.453 (18.7\u001b[A\n",
      "Train(0):   0%| | 767/262387 [00:22<1:57:59, 36.96it/s, Loss: 10.577 (18.7\u001b[A\n",
      "Train(0):   0%| | 768/262387 [00:22<1:57:59, 36.96it/s, Loss: 16.043 (18.7\u001b[A\n",
      "Train(0):   0%| | 769/262387 [00:22<1:52:54, 38.62it/s, Loss: 16.043 (18.7\u001b[A\n",
      "Train(0):   0%| | 769/262387 [00:22<1:52:54, 38.62it/s, Loss: 17.693 (18.7\u001b[A\n",
      "Train(0):   0%| | 770/262387 [00:22<1:52:54, 38.62it/s, Loss: 17.223 (18.7\u001b[A\n",
      "Train(0):   0%| | 771/262387 [00:22<1:52:54, 38.62it/s, Loss: 12.482 (18.7\u001b[A\n",
      "Train(0):   0%| | 772/262387 [00:22<1:52:54, 38.62it/s, Loss: 19.594 (18.7\u001b[A\n",
      "Train(0):   0%| | 773/262387 [00:22<1:52:54, 38.62it/s, Loss: 17.246 (18.7\u001b[A\n",
      "Train(0):   0%| | 774/262387 [00:22<1:48:14, 40.28it/s, Loss: 17.246 (18.7\u001b[A\n",
      "Train(0):   0%| | 774/262387 [00:22<1:48:14, 40.28it/s, Loss: 11.748 (18.7\u001b[A\n",
      "Train(0):   0%| | 775/262387 [00:22<1:48:14, 40.28it/s, Loss: 18.677 (18.7\u001b[A\n",
      "Train(0):   0%| | 776/262387 [00:22<1:48:14, 40.28it/s, Loss: 16.801 (18.7\u001b[A\n",
      "Train(0):   0%| | 777/262387 [00:22<1:48:14, 40.28it/s, Loss: 15.003 (18.7\u001b[A\n",
      "Train(0):   0%| | 778/262387 [00:22<1:48:14, 40.28it/s, Loss: 10.804 (18.7\u001b[A\n",
      "Train(0):   0%| | 779/262387 [00:22<1:42:05, 42.71it/s, Loss: 10.804 (18.7\u001b[A\n",
      "Train(0):   0%| | 779/262387 [00:22<1:42:05, 42.71it/s, Loss: 21.487 (18.7\u001b[A\n",
      "Train(0):   0%| | 780/262387 [00:22<1:42:05, 42.71it/s, Loss: 10.443 (18.7\u001b[A\n",
      "Train(0):   0%| | 781/262387 [00:22<1:42:05, 42.71it/s, Loss: 12.191 (18.7\u001b[A\n",
      "Train(0):   0%| | 782/262387 [00:22<1:42:05, 42.71it/s, Loss: 11.150 (18.7\u001b[A\n",
      "Train(0):   0%| | 783/262387 [00:22<1:42:05, 42.71it/s, Loss: 11.260 (18.6\u001b[A\n",
      "Train(0):   0%| | 784/262387 [00:22<1:42:05, 42.71it/s, Loss: 16.034 (18.6\u001b[A\n",
      "Train(0):   0%| | 785/262387 [00:22<1:38:31, 44.25it/s, Loss: 16.034 (18.6\u001b[A\n",
      "Train(0):   0%| | 785/262387 [00:22<1:38:31, 44.25it/s, Loss: 7.086 (18.67\u001b[A\n",
      "Train(0):   0%| | 786/262387 [00:22<1:38:31, 44.25it/s, Loss: 19.740 (18.6\u001b[A\n",
      "Train(0):   0%| | 787/262387 [00:22<1:38:31, 44.25it/s, Loss: 13.042 (18.6\u001b[A\n",
      "Train(0):   0%| | 788/262387 [00:22<1:38:31, 44.25it/s, Loss: 8.550 (18.65\u001b[A\n",
      "Train(0):   0%| | 789/262387 [00:22<1:38:31, 44.25it/s, Loss: 8.676 (18.64\u001b[A\n",
      "Train(0):   0%| | 790/262387 [00:22<1:45:08, 41.47it/s, Loss: 8.676 (18.64\u001b[A\n",
      "Train(0):   0%| | 790/262387 [00:22<1:45:08, 41.47it/s, Loss: 12.838 (18.6\u001b[A\n",
      "Train(0):   0%| | 791/262387 [00:22<1:45:08, 41.47it/s, Loss: 14.820 (18.6\u001b[A\n",
      "Train(0):   0%| | 792/262387 [00:22<1:45:08, 41.47it/s, Loss: 9.976 (18.62\u001b[A\n",
      "Train(0):   0%| | 793/262387 [00:23<1:45:08, 41.47it/s, Loss: 21.597 (18.6\u001b[A\n",
      "Train(0):   0%| | 794/262387 [00:23<1:45:08, 41.47it/s, Loss: 11.677 (18.6\u001b[A\n",
      "Train(0):   0%| | 795/262387 [00:23<1:51:31, 39.09it/s, Loss: 11.677 (18.6\u001b[A\n",
      "Train(0):   0%| | 795/262387 [00:23<1:51:31, 39.09it/s, Loss: 16.069 (18.6\u001b[A\n",
      "Train(0):   0%| | 796/262387 [00:23<1:51:31, 39.09it/s, Loss: 18.621 (18.6\u001b[A\n",
      "Train(0):   0%| | 797/262387 [00:23<1:51:31, 39.09it/s, Loss: 8.739 (18.59\u001b[A\n",
      "Train(0):   0%| | 798/262387 [00:23<1:51:31, 39.09it/s, Loss: 16.154 (18.5\u001b[A\n",
      "Train(0):   0%| | 799/262387 [00:23<1:53:02, 38.57it/s, Loss: 16.154 (18.5\u001b[A\n",
      "Train(0):   0%| | 799/262387 [00:23<1:53:02, 38.57it/s, Loss: 17.138 (18.5\u001b[A\n",
      "Train(0):   0%| | 800/262387 [00:23<1:53:02, 38.57it/s, Loss: 8.881 (18.58\u001b[A\n",
      "Train(0):   0%| | 801/262387 [00:23<1:53:02, 38.57it/s, Loss: 20.374 (18.5\u001b[A\n",
      "Train(0):   0%| | 802/262387 [00:23<1:53:02, 38.57it/s, Loss: 16.263 (18.5\u001b[A\n",
      "Train(0):   0%| | 803/262387 [00:23<1:53:00, 38.58it/s, Loss: 16.263 (18.5\u001b[A\n",
      "Train(0):   0%| | 803/262387 [00:23<1:53:00, 38.58it/s, Loss: 16.173 (18.5\u001b[A\n",
      "Train(0):   0%| | 804/262387 [00:23<1:52:59, 38.58it/s, Loss: 16.013 (18.5\u001b[A\n",
      "Train(0):   0%| | 805/262387 [00:23<1:52:59, 38.58it/s, Loss: 17.039 (18.5\u001b[A\n",
      "Train(0):   0%| | 806/262387 [00:23<1:52:59, 38.58it/s, Loss: 11.648 (18.5\u001b[A\n",
      "Train(0):   0%| | 807/262387 [00:23<1:52:59, 38.58it/s, Loss: 13.652 (18.5\u001b[A\n",
      "Train(0):   0%| | 808/262387 [00:23<1:46:54, 40.78it/s, Loss: 13.652 (18.5\u001b[A\n",
      "Train(0):   0%| | 808/262387 [00:23<1:46:54, 40.78it/s, Loss: 14.859 (18.5\u001b[A\n",
      "Train(0):   0%| | 809/262387 [00:23<1:46:54, 40.78it/s, Loss: 16.100 (18.5\u001b[A\n",
      "Train(0):   0%| | 810/262387 [00:23<1:46:54, 40.78it/s, Loss: 12.132 (18.5\u001b[A\n",
      "Train(0):   0%| | 811/262387 [00:23<1:46:54, 40.78it/s, Loss: 10.757 (18.5\u001b[A\n",
      "Train(0):   0%| | 812/262387 [00:23<1:46:54, 40.78it/s, Loss: 12.245 (18.5\u001b[A\n",
      "Train(0):   0%| | 813/262387 [00:23<1:44:16, 41.81it/s, Loss: 12.245 (18.5\u001b[A\n",
      "Train(0):   0%| | 813/262387 [00:23<1:44:16, 41.81it/s, Loss: 9.447 (18.51\u001b[A\n",
      "Train(0):   0%| | 814/262387 [00:23<1:44:16, 41.81it/s, Loss: 19.692 (18.5\u001b[A\n",
      "Train(0):   0%| | 815/262387 [00:23<1:44:16, 41.81it/s, Loss: 10.836 (18.5\u001b[A\n",
      "Train(0):   0%| | 816/262387 [00:23<1:44:16, 41.81it/s, Loss: 19.301 (18.5\u001b[A\n",
      "Train(0):   0%| | 817/262387 [00:23<1:44:16, 41.81it/s, Loss: 15.921 (18.5\u001b[A\n",
      "Train(0):   0%| | 818/262387 [00:23<1:47:57, 40.38it/s, Loss: 15.921 (18.5\u001b[A\n",
      "Train(0):   0%| | 818/262387 [00:23<1:47:57, 40.38it/s, Loss: 15.243 (18.5\u001b[A\n",
      "Train(0):   0%| | 819/262387 [00:23<1:47:57, 40.38it/s, Loss: 14.486 (18.4\u001b[A\n",
      "Train(0):   0%| | 820/262387 [00:23<1:47:57, 40.38it/s, Loss: 15.642 (18.4\u001b[A\n",
      "Train(0):   0%| | 821/262387 [00:23<1:47:57, 40.38it/s, Loss: 12.357 (18.4\u001b[A\n",
      "Train(0):   0%| | 822/262387 [00:23<1:47:57, 40.38it/s, Loss: 12.125 (18.4\u001b[A\n",
      "Train(0):   0%| | 823/262387 [00:23<1:42:36, 42.48it/s, Loss: 12.125 (18.4\u001b[A\n",
      "Train(0):   0%| | 823/262387 [00:23<1:42:36, 42.48it/s, Loss: 10.575 (18.4\u001b[A\n",
      "Train(0):   0%| | 824/262387 [00:23<1:42:36, 42.48it/s, Loss: 17.157 (18.4\u001b[A\n",
      "Train(0):   0%| | 825/262387 [00:23<1:42:36, 42.48it/s, Loss: 8.197 (18.45\u001b[A\n",
      "Train(0):   0%| | 826/262387 [00:23<1:42:36, 42.48it/s, Loss: 8.546 (18.44\u001b[A\n",
      "Train(0):   0%| | 827/262387 [00:23<1:42:36, 42.48it/s, Loss: 16.223 (18.4\u001b[A\n",
      "Train(0):   0%| | 828/262387 [00:23<1:44:08, 41.86it/s, Loss: 16.223 (18.4\u001b[A\n",
      "Train(0):   0%| | 828/262387 [00:23<1:44:08, 41.86it/s, Loss: 20.396 (18.4\u001b[A\n",
      "Train(0):   0%| | 829/262387 [00:23<1:44:08, 41.86it/s, Loss: 13.896 (18.4\u001b[A\n",
      "Train(0):   0%| | 830/262387 [00:23<1:44:08, 41.86it/s, Loss: 11.582 (18.4\u001b[A\n",
      "Train(0):   0%| | 831/262387 [00:23<1:44:08, 41.86it/s, Loss: 10.844 (18.4\u001b[A\n",
      "Train(0):   0%| | 832/262387 [00:23<1:44:08, 41.86it/s, Loss: 12.832 (18.4\u001b[A\n",
      "Train(0):   0%| | 833/262387 [00:23<1:40:39, 43.31it/s, Loss: 12.832 (18.4\u001b[A\n",
      "Train(0):   0%| | 833/262387 [00:23<1:40:39, 43.31it/s, Loss: 10.983 (18.4\u001b[A\n",
      "Train(0):   0%| | 834/262387 [00:23<1:40:39, 43.31it/s, Loss: 9.907 (18.39\u001b[A\n",
      "Train(0):   0%| | 835/262387 [00:24<1:40:39, 43.31it/s, Loss: 7.767 (18.38\u001b[A\n",
      "Train(0):   0%| | 836/262387 [00:24<1:40:39, 43.31it/s, Loss: 17.880 (18.3\u001b[A\n",
      "Train(0):   0%| | 837/262387 [00:24<1:40:38, 43.31it/s, Loss: 19.530 (18.3\u001b[A\n",
      "Train(0):   0%| | 838/262387 [00:24<1:44:27, 41.73it/s, Loss: 19.530 (18.3\u001b[A\n",
      "Train(0):   0%| | 838/262387 [00:24<1:44:27, 41.73it/s, Loss: 14.364 (18.3\u001b[A\n",
      "Train(0):   0%| | 839/262387 [00:24<1:44:27, 41.73it/s, Loss: 9.258 (18.36\u001b[A\n",
      "Train(0):   0%| | 840/262387 [00:24<1:44:27, 41.73it/s, Loss: 16.200 (18.3\u001b[A\n",
      "Train(0):   0%| | 841/262387 [00:24<1:44:27, 41.73it/s, Loss: 13.188 (18.3\u001b[A\n",
      "Train(0):   0%| | 842/262387 [00:24<1:44:27, 41.73it/s, Loss: 11.940 (18.3\u001b[A\n",
      "Train(0):   0%| | 843/262387 [00:24<1:47:51, 40.42it/s, Loss: 11.940 (18.3\u001b[A\n",
      "Train(0):   0%| | 843/262387 [00:24<1:47:51, 40.42it/s, Loss: 12.000 (18.3\u001b[A\n",
      "Train(0):   0%| | 844/262387 [00:24<1:47:51, 40.42it/s, Loss: 15.245 (18.3\u001b[A\n",
      "Train(0):   0%| | 845/262387 [00:24<1:47:51, 40.42it/s, Loss: 14.631 (18.3\u001b[A\n",
      "Train(0):   0%| | 846/262387 [00:24<1:47:51, 40.42it/s, Loss: 12.253 (18.3\u001b[A\n",
      "Train(0):   0%| | 847/262387 [00:24<1:47:50, 40.42it/s, Loss: 12.824 (18.3\u001b[A\n",
      "Train(0):   0%| | 848/262387 [00:24<1:49:01, 39.98it/s, Loss: 12.824 (18.3\u001b[A\n",
      "Train(0):   0%| | 848/262387 [00:24<1:49:01, 39.98it/s, Loss: 12.941 (18.3\u001b[A\n",
      "Train(0):   0%| | 849/262387 [00:24<1:49:00, 39.98it/s, Loss: 8.325 (18.30\u001b[A\n",
      "Train(0):   0%| | 850/262387 [00:24<1:49:00, 39.98it/s, Loss: 18.165 (18.3\u001b[A\n",
      "Train(0):   0%| | 851/262387 [00:24<1:49:00, 39.98it/s, Loss: 11.322 (18.2\u001b[A\n",
      "Train(0):   0%| | 852/262387 [00:24<1:49:00, 39.98it/s, Loss: 16.405 (18.2\u001b[A\n",
      "Train(0):   0%| | 853/262387 [00:24<1:42:39, 42.46it/s, Loss: 16.405 (18.2\u001b[A\n",
      "Train(0):   0%| | 853/262387 [00:24<1:42:39, 42.46it/s, Loss: 8.200 (18.27\u001b[A\n",
      "Train(0):   0%| | 854/262387 [00:24<1:42:39, 42.46it/s, Loss: 8.189 (18.26\u001b[A\n",
      "Train(0):   0%| | 855/262387 [00:24<1:42:39, 42.46it/s, Loss: 11.885 (18.2\u001b[A\n",
      "Train(0):   0%| | 856/262387 [00:24<1:42:39, 42.46it/s, Loss: 17.131 (18.2\u001b[A\n",
      "Train(0):   0%| | 857/262387 [00:24<1:42:39, 42.46it/s, Loss: 11.663 (18.2\u001b[A\n",
      "Train(0):   0%| | 858/262387 [00:24<1:45:56, 41.14it/s, Loss: 11.663 (18.2\u001b[A\n",
      "Train(0):   0%| | 858/262387 [00:24<1:45:56, 41.14it/s, Loss: 15.880 (18.2\u001b[A\n",
      "Train(0):   0%| | 859/262387 [00:24<1:45:56, 41.14it/s, Loss: 7.017 (18.23\u001b[A\n",
      "Train(0):   0%| | 860/262387 [00:24<1:45:56, 41.14it/s, Loss: 13.372 (18.2\u001b[A\n",
      "Train(0):   0%| | 861/262387 [00:24<1:45:56, 41.14it/s, Loss: 14.566 (18.2\u001b[A\n",
      "Train(0):   0%| | 862/262387 [00:24<1:45:56, 41.14it/s, Loss: 16.995 (18.2\u001b[A\n",
      "Train(0):   0%| | 863/262387 [00:24<1:47:10, 40.67it/s, Loss: 16.995 (18.2\u001b[A\n",
      "Train(0):   0%| | 863/262387 [00:24<1:47:10, 40.67it/s, Loss: 9.931 (18.21\u001b[A\n",
      "Train(0):   0%| | 864/262387 [00:24<1:47:10, 40.67it/s, Loss: 20.446 (18.2\u001b[A\n",
      "Train(0):   0%| | 865/262387 [00:24<1:47:10, 40.67it/s, Loss: 11.359 (18.2\u001b[A\n",
      "Train(0):   0%| | 866/262387 [00:24<1:47:09, 40.67it/s, Loss: 12.219 (18.2\u001b[A\n",
      "Train(0):   0%| | 867/262387 [00:24<1:47:09, 40.67it/s, Loss: 13.187 (18.1\u001b[A\n",
      "Train(0):   0%| | 868/262387 [00:24<1:53:22, 38.45it/s, Loss: 13.187 (18.1\u001b[A\n",
      "Train(0):   0%| | 868/262387 [00:24<1:53:22, 38.45it/s, Loss: 13.125 (18.1\u001b[A\n",
      "Train(0):   0%| | 869/262387 [00:24<1:53:22, 38.45it/s, Loss: 15.569 (18.1\u001b[A\n",
      "Train(0):   0%| | 870/262387 [00:24<1:53:22, 38.45it/s, Loss: 11.852 (18.1\u001b[A\n",
      "Train(0):   0%| | 871/262387 [00:24<1:53:22, 38.45it/s, Loss: 8.616 (18.16\u001b[A\n",
      "Train(0):   0%| | 872/262387 [00:24<1:58:18, 36.84it/s, Loss: 8.616 (18.16\u001b[A\n",
      "Train(0):   0%| | 872/262387 [00:24<1:58:18, 36.84it/s, Loss: 14.260 (18.1\u001b[A\n",
      "Train(0):   0%| | 873/262387 [00:24<1:58:18, 36.84it/s, Loss: 8.665 (18.15\u001b[A\n",
      "Train(0):   0%| | 874/262387 [00:25<1:58:18, 36.84it/s, Loss: 8.200 (18.14\u001b[A\n",
      "Train(0):   0%| | 875/262387 [00:25<1:58:18, 36.84it/s, Loss: 11.308 (18.1\u001b[A\n",
      "Train(0):   0%| | 876/262387 [00:25<1:57:05, 37.22it/s, Loss: 11.308 (18.1\u001b[A\n",
      "Train(0):   0%| | 876/262387 [00:25<1:57:05, 37.22it/s, Loss: 12.248 (18.1\u001b[A\n",
      "Train(0):   0%| | 877/262387 [00:25<1:57:05, 37.22it/s, Loss: 13.839 (18.1\u001b[A\n",
      "Train(0):   0%| | 878/262387 [00:25<1:57:05, 37.22it/s, Loss: 15.382 (18.1\u001b[A\n",
      "Train(0):   0%| | 879/262387 [00:25<1:57:05, 37.22it/s, Loss: 18.360 (18.1\u001b[A\n",
      "Train(0):   0%| | 880/262387 [00:25<1:55:29, 37.74it/s, Loss: 18.360 (18.1\u001b[A\n",
      "Train(0):   0%| | 880/262387 [00:25<1:55:29, 37.74it/s, Loss: 15.780 (18.1\u001b[A\n",
      "Train(0):   0%| | 881/262387 [00:25<1:55:29, 37.74it/s, Loss: 10.777 (18.1\u001b[A\n",
      "Train(0):   0%| | 882/262387 [00:25<1:55:29, 37.74it/s, Loss: 17.453 (18.1\u001b[A\n",
      "Train(0):   0%| | 883/262387 [00:25<1:55:29, 37.74it/s, Loss: 17.910 (18.1\u001b[A\n",
      "Train(0):   0%| | 884/262387 [00:25<1:55:29, 37.74it/s, Loss: 15.386 (18.1\u001b[A\n",
      "Train(0):   0%| | 885/262387 [00:25<1:53:18, 38.46it/s, Loss: 15.386 (18.1\u001b[A\n",
      "Train(0):   0%| | 885/262387 [00:25<1:53:18, 38.46it/s, Loss: 15.525 (18.1\u001b[A\n",
      "Train(0):   0%| | 886/262387 [00:25<1:53:18, 38.46it/s, Loss: 6.705 (18.08\u001b[A\n",
      "Train(0):   0%| | 887/262387 [00:25<1:53:18, 38.46it/s, Loss: 12.964 (18.0\u001b[A\n",
      "Train(0):   0%| | 888/262387 [00:25<1:53:18, 38.46it/s, Loss: 18.192 (18.0\u001b[A\n",
      "Train(0):   0%| | 889/262387 [00:25<2:00:10, 36.27it/s, Loss: 18.192 (18.0\u001b[A\n",
      "Train(0):   0%| | 889/262387 [00:25<2:00:10, 36.27it/s, Loss: 11.862 (18.0\u001b[A\n",
      "Train(0):   0%| | 890/262387 [00:25<2:00:10, 36.27it/s, Loss: 16.710 (18.0\u001b[A\n",
      "Train(0):   0%| | 891/262387 [00:25<2:00:10, 36.27it/s, Loss: 15.489 (18.0\u001b[A\n",
      "Train(0):   0%| | 892/262387 [00:25<2:00:10, 36.27it/s, Loss: 19.559 (18.0\u001b[A\n",
      "Train(0):   0%| | 893/262387 [00:25<1:57:08, 37.20it/s, Loss: 19.559 (18.0\u001b[A\n",
      "Train(0):   0%| | 893/262387 [00:25<1:57:08, 37.20it/s, Loss: 16.685 (18.0\u001b[A\n",
      "Train(0):   0%| | 894/262387 [00:25<1:57:08, 37.20it/s, Loss: 8.317 (18.06\u001b[A\n",
      "Train(0):   0%| | 895/262387 [00:25<1:57:08, 37.20it/s, Loss: 13.772 (18.0\u001b[A\n",
      "Train(0):   0%| | 896/262387 [00:25<1:57:08, 37.20it/s, Loss: 11.710 (18.0\u001b[A\n",
      "Train(0):   0%| | 897/262387 [00:25<1:56:13, 37.50it/s, Loss: 11.710 (18.0\u001b[A\n",
      "Train(0):   0%| | 897/262387 [00:25<1:56:13, 37.50it/s, Loss: 12.448 (18.0\u001b[A\n",
      "Train(0):   0%| | 898/262387 [00:25<1:56:13, 37.50it/s, Loss: 9.847 (18.03\u001b[A\n",
      "Train(0):   0%| | 899/262387 [00:25<1:56:12, 37.50it/s, Loss: 8.596 (18.02\u001b[A\n",
      "Train(0):   0%| | 900/262387 [00:25<1:56:12, 37.50it/s, Loss: 11.448 (18.0\u001b[A\n",
      "Train(0):   0%| | 901/262387 [00:25<1:55:44, 37.65it/s, Loss: 11.448 (18.0\u001b[A\n",
      "Train(0):   0%| | 901/262387 [00:25<1:55:44, 37.65it/s, Loss: 7.478 (18.00\u001b[A\n",
      "Train(0):   0%| | 902/262387 [00:25<1:55:44, 37.65it/s, Loss: 13.307 (17.9\u001b[A\n",
      "Train(0):   0%| | 903/262387 [00:25<1:55:44, 37.65it/s, Loss: 12.369 (17.9\u001b[A\n",
      "Train(0):   0%| | 904/262387 [00:25<1:55:44, 37.65it/s, Loss: 19.693 (17.9\u001b[A\n",
      "Train(0):   0%| | 905/262387 [00:25<1:55:17, 37.80it/s, Loss: 19.693 (17.9\u001b[A\n",
      "Train(0):   0%| | 905/262387 [00:25<1:55:17, 37.80it/s, Loss: 10.048 (17.9\u001b[A\n",
      "Train(0):   0%| | 906/262387 [00:25<1:55:17, 37.80it/s, Loss: 12.999 (17.9\u001b[A\n",
      "Train(0):   0%| | 907/262387 [00:25<1:55:17, 37.80it/s, Loss: 16.596 (17.9\u001b[A\n",
      "Train(0):   0%| | 908/262387 [00:25<1:55:17, 37.80it/s, Loss: 15.756 (17.9\u001b[A\n",
      "Train(0):   0%| | 909/262387 [00:25<1:55:17, 37.80it/s, Loss: 10.853 (17.9\u001b[A\n",
      "Train(0):   0%| | 910/262387 [00:25<1:52:25, 38.76it/s, Loss: 10.853 (17.9\u001b[A\n",
      "Train(0):   0%| | 910/262387 [00:25<1:52:25, 38.76it/s, Loss: 11.197 (17.9\u001b[A\n",
      "Train(0):   0%| | 911/262387 [00:25<1:52:25, 38.76it/s, Loss: 15.467 (17.9\u001b[A\n",
      "Train(0):   0%| | 912/262387 [00:26<1:52:25, 38.76it/s, Loss: 10.904 (17.9\u001b[A\n",
      "Train(0):   0%| | 913/262387 [00:26<1:52:25, 38.76it/s, Loss: 16.794 (17.9\u001b[A\n",
      "Train(0):   0%| | 914/262387 [00:26<1:59:44, 36.39it/s, Loss: 16.794 (17.9\u001b[A\n",
      "Train(0):   0%| | 914/262387 [00:26<1:59:44, 36.39it/s, Loss: 12.069 (17.9\u001b[A\n",
      "Train(0):   0%| | 915/262387 [00:26<1:59:44, 36.39it/s, Loss: 19.435 (17.9\u001b[A\n",
      "Train(0):   0%| | 916/262387 [00:26<1:59:44, 36.39it/s, Loss: 15.528 (17.9\u001b[A\n",
      "Train(0):   0%| | 917/262387 [00:26<1:59:44, 36.39it/s, Loss: 19.735 (17.9\u001b[A\n",
      "Train(0):   0%| | 918/262387 [00:26<1:59:12, 36.56it/s, Loss: 19.735 (17.9\u001b[A\n",
      "Train(0):   0%| | 918/262387 [00:26<1:59:12, 36.56it/s, Loss: 17.889 (17.9\u001b[A\n",
      "Train(0):   0%| | 919/262387 [00:26<1:59:11, 36.56it/s, Loss: 15.548 (17.9\u001b[A\n",
      "Train(0):   0%| | 920/262387 [00:26<1:59:11, 36.56it/s, Loss: 9.997 (17.93\u001b[A\n",
      "Train(0):   0%| | 921/262387 [00:26<1:59:11, 36.56it/s, Loss: 17.696 (17.9\u001b[A\n",
      "Train(0):   0%| | 922/262387 [00:26<1:58:53, 36.65it/s, Loss: 17.696 (17.9\u001b[A\n",
      "Train(0):   0%| | 922/262387 [00:26<1:58:53, 36.65it/s, Loss: 10.118 (17.9\u001b[A\n",
      "Train(0):   0%| | 923/262387 [00:26<1:58:53, 36.65it/s, Loss: 11.842 (17.9\u001b[A\n",
      "Train(0):   0%| | 924/262387 [00:26<1:58:53, 36.65it/s, Loss: 15.136 (17.9\u001b[A\n",
      "Train(0):   0%| | 925/262387 [00:26<1:58:53, 36.65it/s, Loss: 11.158 (17.9\u001b[A\n",
      "Train(0):   0%| | 926/262387 [00:26<1:58:38, 36.73it/s, Loss: 11.158 (17.9\u001b[A\n",
      "Train(0):   0%| | 926/262387 [00:26<1:58:38, 36.73it/s, Loss: 15.638 (17.9\u001b[A\n",
      "Train(0):   0%| | 927/262387 [00:26<1:58:38, 36.73it/s, Loss: 10.560 (17.8\u001b[A\n",
      "Train(0):   0%| | 928/262387 [00:26<1:58:38, 36.73it/s, Loss: 13.119 (17.8\u001b[A\n",
      "Train(0):   0%| | 929/262387 [00:26<1:58:38, 36.73it/s, Loss: 14.155 (17.8\u001b[A\n",
      "Train(0):   0%| | 930/262387 [00:26<1:58:48, 36.68it/s, Loss: 14.155 (17.8\u001b[A\n",
      "Train(0):   0%| | 930/262387 [00:26<1:58:48, 36.68it/s, Loss: 8.326 (17.87\u001b[A\n",
      "Train(0):   0%| | 931/262387 [00:26<1:58:48, 36.68it/s, Loss: 11.062 (17.8\u001b[A\n",
      "Train(0):   0%| | 932/262387 [00:26<1:58:48, 36.68it/s, Loss: 15.376 (17.8\u001b[A\n",
      "Train(0):   0%| | 933/262387 [00:26<1:58:48, 36.68it/s, Loss: 19.615 (17.8\u001b[A\n",
      "Train(0):   0%| | 934/262387 [00:26<1:58:12, 36.86it/s, Loss: 19.615 (17.8\u001b[A\n",
      "Train(0):   0%| | 934/262387 [00:26<1:58:12, 36.86it/s, Loss: 10.255 (17.8\u001b[A\n",
      "Train(0):   0%| | 935/262387 [00:26<1:58:12, 36.86it/s, Loss: 5.915 (17.84\u001b[A\n",
      "Train(0):   0%| | 936/262387 [00:26<1:58:12, 36.86it/s, Loss: 9.805 (17.83\u001b[A\n",
      "Train(0):   0%| | 937/262387 [00:26<1:58:12, 36.86it/s, Loss: 15.758 (17.8\u001b[A\n",
      "Train(0):   0%| | 938/262387 [00:26<1:58:14, 36.85it/s, Loss: 15.758 (17.8\u001b[A\n",
      "Train(0):   0%| | 938/262387 [00:26<1:58:14, 36.85it/s, Loss: 7.582 (17.82\u001b[A\n",
      "Train(0):   0%| | 939/262387 [00:26<1:58:14, 36.85it/s, Loss: 6.628 (17.81\u001b[A\n",
      "Train(0):   0%| | 940/262387 [00:26<1:58:14, 36.85it/s, Loss: 13.543 (17.8\u001b[A\n",
      "Train(0):   0%| | 941/262387 [00:26<1:58:14, 36.85it/s, Loss: 7.173 (17.79\u001b[A\n",
      "Train(0):   0%| | 942/262387 [00:26<2:03:23, 35.31it/s, Loss: 7.173 (17.79\u001b[A\n",
      "Train(0):   0%| | 942/262387 [00:26<2:03:23, 35.31it/s, Loss: 12.010 (17.7\u001b[A\n",
      "Train(0):   0%| | 943/262387 [00:26<2:03:23, 35.31it/s, Loss: 11.481 (17.7\u001b[A\n",
      "Train(0):   0%| | 944/262387 [00:26<2:03:23, 35.31it/s, Loss: 12.339 (17.7\u001b[A\n",
      "Train(0):   0%| | 945/262387 [00:26<2:03:23, 35.31it/s, Loss: 11.306 (17.7\u001b[A\n",
      "Train(0):   0%| | 946/262387 [00:26<2:00:54, 36.04it/s, Loss: 11.306 (17.7\u001b[A\n",
      "Train(0):   0%| | 946/262387 [00:26<2:00:54, 36.04it/s, Loss: 9.007 (17.76\u001b[A\n",
      "Train(0):   0%| | 947/262387 [00:27<2:00:54, 36.04it/s, Loss: 13.409 (17.7\u001b[A\n",
      "Train(0):   0%| | 948/262387 [00:27<2:00:54, 36.04it/s, Loss: 17.773 (17.7\u001b[A\n",
      "Train(0):   0%| | 949/262387 [00:27<2:00:54, 36.04it/s, Loss: 16.601 (17.7\u001b[A\n",
      "Train(0):   0%| | 950/262387 [00:27<1:59:49, 36.37it/s, Loss: 16.601 (17.7\u001b[A\n",
      "Train(0):   0%| | 950/262387 [00:27<1:59:49, 36.37it/s, Loss: 7.371 (17.74\u001b[A\n",
      "Train(0):   0%| | 951/262387 [00:27<1:59:49, 36.37it/s, Loss: 15.428 (17.7\u001b[A\n",
      "Train(0):   0%| | 952/262387 [00:27<1:59:49, 36.37it/s, Loss: 13.439 (17.7\u001b[A\n",
      "Train(0):   0%| | 953/262387 [00:27<1:59:48, 36.37it/s, Loss: 19.612 (17.7\u001b[A\n",
      "Train(0):   0%| | 954/262387 [00:27<2:13:12, 32.71it/s, Loss: 19.612 (17.7\u001b[A\n",
      "Train(0):   0%| | 954/262387 [00:27<2:13:12, 32.71it/s, Loss: 16.451 (17.7\u001b[A\n",
      "Train(0):   0%| | 955/262387 [00:27<2:13:12, 32.71it/s, Loss: 10.284 (17.7\u001b[A\n",
      "Train(0):   0%| | 956/262387 [00:27<2:13:12, 32.71it/s, Loss: 13.575 (17.7\u001b[A\n",
      "Train(0):   0%| | 957/262387 [00:27<2:13:12, 32.71it/s, Loss: 13.553 (17.7\u001b[A\n",
      "Train(0):   0%| | 958/262387 [00:27<2:13:12, 32.71it/s, Loss: 18.351 (17.7\u001b[A\n",
      "Train(0):   0%| | 959/262387 [00:27<2:01:55, 35.74it/s, Loss: 18.351 (17.7\u001b[A\n",
      "Train(0):   0%| | 959/262387 [00:27<2:01:55, 35.74it/s, Loss: 8.180 (17.71\u001b[A\n",
      "Train(0):   0%| | 960/262387 [00:27<2:01:55, 35.74it/s, Loss: 13.572 (17.7\u001b[A\n",
      "Train(0):   0%| | 961/262387 [00:27<2:01:55, 35.74it/s, Loss: 8.212 (17.70\u001b[A\n",
      "Train(0):   0%| | 962/262387 [00:27<2:01:55, 35.74it/s, Loss: 16.227 (17.6\u001b[A\n",
      "Train(0):   0%| | 963/262387 [00:27<2:03:39, 35.23it/s, Loss: 16.227 (17.6\u001b[A\n",
      "Train(0):   0%| | 963/262387 [00:27<2:03:39, 35.23it/s, Loss: 13.835 (17.6\u001b[A\n",
      "Train(0):   0%| | 964/262387 [00:27<2:03:39, 35.23it/s, Loss: 14.711 (17.6\u001b[A\n",
      "Train(0):   0%| | 965/262387 [00:27<2:03:39, 35.23it/s, Loss: 12.770 (17.6\u001b[A\n",
      "Train(0):   0%| | 966/262387 [00:27<2:03:39, 35.23it/s, Loss: 7.156 (17.67\u001b[A\n",
      "Train(0):   0%| | 967/262387 [00:27<2:03:39, 35.23it/s, Loss: 14.877 (17.6\u001b[A\n",
      "Train(0):   0%| | 968/262387 [00:27<1:53:43, 38.31it/s, Loss: 14.877 (17.6\u001b[A\n",
      "Train(0):   0%| | 968/262387 [00:27<1:53:43, 38.31it/s, Loss: 16.044 (17.6\u001b[A\n",
      "Train(0):   0%| | 969/262387 [00:27<1:53:43, 38.31it/s, Loss: 14.944 (17.6\u001b[A\n",
      "Train(0):   0%| | 970/262387 [00:27<1:53:43, 38.31it/s, Loss: 17.473 (17.6\u001b[A\n",
      "Train(0):   0%| | 971/262387 [00:27<1:53:43, 38.31it/s, Loss: 7.556 (17.65\u001b[A\n",
      "Train(0):   0%| | 972/262387 [00:27<1:53:43, 38.31it/s, Loss: 21.351 (17.6\u001b[A\n",
      "Train(0):   0%| | 973/262387 [00:27<1:56:44, 37.32it/s, Loss: 21.351 (17.6\u001b[A\n",
      "Train(0):   0%| | 973/262387 [00:27<1:56:44, 37.32it/s, Loss: 12.737 (17.6\u001b[A\n",
      "Train(0):   0%| | 974/262387 [00:27<1:56:44, 37.32it/s, Loss: 7.286 (17.64\u001b[A\n",
      "Train(0):   0%| | 975/262387 [00:27<1:56:44, 37.32it/s, Loss: 7.129 (17.63\u001b[A\n",
      "Train(0):   0%| | 976/262387 [00:27<1:56:44, 37.32it/s, Loss: 15.064 (17.6\u001b[A\n",
      "Train(0):   0%| | 977/262387 [00:27<1:56:44, 37.32it/s, Loss: 10.896 (17.6\u001b[A\n",
      "Train(0):   0%| | 978/262387 [00:27<1:50:43, 39.35it/s, Loss: 10.896 (17.6\u001b[A\n",
      "Train(0):   0%| | 978/262387 [00:27<1:50:43, 39.35it/s, Loss: 20.304 (17.6\u001b[A\n",
      "Train(0):   0%| | 979/262387 [00:27<1:50:43, 39.35it/s, Loss: 9.696 (17.62\u001b[A\n",
      "Train(0):   0%| | 980/262387 [00:27<1:50:43, 39.35it/s, Loss: 12.731 (17.6\u001b[A\n",
      "Train(0):   0%| | 981/262387 [00:27<1:50:43, 39.35it/s, Loss: 11.071 (17.6\u001b[A\n",
      "Train(0):   0%| | 982/262387 [00:27<1:50:43, 39.35it/s, Loss: 19.743 (17.6\u001b[A\n",
      "Train(0):   0%| | 983/262387 [00:27<1:46:56, 40.74it/s, Loss: 19.743 (17.6\u001b[A\n",
      "Train(0):   0%| | 983/262387 [00:27<1:46:56, 40.74it/s, Loss: 11.857 (17.6\u001b[A\n",
      "Train(0):   0%| | 984/262387 [00:27<1:46:56, 40.74it/s, Loss: 15.747 (17.6\u001b[A\n",
      "Train(0):   0%| | 985/262387 [00:27<1:46:56, 40.74it/s, Loss: 15.651 (17.6\u001b[A\n",
      "Train(0):   0%| | 986/262387 [00:28<1:46:56, 40.74it/s, Loss: 11.680 (17.5\u001b[A\n",
      "Train(0):   0%| | 987/262387 [00:28<1:46:56, 40.74it/s, Loss: 20.034 (17.5\u001b[A\n",
      "Train(0):   0%| | 988/262387 [00:28<1:53:30, 38.38it/s, Loss: 20.034 (17.5\u001b[A\n",
      "Train(0):   0%| | 988/262387 [00:28<1:53:30, 38.38it/s, Loss: 10.826 (17.5\u001b[A\n",
      "Train(0):   0%| | 989/262387 [00:28<1:53:30, 38.38it/s, Loss: 15.518 (17.5\u001b[A\n",
      "Train(0):   0%| | 990/262387 [00:28<1:53:30, 38.38it/s, Loss: 12.516 (17.5\u001b[A\n",
      "Train(0):   0%| | 991/262387 [00:28<1:53:30, 38.38it/s, Loss: 19.870 (17.5\u001b[A\n",
      "Train(0):   0%| | 992/262387 [00:28<1:53:30, 38.38it/s, Loss: 15.167 (17.5\u001b[A\n",
      "Train(0):   0%| | 993/262387 [00:28<1:50:54, 39.28it/s, Loss: 15.167 (17.5\u001b[A\n",
      "Train(0):   0%| | 993/262387 [00:28<1:50:54, 39.28it/s, Loss: 20.827 (17.5\u001b[A\n",
      "Train(0):   0%| | 994/262387 [00:28<1:50:54, 39.28it/s, Loss: 14.530 (17.5\u001b[A\n",
      "Train(0):   0%| | 995/262387 [00:28<1:50:54, 39.28it/s, Loss: 11.697 (17.5\u001b[A\n",
      "Train(0):   0%| | 996/262387 [00:28<1:50:54, 39.28it/s, Loss: 15.585 (17.5\u001b[A\n",
      "Train(0):   0%| | 997/262387 [00:28<1:51:29, 39.07it/s, Loss: 15.585 (17.5\u001b[A\n",
      "Train(0):   0%| | 997/262387 [00:28<1:51:29, 39.07it/s, Loss: 8.524 (17.56\u001b[A\n",
      "Train(0):   0%| | 998/262387 [00:28<1:51:29, 39.07it/s, Loss: 8.036 (17.55\u001b[A\n",
      "Train(0):   0%| | 999/262387 [00:28<1:51:29, 39.07it/s, Loss: 13.920 (17.5\u001b[A\n",
      "Train(0):   0%| | 1000/262387 [00:28<1:51:29, 39.07it/s, Loss: 20.029 (17.\u001b[A\n",
      "Train(0):   0%| | 1001/262387 [00:28<2:08:32, 33.89it/s, Loss: 20.029 (17.\u001b[A\n",
      "Train(0):   0%| | 1001/262387 [00:28<2:08:32, 33.89it/s, Loss: 13.891 (17.\u001b[A\n",
      "Train(0):   0%| | 1002/262387 [00:28<2:08:32, 33.89it/s, Loss: 15.230 (17.\u001b[A\n",
      "Train(0):   0%| | 1003/262387 [00:28<2:08:32, 33.89it/s, Loss: 19.035 (17.\u001b[A\n",
      "Train(0):   0%| | 1004/262387 [00:28<2:08:32, 33.89it/s, Loss: 9.713 (17.5\u001b[A\n",
      "Train(0):   0%| | 1005/262387 [00:28<2:08:32, 33.89it/s, Loss: 14.054 (17.\u001b[A\n",
      "Train(0):   0%| | 1006/262387 [00:28<2:08:32, 33.89it/s, Loss: 14.515 (17.\u001b[A\n",
      "Train(0):   0%| | 1007/262387 [00:28<1:52:37, 38.68it/s, Loss: 14.515 (17.\u001b[A\n",
      "Train(0):   0%| | 1007/262387 [00:28<1:52:37, 38.68it/s, Loss: 10.834 (17.\u001b[A\n",
      "Train(0):   0%| | 1008/262387 [00:28<1:52:37, 38.68it/s, Loss: 15.157 (17.\u001b[A\n",
      "Train(0):   0%| | 1009/262387 [00:28<1:52:37, 38.68it/s, Loss: 9.153 (17.5\u001b[A\n",
      "Train(0):   0%| | 1010/262387 [00:28<1:52:37, 38.68it/s, Loss: 11.568 (17.\u001b[A\n",
      "Train(0):   0%| | 1011/262387 [00:28<1:58:14, 36.84it/s, Loss: 11.568 (17.\u001b[A\n",
      "Train(0):   0%| | 1011/262387 [00:28<1:58:14, 36.84it/s, Loss: 8.271 (17.5\u001b[A\n",
      "Train(0):   0%| | 1012/262387 [00:28<1:58:14, 36.84it/s, Loss: 12.897 (17.\u001b[A\n",
      "Train(0):   0%| | 1013/262387 [00:28<1:58:14, 36.84it/s, Loss: 13.992 (17.\u001b[A\n",
      "Train(0):   0%| | 1014/262387 [00:28<1:58:14, 36.84it/s, Loss: 19.550 (17.\u001b[A\n",
      "Train(0):   0%| | 1015/262387 [00:28<1:57:25, 37.10it/s, Loss: 19.550 (17.\u001b[A\n",
      "Train(0):   0%| | 1015/262387 [00:28<1:57:25, 37.10it/s, Loss: 14.464 (17.\u001b[A\n",
      "Train(0):   0%| | 1016/262387 [00:28<1:57:25, 37.10it/s, Loss: 16.567 (17.\u001b[A\n",
      "Train(0):   0%| | 1017/262387 [00:28<1:57:25, 37.10it/s, Loss: 8.228 (17.4\u001b[A\n",
      "Train(0):   0%| | 1018/262387 [00:28<1:57:25, 37.10it/s, Loss: 7.770 (17.4\u001b[A\n",
      "Train(0):   0%| | 1019/262387 [00:28<1:56:33, 37.37it/s, Loss: 7.770 (17.4\u001b[A\n",
      "Train(0):   0%| | 1019/262387 [00:28<1:56:33, 37.37it/s, Loss: 17.039 (17.\u001b[A\n",
      "Train(0):   0%| | 1020/262387 [00:28<1:56:33, 37.37it/s, Loss: 10.883 (17.\u001b[A\n",
      "Train(0):   0%| | 1021/262387 [00:28<1:56:33, 37.37it/s, Loss: 11.914 (17.\u001b[A\n",
      "Train(0):   0%| | 1022/262387 [00:29<1:56:33, 37.37it/s, Loss: 16.112 (17.\u001b[A\n",
      "Train(0):   0%| | 1023/262387 [00:29<1:55:34, 37.69it/s, Loss: 16.112 (17.\u001b[A\n",
      "Train(0):   0%| | 1023/262387 [00:29<1:55:34, 37.69it/s, Loss: 15.384 (17.\u001b[A\n",
      "Train(0):   0%| | 1024/262387 [00:29<1:55:34, 37.69it/s, Loss: 13.580 (17.\u001b[A\n",
      "Train(0):   0%| | 1025/262387 [00:29<1:55:34, 37.69it/s, Loss: 17.188 (17.\u001b[A\n",
      "Train(0):   0%| | 1026/262387 [00:29<1:55:34, 37.69it/s, Loss: 12.739 (17.\u001b[A\n",
      "Train(0):   0%| | 1027/262387 [00:29<1:55:06, 37.84it/s, Loss: 12.739 (17.\u001b[A\n",
      "Train(0):   0%| | 1027/262387 [00:29<1:55:06, 37.84it/s, Loss: 15.531 (17.\u001b[A\n",
      "Train(0):   0%| | 1028/262387 [00:29<1:55:06, 37.84it/s, Loss: 7.761 (17.4\u001b[A\n",
      "Train(0):   0%| | 1029/262387 [00:29<1:55:06, 37.84it/s, Loss: 16.204 (17.\u001b[A\n",
      "Train(0):   0%| | 1030/262387 [00:29<1:55:06, 37.84it/s, Loss: 12.169 (17.\u001b[A\n",
      "Train(0):   0%| | 1031/262387 [00:29<1:54:57, 37.89it/s, Loss: 12.169 (17.\u001b[A\n",
      "Train(0):   0%| | 1031/262387 [00:29<1:54:57, 37.89it/s, Loss: 19.160 (17.\u001b[A\n",
      "Train(0):   0%| | 1032/262387 [00:29<1:54:57, 37.89it/s, Loss: 15.928 (17.\u001b[A\n",
      "Train(0):   0%| | 1033/262387 [00:29<1:54:57, 37.89it/s, Loss: 17.411 (17.\u001b[A\n",
      "Train(0):   0%| | 1034/262387 [00:29<1:54:57, 37.89it/s, Loss: 14.667 (17.\u001b[A\n",
      "Train(0):   0%| | 1035/262387 [00:29<1:54:42, 37.97it/s, Loss: 14.667 (17.\u001b[A\n",
      "Train(0):   0%| | 1035/262387 [00:29<1:54:42, 37.97it/s, Loss: 5.752 (17.4\u001b[A\n",
      "Train(0):   0%| | 1036/262387 [00:29<1:54:42, 37.97it/s, Loss: 15.141 (17.\u001b[A\n",
      "Train(0):   0%| | 1037/262387 [00:29<1:54:42, 37.97it/s, Loss: 11.064 (17.\u001b[A\n",
      "Train(0):   0%| | 1038/262387 [00:29<1:54:42, 37.97it/s, Loss: 18.720 (17.\u001b[A\n",
      "Train(0):   0%| | 1039/262387 [00:29<2:00:50, 36.05it/s, Loss: 18.720 (17.\u001b[A\n",
      "Train(0):   0%| | 1039/262387 [00:29<2:00:50, 36.05it/s, Loss: 14.412 (17.\u001b[A\n",
      "Train(0):   0%| | 1040/262387 [00:29<2:00:50, 36.05it/s, Loss: 15.841 (17.\u001b[A\n",
      "Train(0):   0%| | 1041/262387 [00:29<2:00:50, 36.05it/s, Loss: 6.621 (17.3\u001b[A\n",
      "Train(0):   0%| | 1042/262387 [00:29<2:00:50, 36.05it/s, Loss: 9.280 (17.3\u001b[A\n",
      "Train(0):   0%| | 1043/262387 [00:29<1:58:36, 36.72it/s, Loss: 9.280 (17.3\u001b[A\n",
      "Train(0):   0%| | 1043/262387 [00:29<1:58:36, 36.72it/s, Loss: 15.801 (17.\u001b[A\n",
      "Train(0):   0%| | 1044/262387 [00:29<1:58:36, 36.72it/s, Loss: 19.515 (17.\u001b[A\n",
      "Train(0):   0%| | 1045/262387 [00:29<1:58:36, 36.72it/s, Loss: 13.346 (17.\u001b[A\n",
      "Train(0):   0%| | 1046/262387 [00:29<1:58:36, 36.72it/s, Loss: 9.916 (17.3\u001b[A\n",
      "Train(0):   0%| | 1047/262387 [00:29<1:57:23, 37.10it/s, Loss: 9.916 (17.3\u001b[A\n",
      "Train(0):   0%| | 1047/262387 [00:29<1:57:23, 37.10it/s, Loss: 15.247 (17.\u001b[A\n",
      "Train(0):   0%| | 1048/262387 [00:29<1:57:23, 37.10it/s, Loss: 14.702 (17.\u001b[A\n",
      "Train(0):   0%| | 1049/262387 [00:29<1:57:23, 37.10it/s, Loss: 11.506 (17.\u001b[A\n",
      "Train(0):   0%| | 1050/262387 [00:29<1:57:23, 37.10it/s, Loss: 10.669 (17.\u001b[A\n",
      "Train(0):   0%| | 1051/262387 [00:29<1:56:27, 37.40it/s, Loss: 10.669 (17.\u001b[A\n",
      "Train(0):   0%| | 1051/262387 [00:29<1:56:27, 37.40it/s, Loss: 12.798 (17.\u001b[A\n",
      "Train(0):   0%| | 1052/262387 [00:29<1:56:27, 37.40it/s, Loss: 8.392 (17.3\u001b[A\n",
      "Train(0):   0%| | 1053/262387 [00:29<1:56:27, 37.40it/s, Loss: 12.581 (17.\u001b[A\n",
      "Train(0):   0%| | 1054/262387 [00:29<1:56:26, 37.40it/s, Loss: 10.673 (17.\u001b[A\n",
      "Train(0):   0%| | 1055/262387 [00:29<1:55:32, 37.70it/s, Loss: 10.673 (17.\u001b[A\n",
      "Train(0):   0%| | 1055/262387 [00:29<1:55:32, 37.70it/s, Loss: 19.197 (17.\u001b[A\n",
      "Train(0):   0%| | 1056/262387 [00:29<1:55:32, 37.70it/s, Loss: 13.986 (17.\u001b[A\n",
      "Train(0):   0%| | 1057/262387 [00:29<1:55:32, 37.70it/s, Loss: 7.892 (17.3\u001b[A\n",
      "Train(0):   0%| | 1058/262387 [00:29<1:55:32, 37.70it/s, Loss: 7.695 (17.3\u001b[A\n",
      "Train(0):   0%| | 1059/262387 [00:30<2:01:06, 35.96it/s, Loss: 7.695 (17.3\u001b[A\n",
      "Train(0):   0%| | 1059/262387 [00:30<2:01:06, 35.96it/s, Loss: 11.915 (17.\u001b[A\n",
      "Train(0):   0%| | 1060/262387 [00:30<2:01:06, 35.96it/s, Loss: 9.647 (17.3\u001b[A\n",
      "Train(0):   0%| | 1061/262387 [00:30<2:01:06, 35.96it/s, Loss: 11.494 (17.\u001b[A\n",
      "Train(0):   0%| | 1062/262387 [00:30<2:01:06, 35.96it/s, Loss: 11.550 (17.\u001b[A\n",
      "Train(0):   0%| | 1063/262387 [00:30<1:59:09, 36.55it/s, Loss: 11.550 (17.\u001b[A\n",
      "Train(0):   0%| | 1063/262387 [00:30<1:59:09, 36.55it/s, Loss: 14.731 (17.\u001b[A\n",
      "Train(0):   0%| | 1064/262387 [00:30<1:59:09, 36.55it/s, Loss: 9.762 (17.2\u001b[A\n",
      "Train(0):   0%| | 1065/262387 [00:30<1:59:09, 36.55it/s, Loss: 19.010 (17.\u001b[A\n",
      "Train(0):   0%| | 1066/262387 [00:30<1:59:09, 36.55it/s, Loss: 15.336 (17.\u001b[A\n",
      "Train(0):   0%| | 1067/262387 [00:30<1:58:17, 36.82it/s, Loss: 15.336 (17.\u001b[A\n",
      "Train(0):   0%| | 1067/262387 [00:30<1:58:17, 36.82it/s, Loss: 11.197 (17.\u001b[A\n",
      "Train(0):   0%| | 1068/262387 [00:30<1:58:17, 36.82it/s, Loss: 9.142 (17.2\u001b[A\n",
      "Train(0):   0%| | 1069/262387 [00:30<1:58:17, 36.82it/s, Loss: 12.225 (17.\u001b[A\n",
      "Train(0):   0%| | 1070/262387 [00:30<1:58:17, 36.82it/s, Loss: 14.611 (17.\u001b[A\n",
      "Train(0):   0%| | 1071/262387 [00:30<1:57:28, 37.07it/s, Loss: 14.611 (17.\u001b[A\n",
      "Train(0):   0%| | 1071/262387 [00:30<1:57:28, 37.07it/s, Loss: 15.312 (17.\u001b[A\n",
      "Train(0):   0%| | 1072/262387 [00:30<1:57:28, 37.07it/s, Loss: 15.507 (17.\u001b[A\n",
      "Train(0):   0%| | 1073/262387 [00:30<1:57:28, 37.07it/s, Loss: 11.345 (17.\u001b[A\n",
      "Train(0):   0%| | 1074/262387 [00:30<1:57:28, 37.07it/s, Loss: 12.348 (17.\u001b[A\n",
      "Train(0):   0%| | 1075/262387 [00:30<2:01:49, 35.75it/s, Loss: 12.348 (17.\u001b[A\n",
      "Train(0):   0%| | 1075/262387 [00:30<2:01:49, 35.75it/s, Loss: 9.429 (17.2\u001b[A\n",
      "Train(0):   0%| | 1076/262387 [00:30<2:01:49, 35.75it/s, Loss: 14.667 (17.\u001b[A\n",
      "Train(0):   0%| | 1077/262387 [00:30<2:01:49, 35.75it/s, Loss: 19.647 (17.\u001b[A\n",
      "Train(0):   0%| | 1078/262387 [00:30<2:01:49, 35.75it/s, Loss: 8.415 (17.2\u001b[A\n",
      "Train(0):   0%| | 1079/262387 [00:30<1:59:49, 36.35it/s, Loss: 8.415 (17.2\u001b[A\n",
      "Train(0):   0%| | 1079/262387 [00:30<1:59:49, 36.35it/s, Loss: 9.949 (17.2\u001b[A\n",
      "Train(0):   0%| | 1080/262387 [00:30<1:59:49, 36.35it/s, Loss: 11.754 (17.\u001b[A\n",
      "Train(0):   0%| | 1081/262387 [00:30<1:59:49, 36.35it/s, Loss: 13.576 (17.\u001b[A\n",
      "Train(0):   0%| | 1082/262387 [00:30<1:59:49, 36.35it/s, Loss: 8.544 (17.2\u001b[A\n",
      "Train(0):   0%| | 1083/262387 [00:30<1:58:23, 36.79it/s, Loss: 8.544 (17.2\u001b[A\n",
      "Train(0):   0%| | 1083/262387 [00:30<1:58:23, 36.79it/s, Loss: 11.775 (17.\u001b[A\n",
      "Train(0):   0%| | 1084/262387 [00:30<1:58:23, 36.79it/s, Loss: 11.951 (17.\u001b[A\n",
      "Train(0):   0%| | 1085/262387 [00:30<1:58:23, 36.79it/s, Loss: 10.055 (17.\u001b[A\n",
      "Train(0):   0%| | 1086/262387 [00:30<1:58:23, 36.79it/s, Loss: 9.508 (17.1\u001b[A\n",
      "Train(0):   0%| | 1087/262387 [00:30<2:03:48, 35.18it/s, Loss: 9.508 (17.1\u001b[A\n",
      "Train(0):   0%| | 1087/262387 [00:30<2:03:48, 35.18it/s, Loss: 15.187 (17.\u001b[A\n",
      "Train(0):   0%| | 1088/262387 [00:30<2:03:48, 35.18it/s, Loss: 13.287 (17.\u001b[A\n",
      "Train(0):   0%| | 1089/262387 [00:30<2:03:48, 35.18it/s, Loss: 16.379 (17.\u001b[A\n",
      "Train(0):   0%| | 1090/262387 [00:30<2:03:48, 35.18it/s, Loss: 15.314 (17.\u001b[A\n",
      "Train(0):   0%| | 1091/262387 [00:30<2:00:54, 36.02it/s, Loss: 15.314 (17.\u001b[A\n",
      "Train(0):   0%| | 1091/262387 [00:30<2:00:54, 36.02it/s, Loss: 9.808 (17.1\u001b[A\n",
      "Train(0):   0%| | 1092/262387 [00:30<2:00:54, 36.02it/s, Loss: 11.140 (17.\u001b[A\n",
      "Train(0):   0%| | 1093/262387 [00:30<2:00:54, 36.02it/s, Loss: 12.090 (17.\u001b[A\n",
      "Train(0):   0%| | 1094/262387 [00:30<2:00:54, 36.02it/s, Loss: 11.399 (17.\u001b[A\n",
      "Train(0):   0%| | 1095/262387 [00:30<1:58:50, 36.65it/s, Loss: 11.399 (17.\u001b[A\n",
      "Train(0):   0%| | 1095/262387 [00:30<1:58:50, 36.65it/s, Loss: 9.122 (17.1\u001b[A\n",
      "Train(0):   0%| | 1096/262387 [00:31<1:58:50, 36.65it/s, Loss: 12.830 (17.\u001b[A\n",
      "Train(0):   0%| | 1097/262387 [00:31<1:58:50, 36.65it/s, Loss: 12.848 (17.\u001b[A\n",
      "Train(0):   0%| | 1098/262387 [00:31<1:58:50, 36.65it/s, Loss: 11.986 (17.\u001b[A\n",
      "Train(0):   0%| | 1099/262387 [00:31<1:57:54, 36.93it/s, Loss: 11.986 (17.\u001b[A\n",
      "Train(0):   0%| | 1099/262387 [00:31<1:57:54, 36.93it/s, Loss: 12.556 (17.\u001b[A\n",
      "Train(0):   0%| | 1100/262387 [00:31<1:57:54, 36.93it/s, Loss: 12.838 (17.\u001b[A\n",
      "Train(0):   0%| | 1101/262387 [00:31<1:57:54, 36.93it/s, Loss: 16.923 (17.\u001b[A\n",
      "Train(0):   0%| | 1102/262387 [00:31<1:57:54, 36.93it/s, Loss: 16.934 (17.\u001b[A\n",
      "Train(0):   0%| | 1103/262387 [00:31<2:01:18, 35.90it/s, Loss: 16.934 (17.\u001b[A\n",
      "Train(0):   0%| | 1103/262387 [00:31<2:01:18, 35.90it/s, Loss: 13.667 (17.\u001b[A\n",
      "Train(0):   0%| | 1104/262387 [00:31<2:01:18, 35.90it/s, Loss: 7.835 (17.1\u001b[A\n",
      "Train(0):   0%| | 1105/262387 [00:31<2:01:18, 35.90it/s, Loss: 12.299 (17.\u001b[A\n",
      "Train(0):   0%| | 1106/262387 [00:31<2:01:18, 35.90it/s, Loss: 12.881 (17.\u001b[A\n",
      "Train(0):   0%| | 1107/262387 [00:31<2:01:18, 35.90it/s, Loss: 11.938 (17.\u001b[A\n",
      "Train(0):   0%| | 1108/262387 [00:31<1:55:33, 37.68it/s, Loss: 11.938 (17.\u001b[A\n",
      "Train(0):   0%| | 1108/262387 [00:31<1:55:33, 37.68it/s, Loss: 13.230 (17.\u001b[A\n",
      "Train(0):   0%| | 1109/262387 [00:31<1:55:33, 37.68it/s, Loss: 7.515 (17.0\u001b[A\n",
      "Train(0):   0%| | 1110/262387 [00:31<1:55:33, 37.68it/s, Loss: 7.514 (17.0\u001b[A\n",
      "Train(0):   0%| | 1111/262387 [00:31<1:55:33, 37.68it/s, Loss: 15.483 (17.\u001b[A\n",
      "Train(0):   0%| | 1112/262387 [00:31<1:54:29, 38.03it/s, Loss: 15.483 (17.\u001b[A\n",
      "Train(0):   0%| | 1112/262387 [00:31<1:54:29, 38.03it/s, Loss: 11.179 (17.\u001b[A\n",
      "Train(0):   0%| | 1113/262387 [00:31<1:54:29, 38.03it/s, Loss: 12.144 (17.\u001b[A\n",
      "Train(0):   0%| | 1114/262387 [00:31<1:54:29, 38.03it/s, Loss: 10.669 (17.\u001b[A\n",
      "Train(0):   0%| | 1115/262387 [00:31<1:54:29, 38.03it/s, Loss: 14.581 (17.\u001b[A\n",
      "Train(0):   0%| | 1116/262387 [00:31<1:54:29, 38.03it/s, Loss: 6.550 (17.0\u001b[A\n",
      "Train(0):   0%| | 1117/262387 [00:31<1:52:25, 38.73it/s, Loss: 6.550 (17.0\u001b[A\n",
      "Train(0):   0%| | 1117/262387 [00:31<1:52:25, 38.73it/s, Loss: 6.476 (17.0\u001b[A\n",
      "Train(0):   0%| | 1118/262387 [00:31<1:52:25, 38.73it/s, Loss: 19.341 (17.\u001b[A\n",
      "Train(0):   0%| | 1119/262387 [00:31<1:52:25, 38.73it/s, Loss: 8.916 (17.0\u001b[A\n",
      "Train(0):   0%| | 1120/262387 [00:31<1:52:25, 38.73it/s, Loss: 10.304 (17.\u001b[A\n",
      "Train(0):   0%| | 1121/262387 [00:31<1:52:40, 38.65it/s, Loss: 10.304 (17.\u001b[A\n",
      "Train(0):   0%| | 1121/262387 [00:31<1:52:40, 38.65it/s, Loss: 8.938 (17.0\u001b[A\n",
      "Train(0):   0%| | 1122/262387 [00:31<1:52:40, 38.65it/s, Loss: 13.340 (17.\u001b[A\n",
      "Train(0):   0%| | 1123/262387 [00:31<1:52:40, 38.65it/s, Loss: 11.872 (17.\u001b[A\n",
      "Train(0):   0%| | 1124/262387 [00:31<1:52:39, 38.65it/s, Loss: 11.105 (17.\u001b[A\n",
      "Train(0):   0%| | 1125/262387 [00:31<1:52:36, 38.67it/s, Loss: 11.105 (17.\u001b[A\n",
      "Train(0):   0%| | 1125/262387 [00:31<1:52:36, 38.67it/s, Loss: 14.109 (17.\u001b[A\n",
      "Train(0):   0%| | 1126/262387 [00:31<1:52:36, 38.67it/s, Loss: 12.487 (17.\u001b[A\n",
      "Train(0):   0%| | 1127/262387 [00:31<1:52:36, 38.67it/s, Loss: 19.113 (17.\u001b[A\n",
      "Train(0):   0%| | 1128/262387 [00:31<1:52:36, 38.67it/s, Loss: 11.312 (17.\u001b[A\n",
      "Train(0):   0%| | 1129/262387 [00:31<1:55:57, 37.55it/s, Loss: 11.312 (17.\u001b[A\n",
      "Train(0):   0%| | 1129/262387 [00:31<1:55:57, 37.55it/s, Loss: 12.452 (17.\u001b[A\n",
      "Train(0):   0%| | 1130/262387 [00:31<1:55:57, 37.55it/s, Loss: 15.371 (17.\u001b[A\n",
      "Train(0):   0%| | 1131/262387 [00:31<1:55:57, 37.55it/s, Loss: 7.324 (16.9\u001b[A\n",
      "Train(0):   0%| | 1132/262387 [00:31<1:55:57, 37.55it/s, Loss: 13.944 (16.\u001b[A\n",
      "Train(0):   0%| | 1133/262387 [00:31<1:55:57, 37.55it/s, Loss: 19.062 (16.\u001b[A\n",
      "Train(0):   0%| | 1134/262387 [00:31<1:49:54, 39.62it/s, Loss: 19.062 (16.\u001b[A\n",
      "Train(0):   0%| | 1134/262387 [00:32<1:49:54, 39.62it/s, Loss: 6.938 (16.9\u001b[A\n",
      "Train(0):   0%| | 1135/262387 [00:32<1:49:54, 39.62it/s, Loss: 10.437 (16.\u001b[A\n",
      "Train(0):   0%| | 1136/262387 [00:32<1:49:54, 39.62it/s, Loss: 10.829 (16.\u001b[A\n",
      "Train(0):   0%| | 1137/262387 [00:32<1:49:54, 39.62it/s, Loss: 15.971 (16.\u001b[A\n",
      "Train(0):   0%| | 1138/262387 [00:32<1:51:09, 39.17it/s, Loss: 15.971 (16.\u001b[A\n",
      "Train(0):   0%| | 1138/262387 [00:32<1:51:09, 39.17it/s, Loss: 10.073 (16.\u001b[A\n",
      "Train(0):   0%| | 1139/262387 [00:32<1:51:09, 39.17it/s, Loss: 16.705 (16.\u001b[A\n",
      "Train(0):   0%| | 1140/262387 [00:32<1:51:09, 39.17it/s, Loss: 17.762 (16.\u001b[A\n",
      "Train(0):   0%| | 1141/262387 [00:32<1:51:09, 39.17it/s, Loss: 7.608 (16.9\u001b[A\n",
      "Train(0):   0%| | 1142/262387 [00:32<1:51:47, 38.95it/s, Loss: 7.608 (16.9\u001b[A\n",
      "Train(0):   0%| | 1142/262387 [00:32<1:51:47, 38.95it/s, Loss: 12.771 (16.\u001b[A\n",
      "Train(0):   0%| | 1143/262387 [00:32<1:51:47, 38.95it/s, Loss: 10.760 (16.\u001b[A\n",
      "Train(0):   0%| | 1144/262387 [00:32<1:51:47, 38.95it/s, Loss: 13.738 (16.\u001b[A\n",
      "Train(0):   0%| | 1145/262387 [00:32<1:51:47, 38.95it/s, Loss: 11.128 (16.\u001b[A\n",
      "Train(0):   0%| | 1146/262387 [00:32<1:52:34, 38.68it/s, Loss: 11.128 (16.\u001b[A\n",
      "Train(0):   0%| | 1146/262387 [00:32<1:52:34, 38.68it/s, Loss: 13.423 (16.\u001b[A\n",
      "Train(0):   0%| | 1147/262387 [00:32<1:52:34, 38.68it/s, Loss: 18.623 (16.\u001b[A\n",
      "Train(0):   0%| | 1148/262387 [00:32<1:52:34, 38.68it/s, Loss: 9.560 (16.9\u001b[A\n",
      "Train(0):   0%| | 1149/262387 [00:32<1:52:34, 38.68it/s, Loss: 9.805 (16.9\u001b[A\n",
      "Train(0):   0%| | 1150/262387 [00:32<1:54:19, 38.08it/s, Loss: 9.805 (16.9\u001b[A\n",
      "Train(0):   0%| | 1150/262387 [00:32<1:54:19, 38.08it/s, Loss: 11.523 (16.\u001b[A\n",
      "Train(0):   0%| | 1151/262387 [00:32<1:54:19, 38.08it/s, Loss: 15.388 (16.\u001b[A\n",
      "Train(0):   0%| | 1152/262387 [00:32<1:54:19, 38.08it/s, Loss: 14.116 (16.\u001b[A\n",
      "Train(0):   0%| | 1153/262387 [00:32<1:54:19, 38.08it/s, Loss: 11.620 (16.\u001b[A\n",
      "Train(0):   0%| | 1154/262387 [00:32<1:55:05, 37.83it/s, Loss: 11.620 (16.\u001b[A\n",
      "Train(0):   0%| | 1154/262387 [00:32<1:55:05, 37.83it/s, Loss: 6.559 (16.9\u001b[A\n",
      "Train(0):   0%| | 1155/262387 [00:32<1:55:05, 37.83it/s, Loss: 18.512 (16.\u001b[A\n",
      "Train(0):   0%| | 1156/262387 [00:32<1:55:05, 37.83it/s, Loss: 9.241 (16.9\u001b[A\n",
      "Train(0):   0%| | 1157/262387 [00:32<1:55:05, 37.83it/s, Loss: 7.010 (16.8\u001b[A\n",
      "Train(0):   0%| | 1158/262387 [00:32<1:55:05, 37.83it/s, Loss: 12.312 (16.\u001b[A\n",
      "Train(0):   0%| | 1159/262387 [00:32<1:48:58, 39.95it/s, Loss: 12.312 (16.\u001b[A\n",
      "Train(0):   0%| | 1159/262387 [00:32<1:48:58, 39.95it/s, Loss: 9.593 (16.8\u001b[A\n",
      "Train(0):   0%| | 1160/262387 [00:32<1:48:58, 39.95it/s, Loss: 9.850 (16.8\u001b[A\n",
      "Train(0):   0%| | 1161/262387 [00:32<1:48:58, 39.95it/s, Loss: 15.048 (16.\u001b[A\n",
      "Train(0):   0%| | 1162/262387 [00:32<1:48:58, 39.95it/s, Loss: 10.289 (16.\u001b[A\n",
      "Train(0):   0%| | 1163/262387 [00:32<1:50:12, 39.51it/s, Loss: 10.289 (16.\u001b[A\n",
      "Train(0):   0%| | 1163/262387 [00:32<1:50:12, 39.51it/s, Loss: 14.979 (16.\u001b[A\n",
      "Train(0):   0%| | 1164/262387 [00:32<1:50:12, 39.51it/s, Loss: 10.156 (16.\u001b[A\n",
      "Train(0):   0%| | 1165/262387 [00:32<1:50:12, 39.51it/s, Loss: 15.073 (16.\u001b[A\n",
      "Train(0):   0%| | 1166/262387 [00:32<1:50:12, 39.51it/s, Loss: 14.615 (16.\u001b[A\n",
      "Train(0):   0%| | 1167/262387 [00:32<1:50:12, 39.51it/s, Loss: 17.781 (16.\u001b[A\n",
      "Train(0):   0%| | 1168/262387 [00:32<1:54:59, 37.86it/s, Loss: 17.781 (16.\u001b[A\n",
      "Train(0):   0%| | 1168/262387 [00:32<1:54:59, 37.86it/s, Loss: 8.777 (16.8\u001b[A\n",
      "Train(0):   0%| | 1169/262387 [00:32<1:54:59, 37.86it/s, Loss: 14.978 (16.\u001b[A\n",
      "Train(0):   0%| | 1170/262387 [00:32<1:54:59, 37.86it/s, Loss: 17.254 (16.\u001b[A\n",
      "Train(0):   0%| | 1171/262387 [00:32<1:54:59, 37.86it/s, Loss: 18.126 (16.\u001b[A\n",
      "Train(0):   0%| | 1172/262387 [00:32<1:53:48, 38.25it/s, Loss: 18.126 (16.\u001b[A\n",
      "Train(0):   0%| | 1172/262387 [00:32<1:53:48, 38.25it/s, Loss: 10.375 (16.\u001b[A\n",
      "Train(0):   0%| | 1173/262387 [00:33<1:53:48, 38.25it/s, Loss: 14.872 (16.\u001b[A\n",
      "Train(0):   0%| | 1174/262387 [00:33<1:53:48, 38.25it/s, Loss: 12.712 (16.\u001b[A\n",
      "Train(0):   0%| | 1175/262387 [00:33<1:53:48, 38.25it/s, Loss: 14.582 (16.\u001b[A\n",
      "Train(0):   0%| | 1176/262387 [00:33<1:53:49, 38.25it/s, Loss: 14.582 (16.\u001b[A\n",
      "Train(0):   0%| | 1176/262387 [00:33<1:53:49, 38.25it/s, Loss: 14.968 (16.\u001b[A\n",
      "Train(0):   0%| | 1177/262387 [00:33<1:53:49, 38.25it/s, Loss: 14.900 (16.\u001b[A\n",
      "Train(0):   0%| | 1178/262387 [00:33<1:53:49, 38.25it/s, Loss: 15.601 (16.\u001b[A\n",
      "Train(0):   0%| | 1179/262387 [00:33<1:53:49, 38.25it/s, Loss: 7.687 (16.8\u001b[A\n",
      "Train(0):   0%| | 1180/262387 [00:33<1:57:40, 37.00it/s, Loss: 7.687 (16.8\u001b[A\n",
      "Train(0):   0%| | 1180/262387 [00:33<1:57:40, 37.00it/s, Loss: 14.940 (16.\u001b[A\n",
      "Train(0):   0%| | 1181/262387 [00:33<1:57:40, 37.00it/s, Loss: 16.054 (16.\u001b[A\n",
      "Train(0):   0%| | 1182/262387 [00:33<1:57:40, 37.00it/s, Loss: 14.062 (16.\u001b[A\n",
      "Train(0):   0%| | 1183/262387 [00:33<1:57:40, 37.00it/s, Loss: 11.744 (16.\u001b[A\n",
      "Train(0):   0%| | 1184/262387 [00:33<1:56:07, 37.49it/s, Loss: 11.744 (16.\u001b[A\n",
      "Train(0):   0%| | 1184/262387 [00:33<1:56:07, 37.49it/s, Loss: 10.023 (16.\u001b[A\n",
      "Train(0):   0%| | 1185/262387 [00:33<1:56:07, 37.49it/s, Loss: 15.175 (16.\u001b[A\n",
      "Train(0):   0%| | 1186/262387 [00:33<1:56:07, 37.49it/s, Loss: 11.632 (16.\u001b[A\n",
      "Train(0):   0%| | 1187/262387 [00:33<1:56:07, 37.49it/s, Loss: 8.651 (16.7\u001b[A\n",
      "Train(0):   0%| | 1188/262387 [00:33<2:00:02, 36.26it/s, Loss: 8.651 (16.7\u001b[A\n",
      "Train(0):   0%| | 1188/262387 [00:33<2:00:02, 36.26it/s, Loss: 12.674 (16.\u001b[A\n",
      "Train(0):   0%| | 1189/262387 [00:33<2:00:02, 36.26it/s, Loss: 8.693 (16.7\u001b[A\n",
      "Train(0):   0%| | 1190/262387 [00:33<2:00:02, 36.26it/s, Loss: 7.966 (16.7\u001b[A\n",
      "Train(0):   0%| | 1191/262387 [00:33<2:00:02, 36.26it/s, Loss: 11.746 (16.\u001b[A\n",
      "Train(0):   0%| | 1192/262387 [00:33<1:58:11, 36.83it/s, Loss: 11.746 (16.\u001b[A\n",
      "Train(0):   0%| | 1192/262387 [00:33<1:58:11, 36.83it/s, Loss: 11.131 (16.\u001b[A\n",
      "Train(0):   0%| | 1193/262387 [00:33<1:58:11, 36.83it/s, Loss: 13.800 (16.\u001b[A\n",
      "Train(0):   0%| | 1194/262387 [00:33<1:58:11, 36.83it/s, Loss: 15.314 (16.\u001b[A\n",
      "Train(0):   0%| | 1195/262387 [00:33<1:58:11, 36.83it/s, Loss: 13.565 (16.\u001b[A\n",
      "Train(0):   0%| | 1196/262387 [00:33<2:02:53, 35.43it/s, Loss: 13.565 (16.\u001b[A\n",
      "Train(0):   0%| | 1196/262387 [00:33<2:02:53, 35.43it/s, Loss: 10.983 (16.\u001b[A\n",
      "Train(0):   0%| | 1197/262387 [00:33<2:02:52, 35.43it/s, Loss: 9.073 (16.7\u001b[A\n",
      "Train(0):   0%| | 1198/262387 [00:33<2:02:52, 35.43it/s, Loss: 12.479 (16.\u001b[A\n",
      "Train(0):   0%| | 1199/262387 [00:33<2:02:52, 35.43it/s, Loss: 10.021 (16.\u001b[A\n",
      "Train(0):   0%| | 1200/262387 [00:33<2:01:27, 35.84it/s, Loss: 10.021 (16.\u001b[A\n",
      "Train(0):   0%| | 1200/262387 [00:33<2:01:27, 35.84it/s, Loss: 7.349 (16.7\u001b[A\n",
      "Train(0):   0%| | 1201/262387 [00:33<2:01:27, 35.84it/s, Loss: 9.231 (16.7\u001b[A\n",
      "Train(0):   0%| | 1202/262387 [00:33<2:01:27, 35.84it/s, Loss: 11.559 (16.\u001b[A\n",
      "Train(0):   0%| | 1203/262387 [00:33<2:01:27, 35.84it/s, Loss: 6.277 (16.7\u001b[A\n",
      "Train(0):   0%| | 1204/262387 [00:33<1:58:51, 36.62it/s, Loss: 6.277 (16.7\u001b[A\n",
      "Train(0):   0%| | 1204/262387 [00:33<1:58:51, 36.62it/s, Loss: 6.852 (16.7\u001b[A\n",
      "Train(0):   0%| | 1205/262387 [00:33<1:58:51, 36.62it/s, Loss: 15.068 (16.\u001b[A\n",
      "Train(0):   0%| | 1206/262387 [00:33<1:58:51, 36.62it/s, Loss: 7.899 (16.7\u001b[A\n",
      "Train(0):   0%| | 1207/262387 [00:33<1:58:51, 36.62it/s, Loss: 10.709 (16.\u001b[A\n",
      "Train(0):   0%| | 1208/262387 [00:33<1:57:27, 37.06it/s, Loss: 10.709 (16.\u001b[A\n",
      "Train(0):   0%| | 1208/262387 [00:33<1:57:27, 37.06it/s, Loss: 11.938 (16.\u001b[A\n",
      "Train(0):   0%| | 1209/262387 [00:34<1:57:27, 37.06it/s, Loss: 8.893 (16.6\u001b[A\n",
      "Train(0):   0%| | 1210/262387 [00:34<1:57:27, 37.06it/s, Loss: 19.392 (16.\u001b[A\n",
      "Train(0):   0%| | 1211/262387 [00:34<1:57:27, 37.06it/s, Loss: 6.941 (16.6\u001b[A\n",
      "Train(0):   0%| | 1212/262387 [00:34<1:56:36, 37.33it/s, Loss: 6.941 (16.6\u001b[A\n",
      "Train(0):   0%| | 1212/262387 [00:34<1:56:36, 37.33it/s, Loss: 11.309 (16.\u001b[A\n",
      "Train(0):   0%| | 1213/262387 [00:34<1:56:36, 37.33it/s, Loss: 11.389 (16.\u001b[A\n",
      "Train(0):   0%| | 1214/262387 [00:34<1:56:36, 37.33it/s, Loss: 17.129 (16.\u001b[A\n",
      "Train(0):   0%| | 1215/262387 [00:34<1:56:36, 37.33it/s, Loss: 9.819 (16.6\u001b[A\n",
      "Train(0):   0%| | 1216/262387 [00:34<1:56:01, 37.52it/s, Loss: 9.819 (16.6\u001b[A\n",
      "Train(0):   0%| | 1216/262387 [00:34<1:56:01, 37.52it/s, Loss: 13.781 (16.\u001b[A\n",
      "Train(0):   0%| | 1217/262387 [00:34<1:56:01, 37.52it/s, Loss: 12.924 (16.\u001b[A\n",
      "Train(0):   0%| | 1218/262387 [00:34<1:56:01, 37.52it/s, Loss: 7.405 (16.6\u001b[A\n",
      "Train(0):   0%| | 1219/262387 [00:34<1:56:01, 37.52it/s, Loss: 10.281 (16.\u001b[A\n",
      "Train(0):   0%| | 1220/262387 [00:34<1:55:14, 37.77it/s, Loss: 10.281 (16.\u001b[A\n",
      "Train(0):   0%| | 1220/262387 [00:34<1:55:14, 37.77it/s, Loss: 16.677 (16.\u001b[A\n",
      "Train(0):   0%| | 1221/262387 [00:34<1:55:14, 37.77it/s, Loss: 13.291 (16.\u001b[A\n",
      "Train(0):   0%| | 1222/262387 [00:34<1:55:14, 37.77it/s, Loss: 16.593 (16.\u001b[A\n",
      "Train(0):   0%| | 1223/262387 [00:34<1:55:14, 37.77it/s, Loss: 17.946 (16.\u001b[A\n",
      "Train(0):   0%| | 1224/262387 [00:34<1:54:44, 37.93it/s, Loss: 17.946 (16.\u001b[A\n",
      "Train(0):   0%| | 1224/262387 [00:34<1:54:44, 37.93it/s, Loss: 7.896 (16.6\u001b[A\n",
      "Train(0):   0%| | 1225/262387 [00:34<1:54:44, 37.93it/s, Loss: 12.401 (16.\u001b[A\n",
      "Train(0):   0%| | 1226/262387 [00:34<1:54:44, 37.93it/s, Loss: 9.542 (16.6\u001b[A\n",
      "Train(0):   0%| | 1227/262387 [00:34<1:54:44, 37.93it/s, Loss: 10.836 (16.\u001b[A\n",
      "Train(0):   0%| | 1228/262387 [00:34<1:54:35, 37.99it/s, Loss: 10.836 (16.\u001b[A\n",
      "Train(0):   0%| | 1228/262387 [00:34<1:54:35, 37.99it/s, Loss: 8.418 (16.6\u001b[A\n",
      "Train(0):   0%| | 1229/262387 [00:34<1:54:35, 37.99it/s, Loss: 12.370 (16.\u001b[A\n",
      "Train(0):   0%| | 1230/262387 [00:34<1:54:35, 37.99it/s, Loss: 11.224 (16.\u001b[A\n",
      "Train(0):   0%| | 1231/262387 [00:34<1:54:35, 37.99it/s, Loss: 16.182 (16.\u001b[A\n",
      "Train(0):   0%| | 1232/262387 [00:34<1:54:34, 37.99it/s, Loss: 16.182 (16.\u001b[A\n",
      "Train(0):   0%| | 1232/262387 [00:34<1:54:34, 37.99it/s, Loss: 5.999 (16.6\u001b[A\n",
      "Train(0):   0%| | 1233/262387 [00:34<1:54:34, 37.99it/s, Loss: 10.228 (16.\u001b[A\n",
      "Train(0):   0%| | 1234/262387 [00:34<1:54:34, 37.99it/s, Loss: 9.906 (16.5\u001b[A\n",
      "Train(0):   0%| | 1235/262387 [00:34<1:54:34, 37.99it/s, Loss: 6.984 (16.5\u001b[A\n",
      "Train(0):   0%| | 1236/262387 [00:34<1:58:29, 36.73it/s, Loss: 6.984 (16.5\u001b[A\n",
      "Train(0):   0%| | 1236/262387 [00:34<1:58:29, 36.73it/s, Loss: 7.370 (16.5\u001b[A\n",
      "Train(0):   0%| | 1237/262387 [00:34<1:58:29, 36.73it/s, Loss: 15.221 (16.\u001b[A\n",
      "Train(0):   0%| | 1238/262387 [00:34<1:58:29, 36.73it/s, Loss: 15.764 (16.\u001b[A\n",
      "Train(0):   0%| | 1239/262387 [00:34<1:58:28, 36.73it/s, Loss: 11.056 (16.\u001b[A\n",
      "Train(0):   0%| | 1240/262387 [00:34<1:58:28, 36.73it/s, Loss: 16.596 (16.\u001b[A\n",
      "Train(0):   0%| | 1241/262387 [00:34<1:54:01, 38.17it/s, Loss: 16.596 (16.\u001b[A\n",
      "Train(0):   0%| | 1241/262387 [00:34<1:54:01, 38.17it/s, Loss: 11.548 (16.\u001b[A\n",
      "Train(0):   0%| | 1242/262387 [00:34<1:54:01, 38.17it/s, Loss: 9.139 (16.5\u001b[A\n",
      "Train(0):   0%| | 1243/262387 [00:34<1:54:01, 38.17it/s, Loss: 10.980 (16.\u001b[A\n",
      "Train(0):   0%| | 1244/262387 [00:34<1:54:01, 38.17it/s, Loss: 15.574 (16.\u001b[A\n",
      "Train(0):   0%| | 1245/262387 [00:34<1:55:29, 37.69it/s, Loss: 15.574 (16.\u001b[A\n",
      "Train(0):   0%| | 1245/262387 [00:34<1:55:29, 37.69it/s, Loss: 12.258 (16.\u001b[A\n",
      "Train(0):   0%| | 1246/262387 [00:34<1:55:29, 37.69it/s, Loss: 11.367 (16.\u001b[A\n",
      "Train(0):   0%| | 1247/262387 [00:35<1:55:29, 37.69it/s, Loss: 11.231 (16.\u001b[A\n",
      "Train(0):   0%| | 1248/262387 [00:35<1:55:29, 37.69it/s, Loss: 14.233 (16.\u001b[A\n",
      "Train(0):   0%| | 1249/262387 [00:35<1:55:19, 37.74it/s, Loss: 14.233 (16.\u001b[A\n",
      "Train(0):   0%| | 1249/262387 [00:35<1:55:19, 37.74it/s, Loss: 15.945 (16.\u001b[A\n",
      "Train(0):   0%| | 1250/262387 [00:35<1:55:19, 37.74it/s, Loss: 13.385 (16.\u001b[A\n",
      "Train(0):   0%| | 1251/262387 [00:35<1:55:19, 37.74it/s, Loss: 8.141 (16.5\u001b[A\n",
      "Train(0):   0%| | 1252/262387 [00:35<1:55:19, 37.74it/s, Loss: 9.389 (16.5\u001b[A\n",
      "Train(0):   0%| | 1253/262387 [00:35<1:54:51, 37.89it/s, Loss: 9.389 (16.5\u001b[A\n",
      "Train(0):   0%| | 1253/262387 [00:35<1:54:51, 37.89it/s, Loss: 13.358 (16.\u001b[A\n",
      "Train(0):   0%| | 1254/262387 [00:35<1:54:51, 37.89it/s, Loss: 8.289 (16.5\u001b[A\n",
      "Train(0):   0%| | 1255/262387 [00:35<1:54:51, 37.89it/s, Loss: 11.064 (16.\u001b[A\n",
      "Train(0):   0%| | 1256/262387 [00:35<1:54:51, 37.89it/s, Loss: 13.335 (16.\u001b[A\n",
      "Train(0):   0%| | 1257/262387 [00:35<1:54:10, 38.12it/s, Loss: 13.335 (16.\u001b[A\n",
      "Train(0):   0%| | 1257/262387 [00:35<1:54:10, 38.12it/s, Loss: 14.193 (16.\u001b[A\n",
      "Train(0):   0%| | 1258/262387 [00:35<1:54:10, 38.12it/s, Loss: 16.205 (16.\u001b[A\n",
      "Train(0):   0%| | 1259/262387 [00:35<1:54:10, 38.12it/s, Loss: 14.809 (16.\u001b[A\n",
      "Train(0):   0%| | 1260/262387 [00:35<1:54:10, 38.12it/s, Loss: 14.915 (16.\u001b[A\n",
      "Train(0):   0%| | 1261/262387 [00:35<1:54:10, 38.12it/s, Loss: 14.915 (16.\u001b[A\n",
      "Train(0):   0%| | 1261/262387 [00:35<1:54:10, 38.12it/s, Loss: 18.280 (16.\u001b[A\n",
      "Train(0):   0%| | 1262/262387 [00:35<1:54:10, 38.12it/s, Loss: 14.195 (16.\u001b[A\n",
      "Train(0):   0%| | 1263/262387 [00:35<1:54:10, 38.12it/s, Loss: 9.633 (16.4\u001b[A\n",
      "Train(0):   0%| | 1264/262387 [00:35<1:54:10, 38.12it/s, Loss: 16.692 (16.\u001b[A\n",
      "Train(0):   0%| | 1265/262387 [00:35<1:53:28, 38.35it/s, Loss: 16.692 (16.\u001b[A\n",
      "Train(0):   0%| | 1265/262387 [00:35<1:53:28, 38.35it/s, Loss: 18.844 (16.\u001b[A\n",
      "Train(0):   0%| | 1266/262387 [00:35<1:53:28, 38.35it/s, Loss: 14.045 (16.\u001b[A\n",
      "Train(0):   0%| | 1267/262387 [00:35<1:53:28, 38.35it/s, Loss: 10.175 (16.\u001b[A\n",
      "Train(0):   0%| | 1268/262387 [00:35<1:53:28, 38.35it/s, Loss: 17.497 (16.\u001b[A\n",
      "Train(0):   0%| | 1269/262387 [00:35<1:53:28, 38.35it/s, Loss: 8.919 (16.4\u001b[A\n",
      "Train(0):   0%| | 1270/262387 [00:35<1:48:32, 40.09it/s, Loss: 8.919 (16.4\u001b[A\n",
      "Train(0):   0%| | 1270/262387 [00:35<1:48:32, 40.09it/s, Loss: 8.458 (16.4\u001b[A\n",
      "Train(0):   0%| | 1271/262387 [00:35<1:48:32, 40.09it/s, Loss: 9.702 (16.4\u001b[A\n",
      "Train(0):   0%| | 1272/262387 [00:35<1:48:32, 40.09it/s, Loss: 10.752 (16.\u001b[A\n",
      "Train(0):   0%| | 1273/262387 [00:35<1:48:32, 40.09it/s, Loss: 14.416 (16.\u001b[A\n",
      "Train(0):   0%| | 1274/262387 [00:35<1:48:32, 40.09it/s, Loss: 11.508 (16.\u001b[A\n",
      "Train(0):   0%| | 1275/262387 [00:35<1:51:03, 39.19it/s, Loss: 11.508 (16.\u001b[A\n",
      "Train(0):   0%| | 1275/262387 [00:35<1:51:03, 39.19it/s, Loss: 10.647 (16.\u001b[A\n",
      "Train(0):   0%| | 1276/262387 [00:35<1:51:03, 39.19it/s, Loss: 12.242 (16.\u001b[A\n",
      "Train(0):   0%| | 1277/262387 [00:35<1:51:02, 39.19it/s, Loss: 14.958 (16.\u001b[A\n",
      "Train(0):   0%| | 1278/262387 [00:35<1:51:02, 39.19it/s, Loss: 17.635 (16.\u001b[A\n",
      "Train(0):   0%| | 1279/262387 [00:35<1:52:21, 38.73it/s, Loss: 17.635 (16.\u001b[A\n",
      "Train(0):   0%| | 1279/262387 [00:35<1:52:21, 38.73it/s, Loss: 13.149 (16.\u001b[A\n",
      "Train(0):   0%| | 1280/262387 [00:35<1:52:21, 38.73it/s, Loss: 9.849 (16.4\u001b[A\n",
      "Train(0):   0%| | 1281/262387 [00:35<1:52:21, 38.73it/s, Loss: 7.862 (16.4\u001b[A\n",
      "Train(0):   0%| | 1282/262387 [00:35<1:52:21, 38.73it/s, Loss: 8.546 (16.4\u001b[A\n",
      "Train(0):   0%| | 1283/262387 [00:35<1:51:53, 38.89it/s, Loss: 8.546 (16.4\u001b[A\n",
      "Train(0):   0%| | 1283/262387 [00:35<1:51:53, 38.89it/s, Loss: 10.498 (16.\u001b[A\n",
      "Train(0):   0%| | 1284/262387 [00:35<1:51:53, 38.89it/s, Loss: 14.085 (16.\u001b[A\n",
      "Train(0):   0%| | 1285/262387 [00:35<1:51:53, 38.89it/s, Loss: 6.379 (16.4\u001b[A\n",
      "Train(0):   0%| | 1286/262387 [00:36<1:51:53, 38.89it/s, Loss: 11.376 (16.\u001b[A\n",
      "Train(0):   0%| | 1287/262387 [00:36<1:56:00, 37.51it/s, Loss: 11.376 (16.\u001b[A\n",
      "Train(0):   0%| | 1287/262387 [00:36<1:56:00, 37.51it/s, Loss: 15.888 (16.\u001b[A\n",
      "Train(0):   0%| | 1288/262387 [00:36<1:56:00, 37.51it/s, Loss: 14.289 (16.\u001b[A\n",
      "Train(0):   0%| | 1289/262387 [00:36<1:56:00, 37.51it/s, Loss: 11.397 (16.\u001b[A\n",
      "Train(0):   0%| | 1290/262387 [00:36<1:56:00, 37.51it/s, Loss: 10.188 (16.\u001b[A\n",
      "Train(0):   0%| | 1291/262387 [00:36<1:56:00, 37.51it/s, Loss: 9.249 (16.4\u001b[A\n",
      "Train(0):   0%| | 1292/262387 [00:36<1:50:54, 39.24it/s, Loss: 9.249 (16.4\u001b[A\n",
      "Train(0):   0%| | 1292/262387 [00:36<1:50:54, 39.24it/s, Loss: 13.610 (16.\u001b[A\n",
      "Train(0):   0%| | 1293/262387 [00:36<1:50:54, 39.24it/s, Loss: 6.234 (16.3\u001b[A\n",
      "Train(0):   0%| | 1294/262387 [00:36<1:50:54, 39.24it/s, Loss: 16.439 (16.\u001b[A\n",
      "Train(0):   0%| | 1295/262387 [00:36<1:50:54, 39.24it/s, Loss: 17.143 (16.\u001b[A\n",
      "Train(0):   0%| | 1296/262387 [00:36<1:52:32, 38.66it/s, Loss: 17.143 (16.\u001b[A\n",
      "Train(0):   0%| | 1296/262387 [00:36<1:52:32, 38.66it/s, Loss: 17.867 (16.\u001b[A\n",
      "Train(0):   0%| | 1297/262387 [00:36<1:52:32, 38.66it/s, Loss: 13.838 (16.\u001b[A\n",
      "Train(0):   0%| | 1298/262387 [00:36<1:52:32, 38.66it/s, Loss: 11.844 (16.\u001b[A\n",
      "Train(0):   0%| | 1299/262387 [00:36<1:52:32, 38.66it/s, Loss: 6.210 (16.3\u001b[A\n",
      "Train(0):   0%| | 1300/262387 [00:36<1:52:32, 38.66it/s, Loss: 8.778 (16.3\u001b[A\n",
      "Train(0):   0%| | 1301/262387 [00:36<1:46:45, 40.76it/s, Loss: 8.778 (16.3\u001b[A\n",
      "Train(0):   0%| | 1301/262387 [00:36<1:46:45, 40.76it/s, Loss: 11.666 (16.\u001b[A\n",
      "Train(0):   0%| | 1302/262387 [00:36<1:46:45, 40.76it/s, Loss: 17.237 (16.\u001b[A\n",
      "Train(0):   0%| | 1303/262387 [00:36<1:46:45, 40.76it/s, Loss: 7.346 (16.3\u001b[A\n",
      "Train(0):   0%| | 1304/262387 [00:36<1:46:45, 40.76it/s, Loss: 6.080 (16.3\u001b[A\n",
      "Train(0):   0%| | 1305/262387 [00:36<1:46:45, 40.76it/s, Loss: 11.798 (16.\u001b[A\n",
      "Train(0):   0%| | 1306/262387 [00:36<1:53:33, 38.32it/s, Loss: 11.798 (16.\u001b[A\n",
      "Train(0):   0%| | 1306/262387 [00:36<1:53:33, 38.32it/s, Loss: 13.319 (16.\u001b[A\n",
      "Train(0):   0%| | 1307/262387 [00:36<1:53:33, 38.32it/s, Loss: 9.349 (16.3\u001b[A\n",
      "Train(0):   0%| | 1308/262387 [00:36<1:53:33, 38.32it/s, Loss: 7.277 (16.3\u001b[A\n",
      "Train(0):   0%| | 1309/262387 [00:36<1:53:33, 38.32it/s, Loss: 17.619 (16.\u001b[A\n",
      "Train(0):   0%| | 1310/262387 [00:36<1:55:15, 37.75it/s, Loss: 17.619 (16.\u001b[A\n",
      "Train(0):   0%| | 1310/262387 [00:36<1:55:15, 37.75it/s, Loss: 17.089 (16.\u001b[A\n",
      "Train(0):   0%| | 1311/262387 [00:36<1:55:15, 37.75it/s, Loss: 14.254 (16.\u001b[A\n",
      "Train(0):   1%| | 1312/262387 [00:36<1:55:15, 37.75it/s, Loss: 14.215 (16.\u001b[A\n",
      "Train(0):   1%| | 1313/262387 [00:36<1:55:15, 37.75it/s, Loss: 14.112 (16.\u001b[A\n",
      "Train(0):   1%| | 1314/262387 [00:36<1:54:59, 37.84it/s, Loss: 14.112 (16.\u001b[A\n",
      "Train(0):   1%| | 1314/262387 [00:36<1:54:59, 37.84it/s, Loss: 11.886 (16.\u001b[A\n",
      "Train(0):   1%| | 1315/262387 [00:36<1:54:59, 37.84it/s, Loss: 14.410 (16.\u001b[A\n",
      "Train(0):   1%| | 1316/262387 [00:36<1:54:59, 37.84it/s, Loss: 7.493 (16.3\u001b[A\n",
      "Train(0):   1%| | 1317/262387 [00:36<1:54:59, 37.84it/s, Loss: 11.998 (16.\u001b[A\n",
      "Train(0):   1%| | 1318/262387 [00:36<1:54:59, 37.84it/s, Loss: 11.987 (16.\u001b[A\n",
      "Train(0):   1%| | 1319/262387 [00:36<1:51:53, 38.89it/s, Loss: 11.987 (16.\u001b[A\n",
      "Train(0):   1%| | 1319/262387 [00:36<1:51:53, 38.89it/s, Loss: 9.672 (16.3\u001b[A\n",
      "Train(0):   1%| | 1320/262387 [00:36<1:51:53, 38.89it/s, Loss: 14.548 (16.\u001b[A\n",
      "Train(0):   1%| | 1321/262387 [00:36<1:51:53, 38.89it/s, Loss: 6.922 (16.3\u001b[A\n",
      "Train(0):   1%| | 1322/262387 [00:36<1:51:53, 38.89it/s, Loss: 14.076 (16.\u001b[A\n",
      "Train(0):   1%| | 1323/262387 [00:36<1:58:55, 36.59it/s, Loss: 14.076 (16.\u001b[A\n",
      "Train(0):   1%| | 1323/262387 [00:36<1:58:55, 36.59it/s, Loss: 9.692 (16.2\u001b[A\n",
      "Train(0):   1%| | 1324/262387 [00:37<1:58:55, 36.59it/s, Loss: 7.691 (16.2\u001b[A\n",
      "Train(0):   1%| | 1325/262387 [00:37<1:58:55, 36.59it/s, Loss: 8.550 (16.2\u001b[A\n",
      "Train(0):   1%| | 1326/262387 [00:37<1:58:55, 36.59it/s, Loss: 11.660 (16.\u001b[A\n",
      "Train(0):   1%| | 1327/262387 [00:37<1:58:55, 36.59it/s, Loss: 9.913 (16.2\u001b[A\n",
      "Train(0):   1%| | 1328/262387 [00:37<1:50:00, 39.55it/s, Loss: 9.913 (16.2\u001b[A\n",
      "Train(0):   1%| | 1328/262387 [00:37<1:50:00, 39.55it/s, Loss: 13.146 (16.\u001b[A\n",
      "Train(0):   1%| | 1329/262387 [00:37<1:50:00, 39.55it/s, Loss: 18.306 (16.\u001b[A\n",
      "Train(0):   1%| | 1330/262387 [00:37<1:50:00, 39.55it/s, Loss: 14.277 (16.\u001b[A\n",
      "Train(0):   1%| | 1331/262387 [00:37<1:50:00, 39.55it/s, Loss: 13.903 (16.\u001b[A\n",
      "Train(0):   1%| | 1332/262387 [00:37<1:49:55, 39.58it/s, Loss: 13.903 (16.\u001b[A\n",
      "Train(0):   1%| | 1332/262387 [00:37<1:49:55, 39.58it/s, Loss: 12.117 (16.\u001b[A\n",
      "Train(0):   1%| | 1333/262387 [00:37<1:49:55, 39.58it/s, Loss: 13.297 (16.\u001b[A\n",
      "Train(0):   1%| | 1334/262387 [00:37<1:49:55, 39.58it/s, Loss: 11.426 (16.\u001b[A\n",
      "Train(0):   1%| | 1335/262387 [00:37<1:49:55, 39.58it/s, Loss: 12.764 (16.\u001b[A\n",
      "Train(0):   1%| | 1336/262387 [00:37<1:49:48, 39.62it/s, Loss: 12.764 (16.\u001b[A\n",
      "Train(0):   1%| | 1336/262387 [00:37<1:49:48, 39.62it/s, Loss: 14.342 (16.\u001b[A\n",
      "Train(0):   1%| | 1337/262387 [00:37<1:49:48, 39.62it/s, Loss: 12.036 (16.\u001b[A\n",
      "Train(0):   1%| | 1338/262387 [00:37<1:49:48, 39.62it/s, Loss: 9.074 (16.2\u001b[A\n",
      "Train(0):   1%| | 1339/262387 [00:37<1:49:48, 39.62it/s, Loss: 14.123 (16.\u001b[A\n",
      "Train(0):   1%| | 1340/262387 [00:37<2:08:21, 33.90it/s, Loss: 14.123 (16.\u001b[A\n",
      "Train(0):   1%| | 1340/262387 [00:37<2:08:21, 33.90it/s, Loss: 12.608 (16.\u001b[A\n",
      "Train(0):   1%| | 1341/262387 [00:37<2:08:21, 33.90it/s, Loss: 9.248 (16.2\u001b[A\n",
      "Train(0):   1%| | 1342/262387 [00:37<2:08:21, 33.90it/s, Loss: 17.904 (16.\u001b[A\n",
      "Train(0):   1%| | 1343/262387 [00:37<2:08:21, 33.90it/s, Loss: 11.756 (16.\u001b[A\n",
      "Train(0):   1%| | 1344/262387 [00:37<2:08:21, 33.90it/s, Loss: 14.947 (16.\u001b[A\n",
      "Train(0):   1%| | 1345/262387 [00:37<1:57:04, 37.16it/s, Loss: 14.947 (16.\u001b[A\n",
      "Train(0):   1%| | 1345/262387 [00:37<1:57:04, 37.16it/s, Loss: 11.049 (16.\u001b[A\n",
      "Train(0):   1%| | 1346/262387 [00:37<1:57:04, 37.16it/s, Loss: 14.083 (16.\u001b[A\n",
      "Train(0):   1%| | 1347/262387 [00:37<1:57:04, 37.16it/s, Loss: 12.295 (16.\u001b[A\n",
      "Train(0):   1%| | 1348/262387 [00:37<1:57:04, 37.16it/s, Loss: 14.783 (16.\u001b[A\n",
      "Train(0):   1%| | 1349/262387 [00:37<1:57:04, 37.16it/s, Loss: 10.319 (16.\u001b[A\n",
      "Train(0):   1%| | 1350/262387 [00:37<1:54:05, 38.13it/s, Loss: 10.319 (16.\u001b[A\n",
      "Train(0):   1%| | 1350/262387 [00:37<1:54:05, 38.13it/s, Loss: 7.298 (16.2\u001b[A\n",
      "Train(0):   1%| | 1351/262387 [00:37<1:54:05, 38.13it/s, Loss: 17.286 (16.\u001b[A\n",
      "Train(0):   1%| | 1352/262387 [00:37<1:54:05, 38.13it/s, Loss: 10.691 (16.\u001b[A\n",
      "Train(0):   1%| | 1353/262387 [00:37<1:54:05, 38.13it/s, Loss: 7.648 (16.2\u001b[A\n",
      "Train(0):   1%| | 1354/262387 [00:37<1:57:48, 36.93it/s, Loss: 7.648 (16.2\u001b[A\n",
      "Train(0):   1%| | 1354/262387 [00:37<1:57:48, 36.93it/s, Loss: 8.775 (16.2\u001b[A\n",
      "Train(0):   1%| | 1355/262387 [00:37<1:57:48, 36.93it/s, Loss: 9.926 (16.1\u001b[A\n",
      "Train(0):   1%| | 1356/262387 [00:37<1:57:48, 36.93it/s, Loss: 12.138 (16.\u001b[A\n",
      "Train(0):   1%| | 1357/262387 [00:37<1:57:48, 36.93it/s, Loss: 9.313 (16.1\u001b[A\n",
      "Train(0):   1%| | 1358/262387 [00:37<1:55:18, 37.73it/s, Loss: 9.313 (16.1\u001b[A\n",
      "Train(0):   1%| | 1358/262387 [00:37<1:55:18, 37.73it/s, Loss: 10.142 (16.\u001b[A\n",
      "Train(0):   1%| | 1359/262387 [00:37<1:55:18, 37.73it/s, Loss: 17.200 (16.\u001b[A\n",
      "Train(0):   1%| | 1360/262387 [00:37<1:55:18, 37.73it/s, Loss: 13.476 (16.\u001b[A\n",
      "Train(0):   1%| | 1361/262387 [00:37<1:55:18, 37.73it/s, Loss: 9.438 (16.1\u001b[A\n",
      "Train(0):   1%| | 1362/262387 [00:38<1:55:17, 37.73it/s, Loss: 16.935 (16.\u001b[A\n",
      "Train(0):   1%| | 1363/262387 [00:38<1:52:58, 38.51it/s, Loss: 16.935 (16.\u001b[A\n",
      "Train(0):   1%| | 1363/262387 [00:38<1:52:58, 38.51it/s, Loss: 14.732 (16.\u001b[A\n",
      "Train(0):   1%| | 1364/262387 [00:38<1:52:58, 38.51it/s, Loss: 8.320 (16.1\u001b[A\n",
      "Train(0):   1%| | 1365/262387 [00:38<1:52:58, 38.51it/s, Loss: 15.678 (16.\u001b[A\n",
      "Train(0):   1%| | 1366/262387 [00:38<1:52:58, 38.51it/s, Loss: 10.189 (16.\u001b[A\n",
      "Train(0):   1%| | 1367/262387 [00:38<1:51:59, 38.85it/s, Loss: 10.189 (16.\u001b[A\n",
      "Train(0):   1%| | 1367/262387 [00:38<1:51:59, 38.85it/s, Loss: 10.984 (16.\u001b[A\n",
      "Train(0):   1%| | 1368/262387 [00:38<1:51:59, 38.85it/s, Loss: 6.132 (16.1\u001b[A\n",
      "Train(0):   1%| | 1369/262387 [00:38<1:51:59, 38.85it/s, Loss: 11.280 (16.\u001b[A\n",
      "Train(0):   1%| | 1370/262387 [00:38<1:51:59, 38.85it/s, Loss: 13.612 (16.\u001b[A\n",
      "Train(0):   1%| | 1371/262387 [00:38<1:51:59, 38.85it/s, Loss: 6.711 (16.1\u001b[A\n",
      "Train(0):   1%| | 1372/262387 [00:38<1:50:30, 39.37it/s, Loss: 6.711 (16.1\u001b[A\n",
      "Train(0):   1%| | 1372/262387 [00:38<1:50:30, 39.37it/s, Loss: 14.520 (16.\u001b[A\n",
      "Train(0):   1%| | 1373/262387 [00:38<1:50:30, 39.37it/s, Loss: 9.768 (16.1\u001b[A\n",
      "Train(0):   1%| | 1374/262387 [00:38<1:50:30, 39.37it/s, Loss: 12.565 (16.\u001b[A\n",
      "Train(0):   1%| | 1375/262387 [00:38<1:50:30, 39.37it/s, Loss: 15.119 (16.\u001b[A\n",
      "Train(0):   1%| | 1376/262387 [00:38<1:50:29, 39.37it/s, Loss: 9.249 (16.1\u001b[A\n",
      "Train(0):   1%| | 1377/262387 [00:38<1:49:33, 39.71it/s, Loss: 9.249 (16.1\u001b[A\n",
      "Train(0):   1%| | 1377/262387 [00:38<1:49:33, 39.71it/s, Loss: 14.371 (16.\u001b[A\n",
      "Train(0):   1%| | 1378/262387 [00:38<1:49:33, 39.71it/s, Loss: 13.086 (16.\u001b[A\n",
      "Train(0):   1%| | 1379/262387 [00:38<1:49:33, 39.71it/s, Loss: 8.082 (16.1\u001b[A\n",
      "Train(0):   1%| | 1380/262387 [00:38<1:49:33, 39.71it/s, Loss: 14.473 (16.\u001b[A\n",
      "Train(0):   1%| | 1381/262387 [00:38<1:49:30, 39.72it/s, Loss: 14.473 (16.\u001b[A\n",
      "Train(0):   1%| | 1381/262387 [00:38<1:49:30, 39.72it/s, Loss: 10.267 (16.\u001b[A\n",
      "Train(0):   1%| | 1382/262387 [00:38<1:49:30, 39.72it/s, Loss: 13.931 (16.\u001b[A\n",
      "Train(0):   1%| | 1383/262387 [00:38<1:49:30, 39.72it/s, Loss: 13.003 (16.\u001b[A\n",
      "Train(0):   1%| | 1384/262387 [00:38<1:49:30, 39.72it/s, Loss: 11.445 (16.\u001b[A\n",
      "Train(0):   1%| | 1385/262387 [00:38<1:49:30, 39.72it/s, Loss: 9.809 (16.1\u001b[A\n",
      "Train(0):   1%| | 1386/262387 [00:38<1:48:56, 39.93it/s, Loss: 9.809 (16.1\u001b[A\n",
      "Train(0):   1%| | 1386/262387 [00:38<1:48:56, 39.93it/s, Loss: 14.207 (16.\u001b[A\n",
      "Train(0):   1%| | 1387/262387 [00:38<1:48:56, 39.93it/s, Loss: 9.512 (16.0\u001b[A\n",
      "Train(0):   1%| | 1388/262387 [00:38<1:48:56, 39.93it/s, Loss: 15.947 (16.\u001b[A\n",
      "Train(0):   1%| | 1389/262387 [00:38<1:48:56, 39.93it/s, Loss: 16.410 (16.\u001b[A\n",
      "Train(0):   1%| | 1390/262387 [00:38<1:53:00, 38.49it/s, Loss: 16.410 (16.\u001b[A\n",
      "Train(0):   1%| | 1390/262387 [00:38<1:53:00, 38.49it/s, Loss: 7.672 (16.0\u001b[A\n",
      "Train(0):   1%| | 1391/262387 [00:38<1:53:00, 38.49it/s, Loss: 14.861 (16.\u001b[A\n",
      "Train(0):   1%| | 1392/262387 [00:38<1:53:00, 38.49it/s, Loss: 13.262 (16.\u001b[A\n",
      "Train(0):   1%| | 1393/262387 [00:38<1:53:00, 38.49it/s, Loss: 10.546 (16.\u001b[A\n",
      "Train(0):   1%| | 1394/262387 [00:38<1:53:00, 38.49it/s, Loss: 12.226 (16.\u001b[A\n",
      "Train(0):   1%| | 1395/262387 [00:38<1:51:25, 39.04it/s, Loss: 12.226 (16.\u001b[A\n",
      "Train(0):   1%| | 1395/262387 [00:38<1:51:25, 39.04it/s, Loss: 12.940 (16.\u001b[A\n",
      "Train(0):   1%| | 1396/262387 [00:38<1:51:25, 39.04it/s, Loss: 7.483 (16.0\u001b[A\n",
      "Train(0):   1%| | 1397/262387 [00:38<1:51:25, 39.04it/s, Loss: 17.053 (16.\u001b[A\n",
      "Train(0):   1%| | 1398/262387 [00:38<1:51:25, 39.04it/s, Loss: 11.136 (16.\u001b[A\n",
      "Train(0):   1%| | 1399/262387 [00:38<1:50:47, 39.26it/s, Loss: 11.136 (16.\u001b[A\n",
      "Train(0):   1%| | 1399/262387 [00:38<1:50:47, 39.26it/s, Loss: 10.494 (16.\u001b[A\n",
      "Train(0):   1%| | 1400/262387 [00:38<1:50:47, 39.26it/s, Loss: 7.891 (16.0\u001b[A\n",
      "Train(0):   1%| | 1401/262387 [00:39<1:50:47, 39.26it/s, Loss: 10.203 (16.\u001b[A\n",
      "Train(0):   1%| | 1402/262387 [00:39<1:50:47, 39.26it/s, Loss: 17.413 (16.\u001b[A\n",
      "Train(0):   1%| | 1403/262387 [00:39<1:51:33, 38.99it/s, Loss: 17.413 (16.\u001b[A\n",
      "Train(0):   1%| | 1403/262387 [00:39<1:51:33, 38.99it/s, Loss: 8.012 (16.0\u001b[A\n",
      "Train(0):   1%| | 1404/262387 [00:39<1:51:33, 38.99it/s, Loss: 13.266 (16.\u001b[A\n",
      "Train(0):   1%| | 1405/262387 [00:39<1:51:33, 38.99it/s, Loss: 11.612 (16.\u001b[A\n",
      "Train(0):   1%| | 1406/262387 [00:39<1:51:33, 38.99it/s, Loss: 17.847 (16.\u001b[A\n",
      "Train(0):   1%| | 1407/262387 [00:39<1:51:47, 38.91it/s, Loss: 17.847 (16.\u001b[A\n",
      "Train(0):   1%| | 1407/262387 [00:39<1:51:47, 38.91it/s, Loss: 10.971 (16.\u001b[A\n",
      "Train(0):   1%| | 1408/262387 [00:39<1:51:47, 38.91it/s, Loss: 12.898 (16.\u001b[A\n",
      "Train(0):   1%| | 1409/262387 [00:39<1:51:47, 38.91it/s, Loss: 8.524 (16.0\u001b[A\n",
      "Train(0):   1%| | 1410/262387 [00:39<1:51:47, 38.91it/s, Loss: 8.674 (16.0\u001b[A\n",
      "Train(0):   1%| | 1411/262387 [00:39<1:57:02, 37.16it/s, Loss: 8.674 (16.0\u001b[A\n",
      "Train(0):   1%| | 1411/262387 [00:39<1:57:02, 37.16it/s, Loss: 9.380 (16.0\u001b[A\n",
      "Train(0):   1%| | 1412/262387 [00:39<1:57:02, 37.16it/s, Loss: 12.571 (16.\u001b[A\n",
      "Train(0):   1%| | 1413/262387 [00:39<1:57:02, 37.16it/s, Loss: 10.715 (16.\u001b[A\n",
      "Train(0):   1%| | 1414/262387 [00:39<1:57:02, 37.16it/s, Loss: 10.251 (16.\u001b[A\n",
      "Train(0):   1%| | 1415/262387 [00:39<1:55:10, 37.77it/s, Loss: 10.251 (16.\u001b[A\n",
      "Train(0):   1%| | 1415/262387 [00:39<1:55:10, 37.77it/s, Loss: 11.755 (16.\u001b[A\n",
      "Train(0):   1%| | 1416/262387 [00:39<1:55:10, 37.77it/s, Loss: 13.104 (16.\u001b[A\n",
      "Train(0):   1%| | 1417/262387 [00:39<1:55:10, 37.77it/s, Loss: 7.555 (16.0\u001b[A\n",
      "Train(0):   1%| | 1418/262387 [00:39<1:55:10, 37.77it/s, Loss: 13.287 (16.\u001b[A\n",
      "Train(0):   1%| | 1419/262387 [00:39<1:54:10, 38.10it/s, Loss: 13.287 (16.\u001b[A\n",
      "Train(0):   1%| | 1419/262387 [00:39<1:54:10, 38.10it/s, Loss: 13.404 (16.\u001b[A\n",
      "Train(0):   1%| | 1420/262387 [00:39<1:54:10, 38.10it/s, Loss: 14.346 (16.\u001b[A\n",
      "Train(0):   1%| | 1421/262387 [00:39<1:54:10, 38.10it/s, Loss: 9.480 (15.9\u001b[A\n",
      "Train(0):   1%| | 1422/262387 [00:39<1:54:10, 38.10it/s, Loss: 10.221 (15.\u001b[A\n",
      "Train(0):   1%| | 1423/262387 [00:39<1:52:51, 38.54it/s, Loss: 10.221 (15.\u001b[A\n",
      "Train(0):   1%| | 1423/262387 [00:39<1:52:51, 38.54it/s, Loss: 8.328 (15.9\u001b[A\n",
      "Train(0):   1%| | 1424/262387 [00:39<1:52:51, 38.54it/s, Loss: 7.514 (15.9\u001b[A\n",
      "Train(0):   1%| | 1425/262387 [00:39<1:52:51, 38.54it/s, Loss: 8.930 (15.9\u001b[A\n",
      "Train(0):   1%| | 1426/262387 [00:39<1:52:51, 38.54it/s, Loss: 14.563 (15.\u001b[A\n",
      "Train(0):   1%| | 1427/262387 [00:39<1:51:52, 38.88it/s, Loss: 14.563 (15.\u001b[A\n",
      "Train(0):   1%| | 1427/262387 [00:39<1:51:52, 38.88it/s, Loss: 11.175 (15.\u001b[A\n",
      "Train(0):   1%| | 1428/262387 [00:39<1:51:52, 38.88it/s, Loss: 13.843 (15.\u001b[A\n",
      "Train(0):   1%| | 1429/262387 [00:39<1:51:52, 38.88it/s, Loss: 8.668 (15.9\u001b[A\n",
      "Train(0):   1%| | 1430/262387 [00:39<1:51:52, 38.88it/s, Loss: 9.364 (15.9\u001b[A\n",
      "Train(0):   1%| | 1431/262387 [00:39<1:52:19, 38.72it/s, Loss: 9.364 (15.9\u001b[A\n",
      "Train(0):   1%| | 1431/262387 [00:39<1:52:19, 38.72it/s, Loss: 10.706 (15.\u001b[A\n",
      "Train(0):   1%| | 1432/262387 [00:39<1:52:19, 38.72it/s, Loss: 9.204 (15.9\u001b[A\n",
      "Train(0):   1%| | 1433/262387 [00:39<1:52:19, 38.72it/s, Loss: 8.948 (15.9\u001b[A\n",
      "Train(0):   1%| | 1434/262387 [00:39<1:52:19, 38.72it/s, Loss: 7.386 (15.9\u001b[A\n",
      "Train(0):   1%| | 1435/262387 [00:39<1:52:19, 38.72it/s, Loss: 5.683 (15.9\u001b[A\n",
      "Train(0):   1%| | 1436/262387 [00:39<1:50:30, 39.36it/s, Loss: 5.683 (15.9\u001b[A\n",
      "Train(0):   1%| | 1436/262387 [00:39<1:50:30, 39.36it/s, Loss: 5.725 (15.9\u001b[A\n",
      "Train(0):   1%| | 1437/262387 [00:39<1:50:30, 39.36it/s, Loss: 10.565 (15.\u001b[A\n",
      "Train(0):   1%| | 1438/262387 [00:39<1:50:30, 39.36it/s, Loss: 9.124 (15.9\u001b[A\n",
      "Train(0):   1%| | 1439/262387 [00:39<1:50:30, 39.36it/s, Loss: 7.609 (15.9\u001b[A\n",
      "Train(0):   1%| | 1440/262387 [00:40<1:58:26, 36.72it/s, Loss: 7.609 (15.9\u001b[A\n",
      "Train(0):   1%| | 1440/262387 [00:40<1:58:26, 36.72it/s, Loss: 7.029 (15.9\u001b[A\n",
      "Train(0):   1%| | 1441/262387 [00:40<1:58:26, 36.72it/s, Loss: 10.928 (15.\u001b[A\n",
      "Train(0):   1%| | 1442/262387 [00:40<1:58:26, 36.72it/s, Loss: 9.637 (15.9\u001b[A\n",
      "Train(0):   1%| | 1443/262387 [00:40<1:58:26, 36.72it/s, Loss: 11.220 (15.\u001b[A\n",
      "Train(0):   1%| | 1444/262387 [00:40<1:56:55, 37.20it/s, Loss: 11.220 (15.\u001b[A\n",
      "Train(0):   1%| | 1444/262387 [00:40<1:56:55, 37.20it/s, Loss: 16.243 (15.\u001b[A\n",
      "Train(0):   1%| | 1445/262387 [00:40<1:56:55, 37.20it/s, Loss: 12.480 (15.\u001b[A\n",
      "Train(0):   1%| | 1446/262387 [00:40<1:56:55, 37.20it/s, Loss: 13.487 (15.\u001b[A\n",
      "Train(0):   1%| | 1447/262387 [00:40<1:56:55, 37.20it/s, Loss: 11.951 (15.\u001b[A\n",
      "Train(0):   1%| | 1448/262387 [00:40<1:56:55, 37.20it/s, Loss: 17.268 (15.\u001b[A\n",
      "Train(0):   1%| | 1449/262387 [00:40<1:51:59, 38.83it/s, Loss: 17.268 (15.\u001b[A\n",
      "Train(0):   1%| | 1449/262387 [00:40<1:51:59, 38.83it/s, Loss: 14.060 (15.\u001b[A\n",
      "Train(0):   1%| | 1450/262387 [00:40<1:51:59, 38.83it/s, Loss: 12.867 (15.\u001b[A\n",
      "Train(0):   1%| | 1451/262387 [00:40<1:51:59, 38.83it/s, Loss: 11.216 (15.\u001b[A\n",
      "Train(0):   1%| | 1452/262387 [00:40<1:51:59, 38.83it/s, Loss: 8.468 (15.8\u001b[A\n",
      "Train(0):   1%| | 1453/262387 [00:40<1:51:31, 38.99it/s, Loss: 8.468 (15.8\u001b[A\n",
      "Train(0):   1%| | 1453/262387 [00:40<1:51:31, 38.99it/s, Loss: 7.322 (15.8\u001b[A\n",
      "Train(0):   1%| | 1454/262387 [00:40<1:51:31, 38.99it/s, Loss: 11.578 (15.\u001b[A\n",
      "Train(0):   1%| | 1455/262387 [00:40<1:51:31, 38.99it/s, Loss: 10.900 (15.\u001b[A\n",
      "Train(0):   1%| | 1456/262387 [00:40<1:51:31, 38.99it/s, Loss: 11.588 (15.\u001b[A\n",
      "Train(0):   1%| | 1457/262387 [00:40<1:51:48, 38.90it/s, Loss: 11.588 (15.\u001b[A\n",
      "Train(0):   1%| | 1457/262387 [00:40<1:51:48, 38.90it/s, Loss: 9.563 (15.8\u001b[A\n",
      "Train(0):   1%| | 1458/262387 [00:40<1:51:48, 38.90it/s, Loss: 11.134 (15.\u001b[A\n",
      "Train(0):   1%| | 1459/262387 [00:40<1:51:48, 38.90it/s, Loss: 10.919 (15.\u001b[A\n",
      "Train(0):   1%| | 1460/262387 [00:40<1:51:48, 38.90it/s, Loss: 8.959 (15.8\u001b[A\n",
      "Train(0):   1%| | 1461/262387 [00:40<1:51:48, 38.90it/s, Loss: 13.550 (15.\u001b[A\n",
      "Train(0):   1%| | 1462/262387 [00:40<1:50:10, 39.47it/s, Loss: 13.550 (15.\u001b[A\n",
      "Train(0):   1%| | 1462/262387 [00:40<1:50:10, 39.47it/s, Loss: 15.885 (15.\u001b[A\n",
      "Train(0):   1%| | 1463/262387 [00:40<1:50:10, 39.47it/s, Loss: 6.340 (15.8\u001b[A\n",
      "Train(0):   1%| | 1464/262387 [00:40<1:50:10, 39.47it/s, Loss: 14.862 (15.\u001b[A\n",
      "Train(0):   1%| | 1465/262387 [00:40<1:50:10, 39.47it/s, Loss: 8.758 (15.8\u001b[A\n",
      "Train(0):   1%| | 1466/262387 [00:40<1:50:10, 39.47it/s, Loss: 7.817 (15.8\u001b[A\n",
      "Train(0):   1%| | 1467/262387 [00:40<1:48:58, 39.91it/s, Loss: 7.817 (15.8\u001b[A\n",
      "Train(0):   1%| | 1467/262387 [00:40<1:48:58, 39.91it/s, Loss: 7.933 (15.8\u001b[A\n",
      "Train(0):   1%| | 1468/262387 [00:40<1:48:58, 39.91it/s, Loss: 17.031 (15.\u001b[A\n",
      "Train(0):   1%| | 1469/262387 [00:40<1:48:58, 39.91it/s, Loss: 15.022 (15.\u001b[A\n",
      "Train(0):   1%| | 1470/262387 [00:40<1:48:58, 39.91it/s, Loss: 16.589 (15.\u001b[A\n",
      "Train(0):   1%| | 1471/262387 [00:40<1:52:38, 38.60it/s, Loss: 16.589 (15.\u001b[A\n",
      "Train(0):   1%| | 1471/262387 [00:40<1:52:38, 38.60it/s, Loss: 12.303 (15.\u001b[A\n",
      "Train(0):   1%| | 1472/262387 [00:40<1:52:38, 38.60it/s, Loss: 13.272 (15.\u001b[A\n",
      "Train(0):   1%| | 1473/262387 [00:40<1:52:38, 38.60it/s, Loss: 9.923 (15.8\u001b[A\n",
      "Train(0):   1%| | 1474/262387 [00:40<1:52:38, 38.60it/s, Loss: 13.734 (15.\u001b[A\n",
      "Train(0):   1%| | 1475/262387 [00:40<1:52:38, 38.60it/s, Loss: 8.258 (15.8\u001b[A\n",
      "Train(0):   1%| | 1476/262387 [00:40<1:49:00, 39.89it/s, Loss: 8.258 (15.8\u001b[A\n",
      "Train(0):   1%| | 1476/262387 [00:40<1:49:00, 39.89it/s, Loss: 16.566 (15.\u001b[A\n",
      "Train(0):   1%| | 1477/262387 [00:40<1:49:00, 39.89it/s, Loss: 13.800 (15.\u001b[A\n",
      "Train(0):   1%| | 1478/262387 [00:40<1:49:00, 39.89it/s, Loss: 13.603 (15.\u001b[A\n",
      "Train(0):   1%| | 1479/262387 [00:41<1:48:59, 39.89it/s, Loss: 17.228 (15.\u001b[A\n",
      "Train(0):   1%| | 1480/262387 [00:41<1:48:59, 39.89it/s, Loss: 14.926 (15.\u001b[A\n",
      "Train(0):   1%| | 1481/262387 [00:41<1:44:25, 41.64it/s, Loss: 14.926 (15.\u001b[A\n",
      "Train(0):   1%| | 1481/262387 [00:41<1:44:25, 41.64it/s, Loss: 11.786 (15.\u001b[A\n",
      "Train(0):   1%| | 1482/262387 [00:41<1:44:24, 41.64it/s, Loss: 11.363 (15.\u001b[A\n",
      "Train(0):   1%| | 1483/262387 [00:41<1:44:24, 41.64it/s, Loss: 9.361 (15.7\u001b[A\n",
      "Train(0):   1%| | 1484/262387 [00:41<1:44:24, 41.64it/s, Loss: 10.481 (15.\u001b[A\n",
      "Train(0):   1%| | 1485/262387 [00:41<1:44:24, 41.64it/s, Loss: 11.573 (15.\u001b[A\n",
      "Train(0):   1%| | 1486/262387 [00:41<1:40:18, 43.35it/s, Loss: 11.573 (15.\u001b[A\n",
      "Train(0):   1%| | 1486/262387 [00:41<1:40:18, 43.35it/s, Loss: 8.523 (15.7\u001b[A\n",
      "Train(0):   1%| | 1487/262387 [00:41<1:40:18, 43.35it/s, Loss: 17.454 (15.\u001b[A\n",
      "Train(0):   1%| | 1488/262387 [00:41<1:40:18, 43.35it/s, Loss: 11.917 (15.\u001b[A\n",
      "Train(0):   1%| | 1489/262387 [00:41<1:40:18, 43.35it/s, Loss: 11.278 (15.\u001b[A\n",
      "Train(0):   1%| | 1490/262387 [00:41<1:40:18, 43.35it/s, Loss: 12.973 (15.\u001b[A\n",
      "Train(0):   1%| | 1491/262387 [00:41<1:38:28, 44.16it/s, Loss: 12.973 (15.\u001b[A\n",
      "Train(0):   1%| | 1491/262387 [00:41<1:38:28, 44.16it/s, Loss: 5.528 (15.7\u001b[A\n",
      "Train(0):   1%| | 1492/262387 [00:41<1:38:28, 44.16it/s, Loss: 13.838 (15.\u001b[A\n",
      "Train(0):   1%| | 1493/262387 [00:41<1:38:28, 44.16it/s, Loss: 14.306 (15.\u001b[A\n",
      "Train(0):   1%| | 1494/262387 [00:41<1:38:28, 44.16it/s, Loss: 12.836 (15.\u001b[A\n",
      "Train(0):   1%| | 1495/262387 [00:41<1:38:28, 44.16it/s, Loss: 7.479 (15.7\u001b[A\n",
      "Train(0):   1%| | 1496/262387 [00:41<1:41:47, 42.72it/s, Loss: 7.479 (15.7\u001b[A\n",
      "Train(0):   1%| | 1496/262387 [00:41<1:41:47, 42.72it/s, Loss: 11.067 (15.\u001b[A\n",
      "Train(0):   1%| | 1497/262387 [00:41<1:41:47, 42.72it/s, Loss: 10.444 (15.\u001b[A\n",
      "Train(0):   1%| | 1498/262387 [00:41<1:41:47, 42.72it/s, Loss: 11.321 (15.\u001b[A\n",
      "Train(0):   1%| | 1499/262387 [00:41<1:41:47, 42.72it/s, Loss: 13.097 (15.\u001b[A\n",
      "Train(0):   1%| | 1500/262387 [00:41<1:41:47, 42.72it/s, Loss: 17.444 (15.\u001b[A\n",
      "Train(0):   1%| | 1501/262387 [00:41<1:48:02, 40.25it/s, Loss: 17.444 (15.\u001b[A\n",
      "Train(0):   1%| | 1501/262387 [00:41<1:48:02, 40.25it/s, Loss: 10.133 (15.\u001b[A\n",
      "Train(0):   1%| | 1502/262387 [00:41<1:48:02, 40.25it/s, Loss: 9.296 (15.7\u001b[A\n",
      "Train(0):   1%| | 1503/262387 [00:41<1:48:02, 40.25it/s, Loss: 13.095 (15.\u001b[A\n",
      "Train(0):   1%| | 1504/262387 [00:41<1:48:02, 40.25it/s, Loss: 10.357 (15.\u001b[A\n",
      "Train(0):   1%| | 1505/262387 [00:41<1:48:02, 40.25it/s, Loss: 9.186 (15.7\u001b[A\n",
      "Train(0):   1%| | 1506/262387 [00:41<1:48:32, 40.06it/s, Loss: 9.186 (15.7\u001b[A\n",
      "Train(0):   1%| | 1506/262387 [00:41<1:48:32, 40.06it/s, Loss: 9.509 (15.7\u001b[A\n",
      "Train(0):   1%| | 1507/262387 [00:41<1:48:32, 40.06it/s, Loss: 9.270 (15.7\u001b[A\n",
      "Train(0):   1%| | 1508/262387 [00:41<1:48:32, 40.06it/s, Loss: 6.357 (15.7\u001b[A\n",
      "Train(0):   1%| | 1509/262387 [00:41<1:48:31, 40.06it/s, Loss: 9.194 (15.7\u001b[A\n",
      "Train(0):   1%| | 1510/262387 [00:41<1:48:31, 40.06it/s, Loss: 10.710 (15.\u001b[A\n",
      "Train(0):   1%| | 1511/262387 [00:41<1:51:32, 38.98it/s, Loss: 10.710 (15.\u001b[A\n",
      "Train(0):   1%| | 1511/262387 [00:41<1:51:32, 38.98it/s, Loss: 15.203 (15.\u001b[A\n",
      "Train(0):   1%| | 1512/262387 [00:41<1:51:32, 38.98it/s, Loss: 10.760 (15.\u001b[A\n",
      "Train(0):   1%| | 1513/262387 [00:41<1:51:32, 38.98it/s, Loss: 11.787 (15.\u001b[A\n",
      "Train(0):   1%| | 1514/262387 [00:41<1:51:32, 38.98it/s, Loss: 15.660 (15.\u001b[A\n",
      "Train(0):   1%| | 1515/262387 [00:41<1:52:15, 38.73it/s, Loss: 15.660 (15.\u001b[A\n",
      "Train(0):   1%| | 1515/262387 [00:41<1:52:15, 38.73it/s, Loss: 6.417 (15.7\u001b[A\n",
      "Train(0):   1%| | 1516/262387 [00:41<1:52:15, 38.73it/s, Loss: 15.514 (15.\u001b[A\n",
      "Train(0):   1%| | 1517/262387 [00:41<1:52:14, 38.73it/s, Loss: 7.929 (15.6\u001b[A\n",
      "Train(0):   1%| | 1518/262387 [00:41<1:52:14, 38.73it/s, Loss: 13.477 (15.\u001b[A\n",
      "Train(0):   1%| | 1519/262387 [00:41<1:52:36, 38.61it/s, Loss: 13.477 (15.\u001b[A\n",
      "Train(0):   1%| | 1519/262387 [00:41<1:52:36, 38.61it/s, Loss: 12.173 (15.\u001b[A\n",
      "Train(0):   1%| | 1520/262387 [00:42<1:52:36, 38.61it/s, Loss: 16.137 (15.\u001b[A\n",
      "Train(0):   1%| | 1521/262387 [00:42<1:52:36, 38.61it/s, Loss: 9.837 (15.6\u001b[A\n",
      "Train(0):   1%| | 1522/262387 [00:42<1:52:36, 38.61it/s, Loss: 13.937 (15.\u001b[A\n",
      "Train(0):   1%| | 1523/262387 [00:42<1:53:53, 38.17it/s, Loss: 13.937 (15.\u001b[A\n",
      "Train(0):   1%| | 1523/262387 [00:42<1:53:53, 38.17it/s, Loss: 11.608 (15.\u001b[A\n",
      "Train(0):   1%| | 1524/262387 [00:42<1:53:53, 38.17it/s, Loss: 9.922 (15.6\u001b[A\n",
      "Train(0):   1%| | 1525/262387 [00:42<1:53:53, 38.17it/s, Loss: 14.591 (15.\u001b[A\n",
      "Train(0):   1%| | 1526/262387 [00:42<1:53:53, 38.17it/s, Loss: 16.067 (15.\u001b[A\n",
      "Train(0):   1%| | 1527/262387 [00:42<2:01:35, 35.75it/s, Loss: 16.067 (15.\u001b[A\n",
      "Train(0):   1%| | 1527/262387 [00:42<2:01:35, 35.75it/s, Loss: 10.809 (15.\u001b[A\n",
      "Train(0):   1%| | 1528/262387 [00:42<2:01:35, 35.75it/s, Loss: 12.684 (15.\u001b[A\n",
      "Train(0):   1%| | 1529/262387 [00:42<2:01:35, 35.75it/s, Loss: 8.947 (15.6\u001b[A\n",
      "Train(0):   1%| | 1530/262387 [00:42<2:01:35, 35.75it/s, Loss: 13.645 (15.\u001b[A\n",
      "Train(0):   1%| | 1531/262387 [00:42<2:01:35, 35.75it/s, Loss: 9.759 (15.6\u001b[A\n",
      "Train(0):   1%| | 1532/262387 [00:42<1:56:00, 37.48it/s, Loss: 9.759 (15.6\u001b[A\n",
      "Train(0):   1%| | 1532/262387 [00:42<1:56:00, 37.48it/s, Loss: 5.984 (15.6\u001b[A\n",
      "Train(0):   1%| | 1533/262387 [00:42<1:56:00, 37.48it/s, Loss: 14.579 (15.\u001b[A\n",
      "Train(0):   1%| | 1534/262387 [00:42<1:56:00, 37.48it/s, Loss: 9.028 (15.6\u001b[A\n",
      "Train(0):   1%| | 1535/262387 [00:42<1:56:00, 37.48it/s, Loss: 11.325 (15.\u001b[A\n",
      "Train(0):   1%| | 1536/262387 [00:42<1:56:00, 37.48it/s, Loss: 11.501 (15.\u001b[A\n",
      "Train(0):   1%| | 1537/262387 [00:42<1:47:43, 40.36it/s, Loss: 11.501 (15.\u001b[A\n",
      "Train(0):   1%| | 1537/262387 [00:42<1:47:43, 40.36it/s, Loss: 9.952 (15.6\u001b[A\n",
      "Train(0):   1%| | 1538/262387 [00:42<1:47:43, 40.36it/s, Loss: 11.909 (15.\u001b[A\n",
      "Train(0):   1%| | 1539/262387 [00:42<1:47:43, 40.36it/s, Loss: 10.955 (15.\u001b[A\n",
      "Train(0):   1%| | 1540/262387 [00:42<1:47:42, 40.36it/s, Loss: 14.593 (15.\u001b[A\n",
      "Train(0):   1%| | 1541/262387 [00:42<1:47:42, 40.36it/s, Loss: 16.975 (15.\u001b[A\n",
      "Train(0):   1%| | 1542/262387 [00:42<1:42:48, 42.28it/s, Loss: 16.975 (15.\u001b[A\n",
      "Train(0):   1%| | 1542/262387 [00:42<1:42:48, 42.28it/s, Loss: 12.235 (15.\u001b[A\n",
      "Train(0):   1%| | 1543/262387 [00:42<1:42:48, 42.28it/s, Loss: 9.071 (15.6\u001b[A\n",
      "Train(0):   1%| | 1544/262387 [00:42<1:42:48, 42.28it/s, Loss: 15.287 (15.\u001b[A\n",
      "Train(0):   1%| | 1545/262387 [00:42<1:42:48, 42.28it/s, Loss: 10.944 (15.\u001b[A\n",
      "Train(0):   1%| | 1546/262387 [00:42<1:42:48, 42.28it/s, Loss: 6.667 (15.6\u001b[A\n",
      "Train(0):   1%| | 1547/262387 [00:42<1:48:48, 39.95it/s, Loss: 6.667 (15.6\u001b[A\n",
      "Train(0):   1%| | 1547/262387 [00:42<1:48:48, 39.95it/s, Loss: 8.996 (15.6\u001b[A\n",
      "Train(0):   1%| | 1548/262387 [00:42<1:48:48, 39.95it/s, Loss: 14.638 (15.\u001b[A\n",
      "Train(0):   1%| | 1549/262387 [00:42<1:48:48, 39.95it/s, Loss: 9.104 (15.6\u001b[A\n",
      "Train(0):   1%| | 1550/262387 [00:42<1:48:48, 39.95it/s, Loss: 10.500 (15.\u001b[A\n",
      "Train(0):   1%| | 1551/262387 [00:42<1:48:48, 39.95it/s, Loss: 13.348 (15.\u001b[A\n",
      "Train(0):   1%| | 1552/262387 [00:42<1:44:07, 41.75it/s, Loss: 13.348 (15.\u001b[A\n",
      "Train(0):   1%| | 1552/262387 [00:42<1:44:07, 41.75it/s, Loss: 13.076 (15.\u001b[A\n",
      "Train(0):   1%| | 1553/262387 [00:42<1:44:07, 41.75it/s, Loss: 13.163 (15.\u001b[A\n",
      "Train(0):   1%| | 1554/262387 [00:42<1:44:07, 41.75it/s, Loss: 13.491 (15.\u001b[A\n",
      "Train(0):   1%| | 1555/262387 [00:42<1:44:07, 41.75it/s, Loss: 13.230 (15.\u001b[A\n",
      "Train(0):   1%| | 1556/262387 [00:42<1:44:07, 41.75it/s, Loss: 8.143 (15.6\u001b[A\n",
      "Train(0):   1%| | 1557/262387 [00:42<1:41:16, 42.93it/s, Loss: 8.143 (15.6\u001b[A\n",
      "Train(0):   1%| | 1557/262387 [00:42<1:41:16, 42.93it/s, Loss: 5.776 (15.5\u001b[A\n",
      "Train(0):   1%| | 1558/262387 [00:42<1:41:16, 42.93it/s, Loss: 9.433 (15.5\u001b[A\n",
      "Train(0):   1%| | 1559/262387 [00:42<1:41:16, 42.93it/s, Loss: 11.822 (15.\u001b[A\n",
      "Train(0):   1%| | 1560/262387 [00:42<1:41:16, 42.93it/s, Loss: 11.849 (15.\u001b[A\n",
      "Train(0):   1%| | 1561/262387 [00:43<1:41:16, 42.93it/s, Loss: 9.988 (15.5\u001b[A\n",
      "Train(0):   1%| | 1562/262387 [00:43<1:38:32, 44.12it/s, Loss: 9.988 (15.5\u001b[A\n",
      "Train(0):   1%| | 1562/262387 [00:43<1:38:32, 44.12it/s, Loss: 14.796 (15.\u001b[A\n",
      "Train(0):   1%| | 1563/262387 [00:43<1:38:32, 44.12it/s, Loss: 10.043 (15.\u001b[A\n",
      "Train(0):   1%| | 1564/262387 [00:43<1:38:32, 44.12it/s, Loss: 13.364 (15.\u001b[A\n",
      "Train(0):   1%| | 1565/262387 [00:43<1:38:32, 44.12it/s, Loss: 5.933 (15.5\u001b[A\n",
      "Train(0):   1%| | 1566/262387 [00:43<1:38:32, 44.12it/s, Loss: 5.636 (15.5\u001b[A\n",
      "Train(0):   1%| | 1567/262387 [00:43<1:36:22, 45.11it/s, Loss: 5.636 (15.5\u001b[A\n",
      "Train(0):   1%| | 1567/262387 [00:43<1:36:22, 45.11it/s, Loss: 10.482 (15.\u001b[A\n",
      "Train(0):   1%| | 1568/262387 [00:43<1:36:22, 45.11it/s, Loss: 15.419 (15.\u001b[A\n",
      "Train(0):   1%| | 1569/262387 [00:43<1:36:22, 45.11it/s, Loss: 8.202 (15.5\u001b[A\n",
      "Train(0):   1%| | 1570/262387 [00:43<1:36:22, 45.11it/s, Loss: 13.797 (15.\u001b[A\n",
      "Train(0):   1%| | 1571/262387 [00:43<1:36:22, 45.11it/s, Loss: 14.333 (15.\u001b[A\n",
      "Train(0):   1%| | 1572/262387 [00:43<1:41:30, 42.82it/s, Loss: 14.333 (15.\u001b[A\n",
      "Train(0):   1%| | 1572/262387 [00:43<1:41:30, 42.82it/s, Loss: 11.138 (15.\u001b[A\n",
      "Train(0):   1%| | 1573/262387 [00:43<1:41:30, 42.82it/s, Loss: 6.626 (15.5\u001b[A"
     ]
    }
   ],
   "source": [
    "model = GPTPretrain(config)\n",
    "\n",
    "save_pretrain = f\"../save_gpt_pretrain.pth\"\n",
    "best_epoch, best_loss = 0, 0\n",
    "# if os.path.isfile(save_pretrain): # pretrain된 weight가 있으면 불러올 수 있다. \n",
    "#     best_epoch, best_loss = model.gpt.load(save_pretrain)\n",
    "#     print(f\"load pretrain from: {save_pretrain}, epoch={best_epoch}, loss={best_loss}\")\n",
    "#     best_epoch += 1\n",
    "\n",
    "model.to(config.device)\n",
    "\n",
    "criterion_lm = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "offset = best_epoch\n",
    "for step in trange(n_epoch, desc=\"Epoch\"):\n",
    "    epoch = step + offset\n",
    "    loss = train_epoch(config, epoch, model, criterion_lm, optimizer, train_loader)\n",
    "    losses.append(loss)\n",
    "    model.gpt.save(epoch, loss, save_pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e41e7b-a5ea-442e-8044-fcc8425f4377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "data = {\n",
    "    \"loss\": losses\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n",
    "\n",
    "# graph\n",
    "plt.figure(figsize=[12, 4])\n",
    "plt.plot(losses, label=\"loss\")\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056334e3-f9af-42c8-96db-800e24f63fdb",
   "metadata": {},
   "source": [
    "# FineTune GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f161d52b-6f53-4590-a7e8-d405f1722d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" naver movie classfication \"\"\"\n",
    "class MovieClassification(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.gpt = GPT(self.config)\n",
    "        # lm\n",
    "        self.projection_lm = nn.Linear(self.config.d_hidn, self.config.n_dec_vocab, bias=False)\n",
    "        self.projection_lm.weight = self.gpt.decoder.dec_emb.weight\n",
    "        # classfier\n",
    "        self.projection_cls = nn.Linear(self.config.d_hidn, self.config.n_output, bias=False)\n",
    "    \n",
    "    def forward(self, dec_inputs):\n",
    "        # (bs, n_dec_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
    "        dec_outputs, dec_self_attn_probs = self.gpt(dec_inputs)\n",
    "        # (bs, n_dec_seq, n_dec_vocab)\n",
    "        logits_lm = self.projection_lm(dec_outputs)\n",
    "        # (bs, d_hidn)\n",
    "        dec_outputs = dec_outputs[:, -1].contiguous()\n",
    "        # (bs, n_output)\n",
    "        logits_cls = self.projection_cls(dec_outputs)\n",
    "        # (bs, n_dec_seq - 1, n_dec_vocab), (bs, n_output), [(bs, n_head, n_dec_seq, n_dec_seq)]\n",
    "        return logits_lm[:, :-1, :].contiguous(), logits_cls, dec_self_attn_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0925a1-7f6b-46ee-bdf6-3460343b9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieDataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, vocab, infile):\n",
    "        self.vocab = vocab\n",
    "        self.labels = []\n",
    "        self.sentences = []\n",
    "\n",
    "        line_cnt = 0\n",
    "        with open(infile, \"r\") as f:\n",
    "            for line in f:\n",
    "                line_cnt += 1\n",
    "\n",
    "        with open(infile, \"r\") as f:\n",
    "            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n",
    "                data = json.loads(line)\n",
    "                self.labels.append(data[\"label\"])\n",
    "                self.sentences.append([vocab.piece_to_id(\"[BOS]\")] + [vocab.piece_to_id(p) for p in data[\"doc\"]] + [vocab.piece_to_id(\"[EOS]\")])\n",
    "    \n",
    "    def __len__(self):\n",
    "        assert len(self.labels) == len(self.sentences)\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return (torch.tensor(self.labels[item]),\n",
    "                torch.tensor(self.sentences[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac77804-b71b-4502-a140-862adf53877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_collate_fn(inputs):\n",
    "    labels, dec_inputs = list(zip(*inputs))\n",
    "\n",
    "    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n",
    "\n",
    "    batch = [\n",
    "        torch.stack(labels, dim=0),\n",
    "        dec_inputs,\n",
    "    ]\n",
    "    return batch\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e0f444-c2b0-41ee-89c3-5ab015cd4703",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_dataset = MovieDataSet(vocab, f\"../Transformer/ratings_train.json\")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=movie_collate_fn)\n",
    "test_dataset = MovieDataSet(vocab, f\"../Transformer/ratings_test.json\")\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=movie_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9ec19e-8c46-4694-ae3a-572afeb49322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_epoch(config, model, data_loader):\n",
    "    matchs = []\n",
    "    model.eval()\n",
    "\n",
    "    n_word_total = 0\n",
    "    n_correct_total = 0\n",
    "    with tqdm(total=len(data_loader), desc=f\"Valid\") as pbar:\n",
    "        for i, value in enumerate(data_loader):\n",
    "            labels, dec_inputs = map(lambda v: v.to(config.device), value)\n",
    "\n",
    "            outputs = model(dec_inputs)\n",
    "            logits_cls = outputs[1]\n",
    "            _, indices = logits_cls.max(1)\n",
    "\n",
    "            match = torch.eq(indices, labels).detach()\n",
    "            matchs.extend(match.cpu())\n",
    "            accuracy = np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Acc: {accuracy:.3f}\")\n",
    "    return np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c165629b-6ead-4f50-bd29-fe9fb4997a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(config, epoch, model, criterion_lm, criterion_cls, optimizer, train_loader):\n",
    "    losses_1 = []\n",
    "    losses_2 = []\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Train({epoch})\") as pbar:\n",
    "        for i, value in enumerate(train_loader):\n",
    "            labels, dec_inputs = map(lambda v: v.to(config.device), value)\n",
    "\n",
    "            #Calculate L2 loss\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(dec_inputs)\n",
    "            logits_cls = outputs[1]\n",
    "\n",
    "            loss_cls = criterion_cls(logits_cls, labels)\n",
    "            loss = loss_cls\n",
    "\n",
    "            loss_val_2 = loss_cls.item()\n",
    "            \n",
    "            losses_2.append(loss_val_2)\n",
    "            \n",
    "            # loss modification : add L1 loss\n",
    "            labels_lm = dec_inputs[:, 1:].contiguous()\n",
    "            \n",
    "            loss_weight = 1\n",
    "            logits_lm = outputs[0]\n",
    "            loss_lm = criterion_lm(logits_lm.view(-1, logits_lm.size(2)), labels_lm.view(-1))\n",
    "            \n",
    "            loss = loss + loss_weight * loss_lm \n",
    "            loss_val_1 = loss_lm.item()\n",
    "            losses_1.append(loss_val_1)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Loss 1: {loss_val_1:.3f} , Loss 2: {loss_val_2:.3f} ({np.mean(losses_1):.3f}) ({np.mean(losses_2):.3f}\")\n",
    "    return np.mean(losses_1), np.mean(losses_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66d02b-c451-4f90-9e1f-b3467dbc8d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "config.n_output = 2\n",
    "print(config)\n",
    "\n",
    "learning_rate = 5e-5\n",
    "n_epoch = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d37b0b-d178-4e99-a182-fcd5bb17a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    model.to(config.device)\n",
    "\n",
    "    criterion_lm = torch.nn.CrossEntropyLoss()\n",
    "    criterion_cls = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_epoch, best_loss, best_score = 0, 0, 0\n",
    "    losses, scores = [], []\n",
    "    for epoch in range(n_epoch):\n",
    "        loss = train_epoch(config, epoch, model, criterion_lm, criterion_cls, optimizer, train_loader)\n",
    "        score = eval_epoch(config, model, test_loader)\n",
    "\n",
    "        losses.append(loss)\n",
    "        scores.append(score)\n",
    "\n",
    "        if best_score < score:\n",
    "            best_epoch, best_loss, best_score = epoch, loss, score\n",
    "    print(f\">>>> epoch={best_epoch}, loss={best_loss:.5f}, socre={best_score:.5f}\")\n",
    "    return losses, scores\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a69e3-e6d2-4f1d-8fbe-323bf4410191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-train 안 한 GPT\n",
    "model = MovieClassification(config)\n",
    "\n",
    "losses_00, scores_00 = train(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f17e76-b40a-4585-afc7-ef72b0a5e038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre-train 한 GPT\n",
    "model = MovieClassification(config)\n",
    "\n",
    "save_pretrain = f\"../save_gpt_pretrain.pth\"\n",
    "model.gpt.load(save_pretrain)\n",
    "\n",
    "losses_20, scores_20 = train(model)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd809b0-3599-4530-bc19-93c1b2e9945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# table\n",
    "data = {\n",
    "    \"loss_00\": losses_00,\n",
    "    \"socre_00\": scores_00,\n",
    "    \"loss_20\": losses_20,\n",
    "    \"socre_20\": scores_20,\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "display(df)\n",
    "\n",
    "# graph\n",
    "plt.figure(figsize=[12, 4])\n",
    "plt.plot(scores_00, label=\"score_00\")\n",
    "plt.plot(scores_20, label=\"score_20\")\n",
    "plt.legend()\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "508528b76d8b68602d95c8278460fb5ff210fc1da1e8a7a3ea94a4a380fbcf67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
